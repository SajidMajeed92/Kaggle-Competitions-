{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning from Disasters\n",
    "## Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMS Titanic was a British passenger liner that sank in the North Atlantic Ocean in the early hours of 15 April 1912, after colliding with an iceberg during her maiden voyage from Southampton to New York City. There were an estimated 2,224 passengers and crew aboard, and more than 1,500 died, making it one of the deadliest commercial peacetime maritime disasters in modern history. RMS Titanic was the largest ship afloat at the time she entered service and was the second of three Olympic-class ocean liners operated by the White Star Line.\n",
    "\n",
    "### In this exercise, we will try to predict whether a passenger on the Titanic would have survived or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11801/44292724.py:25: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-notebook')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import sklearn libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, precision_recall_curve, auc, make_scorer, confusion_matrix, f1_score, fbeta_score\n",
    "\n",
    "# Import the Naive Bayes, logistic regression, Bagging, RandomForest, AdaBoost, GradientBoost, Decision Trees and SVM Classifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#from matplotlib import style\n",
    "#plt.style.use('bmh')\n",
    "#plt.style.use('ggplot')\n",
    "plt.style.use('seaborn-notebook')\n",
    "\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelBinarizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#titanic_features = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv(\"Dataset/test.csv\")\n",
    "train_df = pd.read_csv(\"Dataset/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Pclass       418 non-null    int64  \n",
      " 2   Name         418 non-null    object \n",
      " 3   Sex          418 non-null    object \n",
      " 4   Age          332 non-null    float64\n",
      " 5   SibSp        418 non-null    int64  \n",
      " 6   Parch        418 non-null    int64  \n",
      " 7   Ticket       418 non-null    object \n",
      " 8   Fare         417 non-null    float64\n",
      " 9   Cabin        91 non-null     object \n",
      " 10  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features:\n",
    "* `survival`: Survival \n",
    "* `PassengerId`: Unique Id of a passenger\n",
    "* `pclass`: Ticket class     \n",
    "* `sex`: Sex     \n",
    "* `Age`: Age in years     \n",
    "* `sibsp`: # of siblings / spouses aboard the Titanic     \n",
    "* `parch`: # of parents / children aboard the Titanic     \n",
    "* `ticket`: Ticket number     \n",
    "* `fare`: Passenger fare     \n",
    "* `cabin`: Cabin number     \n",
    "* `embarked`: Port of Embarkation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the table above, we can note a few things:\n",
    "* ##### We have a few categorical variabes that need to be either converted to numerical or one-hot encoded, so that the machine learning algorithms can process them. \n",
    "* ##### The features have widely different ranges, and we will need to convert into roughly the same scale. \n",
    "* ##### Some features contain missing values (NaN = not a number), that we need to deal with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Age` and `Embarked`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>687</td>\n",
       "      <td>77.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>177</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total     %\n",
       "Cabin          687  77.1\n",
       "Age            177  19.9\n",
       "Embarked         2   0.2\n",
       "PassengerId      0   0.0\n",
       "Survived         0   0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = train_df.isnull().sum().sort_values(ascending=False)\n",
    "percent_1 = train_df.isnull().sum()/train_df.isnull().count()*100\n",
    "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
    "missing_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The `Embarked` feature has only 2 missing values, which can easily be filled. It will be much more tricky, to deal with the `Age` feature, which has 177 missing values. The `Cabin` feature needs further investigation, but it looks like that we might want to drop it from the dataset, since 77 % of it are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Suppress warnings from output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show_err=false; \n",
       "function code_toggle_err() {\n",
       " if (code_show_err){\n",
       " $('div.output_stderr').hide();\n",
       " } else {\n",
       " $('div.output_stderr').show();\n",
       " }\n",
       " code_show_err = !code_show_err\n",
       "} \n",
       "$( document ).ready(code_toggle_err);\n",
       "</script>\n",
       "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show_err=false; \n",
    "function code_toggle_err() {\n",
    " if (code_show_err){\n",
    " $('div.output_stderr').hide();\n",
    " } else {\n",
    " $('div.output_stderr').show();\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "$( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1: How many people Embarked from different ports? Is there a correlation between port of embarkment and survival? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked\n",
       "S    0.722783\n",
       "C    0.188552\n",
       "Q    0.086420\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Embarked'].value_counts()/len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "sns.countplot( x='Embarked', data=train_df, hue=\"Embarked\", palette=\"Set1\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsAAAAHwCAYAAACovdnfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABCeUlEQVR4nO3deXgUVd7+/7ursxMCSYAEEASDBCNCQMLACIh5FBFxYRh1RoPCiKigEZRFMTyyGAYlgAKDiIAoEJEB9w3E34yiAxhcBkYIILKpJAGytEAW0tW/P/zSM/0ExxCaVCf1fl1XX1dyTtWpT3VCcXflVJXD4/F4BAAAANiEYXUBAAAAQG0iAAMAAMBWCMAAAACwFQIwAAAAbIUADAAAAFshAAMAAMBWCMAAAACwFQIwAAAAbIUADAAAAFsJsrqAusLj8cg0eWgeAABAIDIMhxwOR7WWJQBXk2l6VFh4wuoyAAAAcAYxMQ3kdFYvADMFAgAAALZCAAYAAICtEIABAABgKwRgAAAA2AoBGAAAALbCXSAAAAD8zDRNud2VVpdRbzidQTIM/523JQADAAD4icfjkctVqNLS41aXUu+Eh0cqKiqm2vf6/W8IwAAAAH5yOvxGRkYrJCTUL2HN7jwejyoqynX8eJEkqVGj2HMekwAMAADgB6bp9obfyMgoq8upV0JCQiVJx48XqWHD6HOeDsFFcAAAAH7gdrsl/Tuswb9Ov6/+mFtNAAYAAPAjpj2cH/58XwnAAAAAsBXmAAMAANSCzMzJev/9d36xPyYmVm+9ta7G4z/wwAhJ0vz5i2o8xn+TmTlZX331hdasedvvYy9Z8rxefPEFffrpVr+PfSYEYAAAgFoSGxurzMysM/YFBwfXcjX2RQAGAACoJcHBIerY8TKry7A9AjAAAEAAeeCBEWrd+kI1axanN95Yq59+cqlLl8s1ceIT2rTpM7388lIVFh5TUtJlevTRDDVv3sJn/WXLFmvt2tUqKytVt27d9cADY9Sy5QXe/k8++btWrVqhPXt2q7LylJo3b6HBg2/T4MG3SpK+/HKr0tPv09ixj2n58hf1008/KTPzqSp17t6dq/T0+9SxYydNn56lkJAQuVwlWrhwvjZu/FgnThxXu3btNWLESHXr1t27Xnl5uRYt+os+/HCdSktP6qqrrlZ0dMx5ejfPjAAMAABQiyorz3wbL6fT6b3TwYYN69W+faIefXSSCgryNXv2U3rggREKCQnVqFGjVVZWppkzMzV79lOaOfNZ7xjbt/9TxcVFevjh8XK73Xr++b8oPf0+LV/+qiIiGugf//hUEyeO1S23/FF3332vysrK9Prrf9WcOU+rQ4ckXXppR+9YL774gkaPHqvy8nJ17NhZ69d/4O3bv3+fHn74QSUldfSG3/LycqWn36/CwmMaMWKkmjRponfffUuPPPKgZs+er8svT5EkTZs2SVu2bNaIESN1wQWt9NZbr2n9+vfPx1v9iwjAdYBhOGQY3FLFH0zTI9P0WF0GAMCm8vIOq2/fHmfsGznyId1++xBJP4fk6dOzFBX18wM1Pv74b9qy5R969dU3vGdzv/lmm9ate89nDKfTqdmz56tZszhJ0oUXttGwYXfo/fff0eDBt2n//u903XUD9dBDj3jXueyyThow4H/05ZdbfQLwoEG/11VXXV2lzh9++F6jR49Uu3YX689/nqWQkBBJ0rp17+nbb3fr+eeXecfp0eMKPfjgvXruuXlavPhlfffdXv397/+fxo59VDff/HtJ0m9+01N33vkH7d//3dm/oTVEAA5whuFQdONwGU6n1aXUC6bbraLiUkIwAMASsbFN9NRTs8/Ydzq0SlKbNm284VeSYmJi1LhxY5+pDFFRjXT8+HGfMS67rLPPOBdfnKgWLVrq66+/0uDBt+n22++UJJ08eVIHDx7QDz8cUm7uTknSqVMVPmNdfHFilRpPnjyp0aNH6dixo/rLX15QaOi/H/rxxRefKzY2VomJHXzOcv/2t721YMGzcrlc2rbtK0nSFVf08fYbhqGrrvofvfgiARj/j2E4ZDid+i5jksr27be6nDotrG0bXfTkNBmGgwAMALBEcHCwOnRI+tXlIiIaVGkLCwv/1fViYmKrtEVHx+inn1ySpOLiYs2cmamNGz+Ww+HQBRe0UqdOXSRJHo/v/43h4VW353KV6MIL2+inn1xasOBZZWbO9PaVlJTo2LFjv3iG+9ixo3K5fq6jUaPGPn2xsVXrPp8IwHVE2b79Orlrl9VlAACAAHY6YP6nwsJj6tixkyRpypTHdeDAfj3zzAJ17NhJISEhKisr09tvv16t8Rs1aqRZs+Zp/fr3lJU1Q5988nf16dNXkhQZ2VAXXNBakyc/ecZ1W7Ro4Q2+hYWFio+P9/aVlJScxV6eO54EBwAAUE9s2/a1z7SIb775lw4f/lFdu3bz9vftm6quXbt55+5u3vyZpKpngM8kPDxCERERuvHG3+nSSy/T7NlPebfXpUtXFRTkq3HjGHXokOR9ff75Zq1c+bKcziDvhXB/+9sGn3E/+2zjue/8WeAMMAAAQC05dapC//rX9l/sb9fu4nMa3zTdGjfuId15559UUlKshQvn66KLEtSv33WSpEsuuVTr13+gxMRL1LRpM23f/k+tWLFMDodDpaWl1d6OYRgaN26i7r47TQsWPKvx4x/XgAE3au3a1RozZqTuvPNPiouLV07OFq1c+ZIGD75NQUFBuuCCVrrxxkF64YUFqqysVPv2iVq37j3t3bvnnPb7bBGAAQAAasmxY8d0333DfrH/xRdXntP4ffpcpbi4eE2dOklut1tXXNFb6emPeC9Wy8iYotmzn9acOU9Lklq1aq1x4yZq3br3vReoVVe7dhfr1ltv16pVK9Sv33VKTu6qv/zlBS1cOF8LFszViRPHFR/fXPfd94D+8Ic073qPPPKoYmOb6LXXVsvlKtFvfvNb3Xnnn/TCC8+d076fDYenOue7IbfbVGHhiVrfblCQoejoBtpxxxDmAJ+jiMREJa1crqKiE6qsNK0uBwBQz5w6VaFjxw4rNra5goNDrC6n3vm19zcmpoGczurN7mUOMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFRyEDAAAEEMNwyDActb5d0/TINGv2gOD169/XmjWv6rvvvpXD4dCFF7bVwIE36eabB/u5Sv8gAAMAAAQIw3AounG4DKez1rdtut0qKi496xD8zjtv6tlns/TQQ2PVqVOyJI8+/3yznn02S0VFhRo27J7zUu+5IAADAAAECMNwyHA69V3GJJXt219r2w1r20YXPTlNhuE46wD8+utrdP31N2ngwJu8ba1bt9GRI0e0evUrBGAAAAD8urJ9+3Vy1y6ry6gWw3DoX//aJpfLpaioKG97WtpQXX/9jRZW9ssC6iK4ffv2qUuXLnrttde8bTt37lRaWpqSk5OVmpqql19+2Wcd0zQ1d+5c9e7dW8nJybrnnnt06NCh2i4dAADAlm6//U7t3p2rQYOu07hxD2nFimXaufMbRUZGqnXrC60u74wCJgCfOnVKY8eO1cmTJ71tRUVFGjZsmFq3bq21a9dq1KhRysrK0tq1a73LLFiwQNnZ2Zo2bZpWrVol0zQ1fPhwVVRUWLEbAAAAtnLVVVdrwYIl6tXrSn3zzb+0cOF83XPPXbr99sHatu1rq8s7o4CZAjFv3jxFRkb6tK1evVrBwcGaOnWqgoKClJCQoAMHDmjRokUaPHiwKioqtHTpUo0dO1Z9+/aVJM2ZM0e9e/fW+vXrNXDgQAv2BAAAwF46drxMHTteJtM09e23u7Vp02dau3a1xo59SK+++rqio2OsLtFHQJwBzsnJ0auvvqoZM2b4tG/dulXdu3dXUNC/c3qPHj20f/9+HT16VLm5uTpx4oR69uzp7Y+KilJSUpJycnJqrX4AAAA7KijI16xZT6mgIF+SZBiG2rfvoLvuulvPPLNAJ0+e0Ndff2lxlVVZHoBdLpfGjx+vjIwMNW/e3KcvLy9P8fHxPm3NmjWTJB0+fFh5eXmSVGW9Zs2aefsAAABwfoSEhOrtt1/X+vXvV+lr2LChJCkmJra2y/pVlk+BmDx5srp06aIbbrihSl9ZWZlCQkJ82kJDQyVJ5eXlKi0tlaQzLlNSUuL3WoOCav/zgtNp+WeUeof3FABwPphm7T+8wmqNGzfWHXfcpRdeeE4nTpxQaurViohooP3792nZssXq2rWbOnfu4tdtOp2Oc85klgbgN954Q1u3btXbb799xv6wsLAqF7OVl5dLkiIiIhQWFiZJqqio8H59epnw8HC/1moYDkVHN/DrmLBGVJR/fzcAAJCksjKnjh41zimgnT5JE9a2jR8r+3Wnt1eTk0T33z9KF154od588zW9/vpfVVZWpvj45rr66n66664/+e0Eomk6ZBiGGjWK8Ml9NWFpAF67dq2OHTvmvYDttCeeeELvvfee4uPjVVBQ4NN3+vu4uDhVVlZ621q3bu2zTGJiol9rNU2PXK6Tv76gnzmdBoHNz1yuUrndptVlAADqmYqKcpmmKbfbo8rKmv0/Y5oemW63Lnpymp+rq8a23W6dOuWu0eOQ+/UboH79Bpyxr6bvxf/ldntkmqZKSk6qtNRdpT8qKrzaAd7SAJyVlaWysjKftn79+ik9PV033nij3nzzTa1atUput1vO//dIwM2bN6tt27aKjY1Vw4YNFRkZqS1btngDsMvl0o4dO5SWlub3ev31A4S13G6TnyUAwO/c7rMPjv+XaXpUVFwqw6j96RSm6alR+K1t5/IB4zRLA3BcXNwZ22NjYxUXF6fBgwdr8eLFevzxxzV8+HBt27ZNy5Yt05QpUyT9PPc3LS1NWVlZiomJUcuWLTVz5kzFx8erX79+tbkrAAAAflFXgmhdZvlFcP9NbGysFi9erMzMTA0aNEhNmzbV+PHjNWjQIO8y6enpqqysVEZGhsrKypSSkqIlS5YoODjYwsoBAAAQqBwej4ePGNXgdpsqLDxR69sNCjIUHd1AO+4YUmeeCR6oIhITlbRyuYqKTjAFAgDgd6dOVejYscOKjW2u4OCQX18BZ+XX3t+YmAbVngPM/aAAAABgKwRgAAAA2AoBGAAAALZCAAYAAICtEIABAABgKwF9GzQAAAC7MQwHD8I4zwjAAAAAAcIwHGrcOKLat/PyJ7fbVHHxyRqF4MrKSr322l+1bt17OnjwgEJDQ3TxxYkaMmSYunbtdh6qPTcEYAAAgABhGA45nYae+utmHTriqrXttmoapQm39JBhOM46AJeXl2vMmFHKz8/T8OH3qWPHTiovL9e7776l0aNHKiNjqvr163+eKq8ZAjAAAECAOXTEpW8PF1ldRrUsWbJQe/fu0csvv6q4uHhv+0MPPaITJ47r2WdnqlevPoqIiLCwSl8EYAAAANRIZWWl3nnnLQ0YcKNP+D1txIiRGjTo9woNDbWgul9GAAYAAECN/Pjj93K5SnTZZZ3P2N+kSVM1adK0lqv6ddwGDQAAADXicv08T7lhw4YWV3J2CMAAAACokcaNoyVJLleJxZWcHQIwAAAAaqRFi5aKiYnV9u3/PGP//v37NGbMKH333d5aruy/IwADAACgRgzD0PXX36j33ntH+fl5Vfqzs1/Wzp071Lx5Cwuq+2UEYAAAANTYXXfdrVatWmvkyOH64IN39cMP32vnzm80ffoUffDBu5ow4XGFh4dbXaYP7gIBAAAQYFo1jaoz2wsLC9P8+Yv0yivLtWLFS8rPP6zQ0DC1b99B8+Y9r86du/ixUv8gAAMAAAQI0/TI7TY14ZYetb5tt9us0WOQJSk8PFx/+tMI/elPI/xc1flBAAYAAAgQpulRcfFJGYbDkm3XNADXNQRgAACAAGKnIGoVLoIDAACArRCAAQAAYCsEYAAAANgKARgAAAC2QgAGAACArRCAAQAAYCsEYAAAANgK9wEGAAAIIIbh4EEY5xkBGAAAIEAYhkONo8PlNJy1vm236VZxUWmNQnBFRYXWrFmlDz/8QN9//71CQoLVrl17/e53t+jKK1PPQ7XnhgAMAAAQIAzDIafh1F8+nacfSn6ote22bNRSo3o9KMNwnHUAPnnyhNLT71dJSYnuvnuEOnVKVmlpqf7+9480efLjuuGGm/XwwxPOU+U1QwAGAAAIMD+U/KD9hfutLqNa5s9/RseOHdXSpSsVHR3tbU9IaKdLLrlU48ePVqdOybr66mstrNIXF8EBAACgRo4fP64PPnhXf/xjmk/4Pe23v+2lyy/vrtWrX7Ggul9GAAYAAECN7Nz5L1VUVKhTp+RfXKZbtxTt3PmNKisra6+wX0EABgAAQI0UFxdLkiIjG/7iMo0aNZbH4/EuGwgIwAAAAKiRxo1/nvbgcpX84jKn+yIjI2ulpuqwPAAfO3ZM48aNU48ePdSlSxeNGDFCe/fu9fZnZGQoMTHR55Wa+u/baZimqblz56p3795KTk7WPffco0OHDlmxKwAAALZyySWXKiQkVF9//eUvLvPVV18qIaGdwsLCarGy/87yADxq1CgdOHBAixYt0po1axQWFqahQ4eqtLRUkrRr1y7dd999+vTTT72vNWvWeNdfsGCBsrOzNW3aNK1atUqmaWr48OGqqKiwapcAAABsITIyUgMG3KBVq1bq6NGjkn4+OZmWdosWLJirjRv/rs8/36TBg2+ztM7/y9IAXFJSopYtW+rJJ59Up06dlJCQoJEjR6qgoEB79uyRx+PRt99+q44dO6pp06beV0xMjKSfb7q8dOlSpaenq2/fvurQoYPmzJmjvLw8rV+/3spdAwAAsIVRox5Sy5YX6L77humDD95VXt5h3Xnn3XrzzbV67LGxuuyyzrrhhputLtOHpfcBbtSokWbNmuX9vrCwUMuWLVN8fLzatWungwcP6uTJk7rooovOuH5ubq5OnDihnj17etuioqKUlJSknJwcDRw48LzvAwAAgL+1bNSyzmwvPDxc8+Y9r9deW63Vq7M1a9YMOZ1BSki4WJ07d9Fbb72miRPH6pFHHlWTJk39WHXNBcyDMCZNmqTVq1crJCREzz33nCIiIrR7925J0vLly/XJJ5/IMAz16dNHY8aMUcOGDZWXlydJat68uc9YzZo18/YBAADUFabpkdt0a1SvB2t9227TXaPHIEtSUFCQbr31dt166+1V+v7whzv01ltvqEGDwLkILmAC8F133aXbbrtNK1eu1KhRo5Sdna3du3fLMAw1a9ZMCxcu1MGDB/X0009rz549eumll7zzhENCQnzGCg0NVUnJL1+NWFNBQbU/Y8TptHyadr3DewoAOB9M0+GHMTwqLiqVYZz7WDXZdk0D8H/TqFFjDRky1G/jOZ2Oc85kAROA27VrJ0nKzMzUP//5T61YsUKZmZm6/fbbvU8Wad++vZo2bapbb71V27dv915NWFFR4XNlYXl5ucLDw/1an2E4FB3dwK9jwhpRUf793QAAQJLKypw6etTwS0CzgmE4LAne1WWaDhmGoUaNIs75jhKWBuDCwkJt2rRJ1157rYKCfi7FMAy1a9dOBQUFMgyjymP1Lr74YklSXl6ed+pDQUGBWrdu7V2moKBAiYmJfq3VND1yuU76dczqcDoNApufuVylcrtNq8sAANQzFRXlMk1TbrdHlZX8P+NvbrdHpmmqpOSkSkvdVfqjosKr/VdeSwPw0aNH9fDDD2vx4sXq3bu3JOnUqVPasWOHUlNTNX78eBUUFGjZsmXedbZv3y7p5zPGrVq1UmRkpLZs2eINwC6XSzt27FBaWprf6+WXuX5wu01+lgAAv3O7/T99AFX54wOGpefn27dvrz59+ujJJ59UTk6Odu/erUcffVQul0tDhw7Vtddeq02bNmn+/Pk6ePCgPv74Y02cOFEDBw5UQkKCQkJClJaWpqysLH300UfKzc3VmDFjFB8fr379+lm5awAAAAhQls8Bnj17tmbNmqUxY8bop59+Urdu3bRy5Uq1aNFCLVq00DPPPKNFixbphRdeUMOGDXXDDTdo9OjR3vXT09NVWVmpjIwMlZWVKSUlRUuWLFFwcLB1OwUAAGzL4+FM8Pngz/fV4eGnVC1ut6nCwhO1vt2gIEPR0Q20444hOrlrV61vvz6JSExU0srlKio6wRQIAIDfmaZbBQXfKzIyWpGRUVaXU+8cP+7S8eNFataslQyj6iSGmJgGdWMOMAAAQH1hGE6Fh0fq+PEiSVJISKgcjsC9q0Jd4fF4VFFRruPHixQeHnnG8Hu2CMAAAAB+EhUVI0neEAz/CQ+P9L6/54oADAAA4CcOh0ONGsWqYcNoud2VVpdTbzidQX4583saARgAAMDPDMOQYYT8+oKwRN17TAkAAABwDgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbsTwAHzt2TOPGjVOPHj3UpUsXjRgxQnv37vX279y5U2lpaUpOTlZqaqpefvlln/VN09TcuXPVu3dvJScn65577tGhQ4dqezcAAABQR1gegEeNGqUDBw5o0aJFWrNmjcLCwjR06FCVlpaqqKhIw4YNU+vWrbV27VqNGjVKWVlZWrt2rXf9BQsWKDs7W9OmTdOqVatkmqaGDx+uiooKC/cKAAAAgSrIyo2XlJSoZcuWuvfee9W+fXtJ0siRI3XTTTdpz5492rRpk4KDgzV16lQFBQUpISHBG5YHDx6siooKLV26VGPHjlXfvn0lSXPmzFHv3r21fv16DRw40MK9AwAAQCCy9Axwo0aNNGvWLG/4LSws1LJlyxQfH6927dpp69at6t69u4KC/p3Te/Toof379+vo0aPKzc3ViRMn1LNnT29/VFSUkpKSlJOTU+v7AwAAgMBn6Rng/zRp0iStXr1aISEheu655xQREaG8vDxvOD6tWbNmkqTDhw8rLy9PktS8efMqy5zu86egoNr/vOB0Wj5Lpd7hPQUAwN4CJgDfdddduu2227Ry5UqNGjVK2dnZKisrU0hIiM9yoaGhkqTy8nKVlpZK0hmXKSkp8Wt9huFQdHQDv44Ja0RFhVtdAgAAsFDABOB27dpJkjIzM/XPf/5TK1asUFhYWJWL2crLyyVJERERCgsLkyRVVFR4vz69THi4f0OOaXrkcp3065jV4XQaBDY/c7lK5XabVpcBAAD8KCoqvNp/5bU0ABcWFmrTpk269tprvfN8DcNQu3btVFBQoPj4eBUUFPisc/r7uLg4VVZWettat27ts0xiYqLf662sJDTVB263yc8SAAAbs3Qy5NGjR/Xwww9r06ZN3rZTp05px44dSkhIUEpKir744gu53W5v/+bNm9W2bVvFxsaqQ4cOioyM1JYtW7z9LpdLO3bsUEpKSq3uCwAAAOoGSwNw+/bt1adPHz355JPKycnR7t279eijj8rlcmno0KEaPHiwjh8/rscff1zffvutXnvtNS1btkz33nuvpJ/n/qalpSkrK0sfffSRcnNzNWbMGMXHx6tfv35W7hoAAAAClOVzgGfPnq1Zs2ZpzJgx+umnn9StWzetXLlSLVq0kCQtXrxYmZmZGjRokJo2barx48dr0KBB3vXT09NVWVmpjIwMlZWVKSUlRUuWLFFwcLBVuwQAAIAA5vB4PB6ri6gL3G5ThYUnan27QUGGoqMbaMcdQ3Ry165a3359EpGYqKSVy1VUdII5wAAA1DMxMQ2qfREcN0QFAACArRCAAQAAYCsEYAAAANgKARgAAAC2QgAGAACArRCAAQAAYCsEYAAAANgKARgAAAC2QgAGAACArRCAAQAAYCsEYAAAANgKARgAAAC2QgAGAACArRCAAQAAYCsEYAAAANgKARgAAAC2QgAGAACArRCAAQAAYCsEYAAAANgKARgAAAC2QgAGAACArRCAAQAAYCsEYAAAANgKARgAAAC2QgAGAACArRCAAQAAYCsEYAAAANgKARgAAAC2QgAGAACArRCAAQAAYCsEYAAAANgKARgAAAC2QgAGAACArRCAAQAAYCsEYAAAANiK5QG4uLhY//u//6s+ffqoa9eu+uMf/6itW7d6+4cNG6bExESf15AhQ7z95eXlmjJlinr27KkuXbrokUceUWFhoRW7AgAAgDogyOoCHn74YR05ckSzZ89WbGysli9frrvvvluvv/66LrroIu3atUuTJ0/W1Vdf7V0nODjY+/XkyZO1detWzZs3TyEhIXriiSeUnp6uFStWWLE7AAAACHCWBuADBw7os88+U3Z2ti6//HJJ0qRJk7Rx40a9/fbbSktL07Fjx9S5c2c1bdq0yvr5+fl64403tHDhQnXr1k2SNHv2bPXv319fffWVunTpUqv7AwAAgMBn6RSI6OhoLVq0SJdddpm3zeFwyOFwyOVyadeuXXI4HGrbtu0Z1//iiy8kST169PC2tW3bVnFxccrJyTm/xQMAAKBOsvQMcFRUlK688kqftnXr1unAgQOaOHGidu/erYYNG2rq1Kn67LPPFBERof79+2vkyJEKCQlRfn6+oqOjFRoa6jNGs2bNlJeX5/d6g4Jq//OC02n5NO16h/cUAAB7s3wO8H/68ssv9dhjj6lfv37q27evJk6cqPLycnXq1EnDhg3Tzp079fTTT+vHH3/U008/rdLSUoWEhFQZJzQ0VOXl5X6tzTAcio5u4NcxYY2oqHCrSwAAABYKmAC8YcMGjR07Vl27dlVWVpYkaerUqZowYYIaNWokSWrfvr2Cg4M1ZswYjR8/XmFhYaqoqKgyVnl5ucLD/RtyTNMjl+ukX8esDqfTILD5mctVKrfbtLoMAADgR1FR4dX+K29ABOAVK1YoMzNT/fv311NPPeU9qxsUFOQNv6ddfPHFkqS8vDzFx8eruLhYFRUVPmeCCwoKFBcX5/c6KysJTfWB223yswQAwMYsnwyZnZ2tadOm6Y477tDs2bN9guyQIUP02GOP+Sy/fft2BQcHq02bNrr88stlmqb3YjhJ2rdvn/Lz85WSklJr+wAAAIC6w9IzwPv27dP06dN1zTXX6N5779XRo0e9fWFhYbr22ms1ffp0derUSb169dL27dv19NNP6+6771ZkZKQiIyN1/fXXKyMjQ9OnT1d4eLieeOIJde/eXcnJydbtGAAAAAKWpQF43bp1OnXqlD788EN9+OGHPn2DBg3SjBkz5HA4tHz5ck2fPl1NmzbV0KFDNWLECO9y06ZN0/Tp0/XAAw9Ikvr06aOMjIxa3Q8AAADUHQ6Px+M525VycnKUlJSkBg2q3hXB5XJp48aNuv766/1SYKBwu00VFp6o9e0GBRmKjm6gHXcM0cldu2p9+/VJRGKiklYuV1HRCeYAAwBQz8TENKj2RXA1mgN85513au/evWfs27FjR5V5uwAAAECgqPYUiAkTJujw4cOSJI/Ho8mTJysyMrLKcvv371eTJk38VyEAAADgR9U+A3zttdfK4/HoP2dMnP7+9MswDCUnJ+vPf/7zeSkWAAAAOFfVPgOcmpqq1NRUST/fnmzy5MlKSEg4b4UBAAAA50ON7gKxfPlyf9cBAAAA1IoaBeCysjI999xz+tvf/qbS0lKZpu8V9Q6HQxs2bPBLgQAAAIA/1SgAZ2Zmas2aNerevbsuueQSGYblD5QDAAAAqqVGAXj9+vUaM2aMzwMpAAAAgLqgRqduT506pU6dOvm7FgAAAOC8q1EA7tWrlz755BN/1wIAAACcdzWaAjFgwAA98cQTKiwsVOfOnRUeHl5lmZtvvvlcawMAAAD8rkYBePTo0ZKkN954Q2+88UaVfofDQQAGAABAQKpRAP7oo4/8XQcAAABQK2oUgFu2bOnvOgAAAIBaUaMAPH/+/F9d5oEHHqjJ0AAAAMB55fcAHBkZqWbNmhGAAQAAEJBqFIBzc3OrtJ08eVJbt27V5MmTNWnSpHMuDAAAADgf/PYM44iICPXp00ejRo3S008/7a9hAQAAAL/yWwA+rUWLFtq7d6+/hwUAAAD8okZTIM7E4/EoLy9Pixcv5i4RAAAACFg1CsAdOnSQw+E4Y5/H42EKBAAAAAJWjQLwqFGjzhiAIyMj1bdvX7Vp0+Zc6wIAAADOixoF4AcffNDfdQAAAAC1osZzgAsLC7V06VJ9/vnncrlcio6OVrdu3TR06FDFxsb6s0YAQD1jGA4Zxpmn0uHsmKZHpumxugygTqlRAM7Ly9Ntt92mwsJCJScnKykpSUeOHNGLL76oN954Q2vWrFFcXJy/awUA1AOG4VB043AZTqfVpdQLptutouJSQjBwFmoUgGfOnKmgoCC99957atWqlbf90KFD+tOf/qQ5c+ZoxowZfisSAFB/GIZDhtOp7zImqWzffqvLqdPC2rbRRU9Ok2E4CMDAWahRAP700081ceJEn/ArSa1ateJBGACAainbt18nd+2yugwANlSjB2G43W5FR0efsS8mJkbHjx8/p6IAAACA86VGATgxMVFvv/32GfvefPNNtW/f/pyKAgAAAM6XGk2BGDlypO6++26VlJRowIABatq0qY4cOaJ3331Xn376qebOnevvOgEAAAC/qFEAvuKKKzRjxgxlZWXpk08+8bY3bdpUf/7zn3XNNdf4rUAAAADAn2p8H+CCggIlJSVpwoQJKikpUW5urubNm8f8XwAAAAS0GgXgpUuX6plnnlFaWpoSEhIkSc2bN9d3332nGTNmKDQ0VLfccotfCwUAAAD8oUYBeNWqVRo9erRGjBjhbWvevLkyMjLUpEkTLVu2jAAMAACAgFSju0Dk5+frsssuO2Nf586d9f33359TUQAAAMD5UqMA3LJlS23atOmMfTk5OYqPj6/2WMXFxfrf//1f9enTR127dtUf//hHbd261du/adMm/e53v1Pnzp3Vv39/vfvuuz7rl5eXa8qUKerZs6e6dOmiRx55RIWFhTXZLQAAANhAjaZA3HrrrZo5c6ZOnTqlq6++WrGxsSosLNTf/vY3vfjii3rkkUeqPdbDDz+sI0eOaPbs2YqNjdXy5ct199136/XXX5fH49G9996rYcOGaebMmfr73/+u8ePHKyYmRj179pQkTZ48WVu3btW8efMUEhKiJ554Qunp6VqxYkVNdg0AAAD1XI0C8NChQ5Wfn6/ly5dr2bJl3nan06m77rpLw4YNq9Y4Bw4c0Geffabs7GxdfvnlkqRJkyZp48aNevvtt3Xs2DElJiZqzJgxkqSEhATt2LFDixcvVs+ePZWfn6833nhDCxcuVLdu3SRJs2fPVv/+/fXVV1+pS5cuNdk9AAAA1GM1vg3ahAkTNHLkSH399dcqLi5WVFSUOnXq9IuPSD6T6OhoLVq0yGc+scPhkMPhkMvl0tatW3X11Vf7rNOjRw9lZmbK4/Hoiy++8Lad1rZtW8XFxSknJ4cADAAAgCpqHIAlqWHDhurdu3eN14+KitKVV17p07Zu3TodOHBAEydO1Ouvv15lPnGzZs1UWlqqoqIi5efnKzo6WqGhoVWWycvLq3FdvyQoqEZTps+J01n726zveE8Ba/Fv0P94T4Gzc04B2N++/PJLPfbYY+rXr5/69u2rsrIyhYSE+Cxz+vuKigqVlpZW6Zek0NBQlZeX+7U2w3AoOrqBX8eENaKiwq0uAQD8iuMacHYCJgBv2LBBY8eOVdeuXZWVlSXp5yBbUVHhs9zp78PDwxUWFlalX/r5zhDh4f49GJimRy7XSb+OWR1Op8GBzc9crlK53abVZQC2xXHN/ziuAT9/EKzuX0MCIgCvWLFCmZmZ6t+/v5566invWd3mzZuroKDAZ9mCggJFRESoYcOGio+PV3FxsSoqKnzOBBcUFCguLs7vdVZWcnCpD9xuk58lgHqF4xpwdiyfNJSdna1p06bpjjvu0OzZs32CbLdu3fT555/7LL9582Z17dpVhmHo8ssvl2ma3ovhJGnfvn3Kz89XSkpKre0DAAAA6g5LA/C+ffs0ffp0XXPNNbr33nt19OhRHTlyREeOHNFPP/2kIUOGaNu2bcrKytLevXu1dOlSffDBBxo+fLgkKS4uTtdff70yMjK0ZcsWbdu2TQ8//LC6d++u5ORkK3cNAAAAAcrSKRDr1q3TqVOn9OGHH+rDDz/06Rs0aJBmzJihBQsWaObMmXrppZd0wQUXaObMmd6HYEjStGnTNH36dD3wwAOSpD59+igjI6NW9wMAAAB1h8Pj8XisLqIucLtNFRaeqPXtBgUZio5uoB13DNHJXbtqffv1SURiopJWLldR0QnmygEW4rjmPxzXgH+LiWlQ7YvgLJ8DDAAAANQmAjAAAABshQAMAAAAWyEAAwAAwFYIwAAAALAVAjAAAABshQAMAAAAWyEAAwAAwFYIwAAAALAVAjAAAABshQAMAAAAWyEAAwAAwFYIwAAAALAVAjAAAABshQAMAAAAWyEAAwAAwFYIwAAAALAVAjAAAABshQAMAAAAWyEAAwAAwFYIwAAAALAVAjAAAABshQAMAAAAWyEAAwAAwFYIwAAAALAVAjAAAABshQAMAAAAWyEAAwAAwFYIwAAAALAVAjAAAABshQAMAAAAWyEAAwAAwFYIwAAAALAVAjAAAABshQAMAAAAWwmoAPz8889ryJAhPm0ZGRlKTEz0eaWmpnr7TdPU3Llz1bt3byUnJ+uee+7RoUOHart0AAAA1BEBE4BXrlypZ555pkr7rl27dN999+nTTz/1vtasWePtX7BggbKzszVt2jStWrVKpmlq+PDhqqioqMXqAQAAUFdYHoDz8/N13333KSsrS23atPHp83g8+vbbb9WxY0c1bdrU+4qJiZEkVVRUaOnSpUpPT1ffvn3VoUMHzZkzR3l5eVq/fr0FewMAAIBAZ3kA/uabbxQcHKy33npLnTt39uk7ePCgTp48qYsuuuiM6+bm5urEiRPq2bOnty0qKkpJSUnKyck5r3UDAACgbgqyuoDU1FSfOb3/affu3ZKk5cuX65NPPpFhGOrTp4/GjBmjhg0bKi8vT5LUvHlzn/WaNWvm7QMAAAD+k+UB+L/ZvXu3DMNQs2bNtHDhQh08eFBPP/209uzZo5deekmlpaWSpJCQEJ/1QkNDVVJS4vd6goJq/4S502n5Sfp6h/cUsBb/Bv2P9xQ4OwEdgO+//37dfvvtio6OliS1b99eTZs21a233qrt27crLCxM0s9zgU9/LUnl5eUKDw/3ay2G4VB0dAO/jglrREX593cDAKzGcQ04OwEdgA3D8Ibf0y6++GJJUl5ennfqQ0FBgVq3bu1dpqCgQImJiX6txTQ9crlO+nXM6nA6DQ5sfuZylcrtNq0uA7Atjmv+x3EN+PmDYHX/GhLQAXj8+PEqKCjQsmXLvG3bt2+XJLVr106tWrVSZGSktmzZ4g3ALpdLO3bsUFpamt/rqazk4FIfuN0mP0sA9QrHNeDsBPSkoWuvvVabNm3S/PnzdfDgQX388ceaOHGiBg4cqISEBIWEhCgtLU1ZWVn66KOPlJubqzFjxig+Pl79+vWzunwAAAAEoIA+A/w///M/euaZZ7Ro0SK98MILatiwoW644QaNHj3au0x6eroqKyuVkZGhsrIypaSkaMmSJQoODraucAAAAASsgArAM2bMqNJ23XXX6brrrvvFdZxOp8aNG6dx48adz9IAAABQTwT0FAgAAADA3wjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbCagA/Pzzz2vIkCE+bTt37lRaWpqSk5OVmpqql19+2affNE3NnTtXvXv3VnJysu655x4dOnSoNssGAABAHRIwAXjlypV65plnfNqKioo0bNgwtW7dWmvXrtWoUaOUlZWltWvXepdZsGCBsrOzNW3aNK1atUqmaWr48OGqqKio5T0AAABAXRBkdQH5+fl64okntGXLFrVp08anb/Xq1QoODtbUqVMVFBSkhIQEHThwQIsWLdLgwYNVUVGhpUuXauzYserbt68kac6cOerdu7fWr1+vgQMH1v4OAQAAIKBZfgb4m2++UXBwsN566y117tzZp2/r1q3q3r27goL+ndN79Oih/fv36+jRo8rNzdWJEyfUs2dPb39UVJSSkpKUk5NTa/sAAACAusPyM8CpqalKTU09Y19eXp7at2/v09asWTNJ0uHDh5WXlydJat68eZVlTvf5U1BQ7X9ecDot/4xS7/CeAtbi36D/8Z4CZ8fyAPzflJWVKSQkxKctNDRUklReXq7S0lJJOuMyJSUlfq3FMByKjm7g1zFhjaiocKtLAAC/4rgGnJ2ADsBhYWFVLmYrLy+XJEVERCgsLEySVFFR4f369DLh4f49GJimRy7XSb+OWR1Op8GBzc9crlK53abVZQC2xXHN/ziuAT9/EKzuX0MCOgDHx8eroKDAp+3093FxcaqsrPS2tW7d2meZxMREv9dTWcnBpT5wu01+lgDqFY5rwNkJ6ElDKSkp+uKLL+R2u71tmzdvVtu2bRUbG6sOHTooMjJSW7Zs8fa7XC7t2LFDKSkpVpQMAACAABfQAXjw4ME6fvy4Hn/8cX377bd67bXXtGzZMt17772Sfp77m5aWpqysLH300UfKzc3VmDFjFB8fr379+llcPQAAAAJRQE+BiI2N1eLFi5WZmalBgwapadOmGj9+vAYNGuRdJj09XZWVlcrIyFBZWZlSUlK0ZMkSBQcHW1g5AAAAAlVABeAZM2ZUaevUqZNeffXVX1zH6XRq3LhxGjdu3PksDQCAgMVt0M6daXpkmh6ry0AtCagADAAAqi8oNlZu08NdNfzA7TZVXHySEGwTBGAAAOqooIaRchoOPfXXzTp0xGV1OXVWq6ZRmnBLDxmGgwBsEwRgAADquENHXPr2cJHVZQB1BpOGAAAAYCsEYAAAANgKARgAAAC2QgAGAACArRCAAQAAYCsEYAAAANgKARgAAAC2QgAGAACArRCAAQAAYCsEYAAAANgKARgAAAC2QgAGAACArRCAAQAAYCtBVhcA1Dank89958o0PTJNj9VlAABQIwRg2EZQbKzcpkdRUeFWl1Lnud2miotPEoIBAHUSARi2EdQwUk7Doaf+ulmHjrisLqfOatU0ShNu6SHDcBCAAQB1EgEYtnPoiEvfHi6yugwAAGARJkMCAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGyFAAwAAABbIQADAADAVgjAAAAAsBUCMAAAAGylTgTg/Px8JSYmVnm99tprkqSdO3cqLS1NycnJSk1N1csvv2xxxQAAAAhUQVYXUB25ubkKDQ3Vhg0b5HA4vO0NGzZUUVGRhg0bptTUVE2ZMkVff/21pkyZogYNGmjw4MEWVg0AAIBAVCcC8O7du9WmTRs1a9asSt9LL72k4OBgTZ06VUFBQUpISNCBAwe0aNEiAjAAAACqqBNTIHbt2qWEhIQz9m3dulXdu3dXUNC/s3yPHj20f/9+HT16tLZKBAAAQB1RZ84AR0dH64477tC+fft04YUX6v7771efPn2Ul5en9u3b+yx/+kzx4cOH1aRJE7/VERRU+58XnM468RkFNsTvJmqK3x0EKn437SPgA3BlZaW+++47tWvXTo8++qgiIyP17rvvasSIEXrxxRdVVlamkJAQn3VCQ0MlSeXl5X6rwzAcio5u4LfxgLouKirc6hIAwK84rtlHwAfgoKAgbdmyRU6nU2FhYZKkjh07as+ePVqyZInCwsJUUVHhs87p4BsREeG3OkzTI5frpN/Gqy6n0+AfJAKSy1Uqt9u0ugzUQRzXEKg4rtVtUVHh1T6LH/ABWJIaNKh65vXiiy/Wp59+qvj4eBUUFPj0nf4+Li7Or3VUVvKPAoB/maZHpumxugwAktxuk//rbSLgA/CePXt022236bnnntNvfvMbb/u//vUvtWvXTpdccolWrVolt9stp9MpSdq8ebPatm2r2NhYq8oG6q3oyDCZpskZPD9xm24VF5USggGgFgV8AE5ISNBFF12kqVOnasqUKYqOjtbq1av19ddfa+3atYqNjdXixYv1+OOPa/jw4dq2bZuWLVumKVOmWF06UC81CAuWYRj6y6fz9EPJD1aXU6e1bNRSo3o9KMNwEIABoBYFfAA2DEMLFy7UrFmzNHr0aLlcLiUlJenFF1/03v1h8eLFyszM1KBBg9S0aVONHz9egwYNsrhyoH77oeQH7S/cb3UZAACctYAPwJLUpEkT/fnPf/7F/k6dOunVV1+txYoAAABQV3HDOwAAANgKARgAAAC2QgAGAACArRCAAQAAYCsEYAAAANgKARgAAAC2QgAGAACArRCAAQAAYCsEYAAAANgKARgAAAC2QgAGAACArQRZXQAAAEAgcDo5L+gPpumRaXqsLuO/IgADAABbi44Mk2maiooKt7qUesFtulVcVBrQIZgADAAAbK1BWLAMw9BfPp2nH0p+sLqcOq1lo5Ya1etBGYaDAAwAABDofij5QfsL91tdBmoBk10AAABgKwRgAAAA2AoBGAAAALZCAAYAAICtEIABAABgKwRgAAAA2AoBGAAAALZCAAYAAICtEIABAABgKwRgAAAA2AoBGAAAALZCAAYAAICtEIABAABgKwRgAAAA2AoBGAAAALZCAAYAAICtEIABAABgKwRgAAAA2AoBGAAAALZCAAYAAICt1IsAbJqm5s6dq969eys5OVn33HOPDh06ZHVZAAAACED1IgAvWLBA2dnZmjZtmlatWiXTNDV8+HBVVFRYXRoAAAACTJ0PwBUVFVq6dKnS09PVt29fdejQQXPmzFFeXp7Wr19vdXkAAAAIMHU+AOfm5urEiRPq2bOnty0qKkpJSUnKycmxsDIAAAAEIofH4/FYXcS5WL9+vR588EH985//VFhYmLf9oYceUllZmZ5//nm/bMfj8cg0a/+tcjgkwzB0qrBQnsrKWt9+fWKEhiqoUSMVHy9Tpdu0upw6KzTYqYYRoSopK5Hb5HfyXDiNIDUKayTTNFW3j8Rnh+Oa/3Bc8w+Oa/5j5XHNMBxyOBzVWjboPNdy3pWWlkqSQkJCfNpDQ0NVUlLit+04HA45ndV7U8+H4JgYy7Zd3zSODPv1hfCrGoU1srqEesMw6vwf42qE45r/cFzzD45r/hPox7XArq4aTp/1/b8XvJWXlys8PNyKkgAAABDA6nwAbt68uSSpoKDAp72goEBxcXFWlAQAAIAAVucDcIcOHRQZGaktW7Z421wul3bs2KGUlBQLKwMAAEAgqvNzgENCQpSWlqasrCzFxMSoZcuWmjlzpuLj49WvXz+rywMAAECAqfMBWJLS09NVWVmpjIwMlZWVKSUlRUuWLFFwcLDVpQEAACDA1PnboAEAAABno87PAQYAAADOBgEYAAAAtkIABgAAgK0QgAEAAGArBGAAAADYCgEYAAAAtkIABgAAgK0QgAEAAGArBGAAAADYCgEYAAAAtkIABgAAgK0QgAEAAGArBGAgAJimqblz56p3795KTk7WPffco0OHDlldFgD4zfPPP68hQ4ZYXQYgiQAMBIQFCxYoOztb06ZN06pVq2SapoYPH66KigqrSwOAc7Zy5Uo988wzVpcBeBGAAYtVVFRo6dKlSk9PV9++fdWhQwfNmTNHeXl5Wr9+vdXlAUCN5efn67777lNWVpbatGljdTmAFwEYsFhubq5OnDihnj17etuioqKUlJSknJwcCysDgHPzzTffKDg4WG+99ZY6d+5sdTmAV5DVBQB2l5eXJ0lq3ry5T3uzZs28fQBQF6Wmpio1NdXqMoAqOAMMWKy0tFSSFBIS4tMeGhqq8vJyK0oCAKBeIwADFgsLC5OkKhe8lZeXKzw83IqSAACo1wjAgMVOT30oKCjwaS8oKFBcXJwVJQEAUK8RgAGLdejQQZGRkdqyZYu3zeVyaceOHUpJSbGwMgAA6icuggMsFhISorS0NGVlZSkmJkYtW7bUzJkzFR8fr379+lldHgAA9Q4BGAgA6enpqqysVEZGhsrKypSSkqIlS5YoODjY6tIAAKh3HB6Px2N1EQAAAEBtYQ4wAAAAbIUADAAAAFshAAMAAMBWCMAAAACwFQIwAAAAbIUADAAAAFshAAMAAMBWCMAAYLHdu3drzJgxuuKKK9SxY0f16tVLo0ePVm5ubq1sf968eUpMTKyVbT366KNKTU2tlW0BwC/hSXAAYKE9e/botttuU3JysjIyMhQbG6u8vDytWLFCt956q15++WUlJyef1xpuueUW9e7d+7xuAwACCQEYACz04osvKjo6Wi+88IKCgv59SL766qvVv39/LViwQIsWLTqvNcTHxys+Pv68bgMAAglTIADAQkePHpXH45Fpmj7tERERmjhxoq677jpJUmpqqh599FGfZV577TUlJibq+++/l/TzVIZrrrlG8+fPV/fu3dWrVy9lZGToiiuukNvt9lk3MzNTv/nNb3Tq1CmfKRALFy5Ux44dVVJS4rP8smXLdOmll+rYsWOSpB9//FEPP/ywunfvrs6dO+uuu+7Sjh07fNYpKSnRY489pu7duyslJUUzZ86ssp8AYAUCMABYqG/fvvrxxx/1hz/8QStXrtTevXvl8XgkSf3799egQYPOarwff/xRH3/8sebMmaPHHntMN998s44ePaotW7Z4lzFNU++//76uv/56BQcH+6x/ww03qLKyUuvXr/dpf/fdd9WrVy/FxsaqsLBQf/jDH/TNN99o0qRJmjVrlkzT1B133KG9e/d6tzF8+HB9/PHHmjBhgmbMmKEvv/xS7733Xk3eJgDwK6ZAAICFbr/9dh05ckRLlizR1KlTJUnR0dHq1auX7rzzTnXq1OmsxqusrNSECRPUrVs3SZLH41HLli31zjvv6Le//a0kacuWLTpy5IhuuummKuu3bNlSKSkpeuedd3TLLbdIkg4ePKht27Zpzpw5kqSXXnpJxcXFeuWVV9SyZUtJUp8+fTRgwAA9++yzmjt3rj755BNt27ZNL7zwgvr06SNJ6tmzJxfAAQgInAEGAIs99NBD2rhxo2bNmqXf//73ioyM1Ntvv+29CO5sXXLJJd6vHQ6HbrzxRm3YsEEVFRWSfj6b26ZNG3Xu3PmM6994443KycnRkSNHvMtHRkZ6w+umTZt0ySWXKC4uTpWVlaqsrJRhGOrTp4/+8Y9/SJK2bt2q4OBgn4vrIiIidOWVV571/gCAvxGAASAANGrUSAMHDlRmZqY2bNig119/XQkJCZo5c6aKiorOaqwGDRr4fH/TTTeppKREGzduVEVFhdavX68bb7zxF9fv37+/goKC9P7770v6OQBfe+21CgsLkyQVFxfr66+/1qWXXurzWrlypX766SeVlpaqpKREjRs3lsPh8Bm7adOmZ7UvAHA+MAUCACySn5+vwYMH66GHHvJONzgtKSlJY8aM0ahRo3To0CFJqnIh28mTJ6u1nbZt26pTp056//33ZRiGXC7Xfw3ADRs2VGpqqt5//3316NFDe/bs0aRJk3z6u3fvrvHjx59x/ZCQEEVHR6uoqEhut1tOp9PbV1xcXK2aAeB84gwwAFikSZMmCgoKUnZ2tsrLy6v0f/fddwoNDdWFF16oyMhI5eXl+fR/8cUX1d7WTTfdpI0bN+rdd99V165d1apVq19d/uuvv9Yrr7yiFi1aqHv37t6+7t27a9++fWrbtq0uu+wy7+vNN9/UmjVr5HQ61bNnT1VWVmrDhg3e9SoqKvTZZ59Vu2YAOF8IwABgEafTqcmTJ2v37t0aPHiwXnnlFX3++ef6+OOPNX36dD377LN64IEH1KhRI1111VXKycnR888/r82bN2v69OnavHlztbc1YMAAnThxQu+9994ZL377v3r37q3GjRvr1Vdf1Q033OAzlWHo0KEyTVNDhw7Ve++9p02bNmnSpElavny52rZtK+nnC95O34YtOztbH3/8se6//34VFhae/RsFAH7GFAgAsFDfvn21evVqLVmyRAsXLlRhYaFCQkKUlJSkOXPmqF+/fpKke++9V4WFhVqyZIlOnTqlvn37KjMzU/fff3+1thMTE6NevXrps88+U//+/X91+aCgIF1//fVavnx5lekScXFxWrVqlWbNmqXJkyervLxcbdq0UWZmpn7/+997l5s/f76ysrI0d+5clZeXa8CAAbr11lv10UcfncU7BAD+5/CcvuEkAAAAYANMgQAAAICtEIABAABgKwRgAAAA2AoBGAAAALZCAAYAAICtEIABAABgKwRgAAAA2AoBGAAAALZCAAYAAICtEIABAABgKwRgAAAA2AoBGAAAALby/wMQ4lp40Qi5mAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"darkgrid\")\n",
    "sns.countplot( x='Survived', data=train_df, hue=\"Embarked\", palette=\"Set1\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>445.357143</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>1.886905</td>\n",
       "      <td>30.814769</td>\n",
       "      <td>0.386905</td>\n",
       "      <td>0.363095</td>\n",
       "      <td>59.954144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>417.896104</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>2.909091</td>\n",
       "      <td>28.089286</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.168831</td>\n",
       "      <td>13.276030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>449.527950</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>2.350932</td>\n",
       "      <td>29.445397</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>27.079812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PassengerId  Survived    Pclass        Age     SibSp     Parch  \\\n",
       "Embarked                                                                   \n",
       "C          445.357143  0.553571  1.886905  30.814769  0.386905  0.363095   \n",
       "Q          417.896104  0.389610  2.909091  28.089286  0.428571  0.168831   \n",
       "S          449.527950  0.336957  2.350932  29.445397  0.571429  0.413043   \n",
       "\n",
       "               Fare  \n",
       "Embarked             \n",
       "C         59.954144  \n",
       "Q         13.276030  \n",
       "S         27.079812  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf=train_df.groupby('Embarked').mean('Embarked')\n",
    "tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2: Does survival depend upon gender?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>431.028662</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>2.159236</td>\n",
       "      <td>27.915709</td>\n",
       "      <td>0.694268</td>\n",
       "      <td>0.649682</td>\n",
       "      <td>44.479818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>454.147314</td>\n",
       "      <td>0.188908</td>\n",
       "      <td>2.389948</td>\n",
       "      <td>30.726645</td>\n",
       "      <td>0.429809</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>25.523893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId  Survived    Pclass        Age     SibSp     Parch  \\\n",
       "Sex                                                                      \n",
       "female   431.028662  0.742038  2.159236  27.915709  0.694268  0.649682   \n",
       "male     454.147314  0.188908  2.389948  30.726645  0.429809  0.235702   \n",
       "\n",
       "             Fare  \n",
       "Sex                \n",
       "female  44.479818  \n",
       "male    25.523893  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('Sex').mean('Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sajid/.local/lib/python3.10/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 580.875x900 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "FacetGrid = sns.FacetGrid(train_df, row='Embarked',  aspect=1.6)\n",
    "FacetGrid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', order=None, hue_order=None )\n",
    "FacetGrid.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### Embarked seems to be correlated with survival, depending on the gender.\n",
    "\n",
    "* ##### Women on port Q and on port S have a higher chance of survival. The inverse is true, if they are at port C. Men have a high survival probability if they are on port C, but a low probability if they are on port Q or S.\n",
    "\n",
    "* ##### Pclass also seems to be correlated with survival. We will generate another plot of it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11801/232030325.py:6: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  ax = sns.distplot(women[women['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[0], kde =False, color=\"green\")\n",
      "/tmp/ipykernel_11801/232030325.py:7: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  ax = sns.distplot(women[women['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[0], kde =False, color=\"red\")\n",
      "/tmp/ipykernel_11801/232030325.py:10: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  ax = sns.distplot(men[men['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[1], kde = False, color=\"green\")\n",
      "/tmp/ipykernel_11801/232030325.py:11: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  ax = sns.distplot(men[men['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[1], kde = False, color=\"red\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "survived = 'survived'\n",
    "not_survived = 'not survived'\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(16, 8))\n",
    "women = train_df[train_df['Sex']=='female']\n",
    "men = train_df[train_df['Sex']=='male']\n",
    "ax = sns.distplot(women[women['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[0], kde =False, color=\"green\")\n",
    "ax = sns.distplot(women[women['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[0], kde =False, color=\"red\")\n",
    "ax.legend()\n",
    "ax.set_title('Female')\n",
    "ax = sns.distplot(men[men['Survived']==1].Age.dropna(), bins=18, label = survived, ax = axes[1], kde = False, color=\"green\")\n",
    "ax = sns.distplot(men[men['Survived']==0].Age.dropna(), bins=40, label = not_survived, ax = axes[1], kde = False, color=\"red\")\n",
    "ax.legend()\n",
    "_ = ax.set_title('Male');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ##### You can see that men have a high probability of survival when they are between 18 and 30 years old, which is also a little bit true for women but not fully. For women the survival chances are higher between 14 and 40.\n",
    "\n",
    "* ##### For men the probability of survival is very low between the age of 5 and 18, but that isn’t true for women. Another thing to note is that infants also have a little bit higher probability of survival.\n",
    "\n",
    "* ##### Since there seem to be certain ages, which have increased odds of survival and because I want every feature to be roughly on the same scale, I will create age groups later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Pclass', y='Survived', data=train_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here we see clearly, that Pclass is contributing to a persons chance of survival, especially if this person is in class 1. We will create another pclass plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sajid/.local/lib/python3.10/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 972.222x900 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The plot above confirms our assumption about pclass 1, but we can also spot a high probability that a person in pclass 3 will not survive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `SibSp` and `Parch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SibSp and Parch would make more sense as a combined feature, that shows the total number of relatives, a person has on the Titanic. I will create it below and also a feature that sows if someone is not alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "travelled_alone\n",
       "Yes    537\n",
       "No     354\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n",
    "    dataset.loc[dataset['relatives'] > 0, 'travelled_alone'] = 'No'\n",
    "    dataset.loc[dataset['relatives'] == 0, 'travelled_alone'] = 'Yes'\n",
    "    #dataset['travelled_alone'] = dataset['travelled_alone'].astype(int)\n",
    "train_df['travelled_alone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "travelled_alone\n",
       "Yes    253\n",
       "No     165\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['travelled_alone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relatives\n",
       "0     537\n",
       "1     161\n",
       "2     102\n",
       "3      29\n",
       "5      22\n",
       "4      15\n",
       "6      12\n",
       "10      7\n",
       "7       6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['relatives'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here we can see that you had a high probabilty of survival with 1 to 3 realitves, but a lower one if you had less than 1 or more than 3 (except for some cases with 6 relatives)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'PassengerId' from the train set, because it does not contribute to a persons survival probability.\n",
    "train_df = train_df.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin:\n",
    "##### Cabin number looks like ‘C23’ and the letter refers to the deck. We will extract these and create a new feature, to represent a persons deck. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count         204\n",
       "unique        147\n",
       "top       B96 B98\n",
       "freq            4\n",
       "Name: Cabin, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Cabin'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "deck = {\"A\": \"A\", \"B\": \"B\", \"C\": \"C\", \"D\": \"D\", \"E\": \"E\", \"F\": \"F\", \"G\": \"G\", \"U\": \"U\"}\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n",
    "    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
    "    dataset['Deck'] = dataset['Deck'].map(deck)\n",
    "    dataset['Deck'] = dataset['Deck'].fillna(\"U\")\n",
    "    #dataset['Deck'] = dataset['Deck'].astype(int)\n",
    "# we can now drop the cabin feature\n",
    "train_df = train_df.drop(['Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deck\n",
       "U    688\n",
       "C     59\n",
       "B     47\n",
       "D     33\n",
       "E     32\n",
       "A     15\n",
       "F     13\n",
       "G      4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Deck'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>relatives</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deck</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.833333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>39.623887</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.744681</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.955556</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>113.505764</td>\n",
       "      <td>0.936170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.593220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.086667</td>\n",
       "      <td>0.644068</td>\n",
       "      <td>0.474576</td>\n",
       "      <td>100.151341</td>\n",
       "      <td>1.118644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.757576</td>\n",
       "      <td>1.121212</td>\n",
       "      <td>39.032258</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>57.244576</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>38.116667</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>46.026694</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>19.954545</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>18.696792</td>\n",
       "      <td>1.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>13.581250</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U</th>\n",
       "      <td>0.299419</td>\n",
       "      <td>2.636628</td>\n",
       "      <td>27.588208</td>\n",
       "      <td>0.546512</td>\n",
       "      <td>0.364826</td>\n",
       "      <td>19.181079</td>\n",
       "      <td>0.911337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Survived    Pclass        Age     SibSp     Parch        Fare  relatives\n",
       "Deck                                                                          \n",
       "A     0.466667  1.000000  44.833333  0.133333  0.133333   39.623887   0.266667\n",
       "B     0.744681  1.000000  34.955556  0.361702  0.574468  113.505764   0.936170\n",
       "C     0.593220  1.000000  36.086667  0.644068  0.474576  100.151341   1.118644\n",
       "D     0.757576  1.121212  39.032258  0.424242  0.303030   57.244576   0.727273\n",
       "E     0.750000  1.312500  38.116667  0.312500  0.312500   46.026694   0.625000\n",
       "F     0.615385  2.384615  19.954545  0.538462  0.538462   18.696792   1.076923\n",
       "G     0.500000  3.000000  14.750000  0.500000  1.250000   13.581250   1.750000\n",
       "U     0.299419  2.636628  27.588208  0.546512  0.364826   19.181079   0.911337"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('Deck').mean('Deck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deck\n",
       "U    327\n",
       "C     35\n",
       "B     18\n",
       "D     13\n",
       "E      9\n",
       "F      8\n",
       "A      7\n",
       "G      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Deck'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age:\n",
    "##### Fill null values with random numbers, which are computed based on the mean age value in regards to the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    mean = train_df[\"Age\"].mean()\n",
    "    std = test_df[\"Age\"].std()\n",
    "    is_null = dataset[\"Age\"].isnull().sum()\n",
    "    # compute random numbers between the mean, std and is_null\n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    # fill NaN values in Age column with random values generated\n",
    "    age_slice = dataset[\"Age\"].copy()\n",
    "    age_slice[np.isnan(age_slice)] = rand_age\n",
    "    dataset[\"Age\"] = age_slice\n",
    "    dataset[\"Age\"] = train_df[\"Age\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Age\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"Age\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean      29.491582\n",
       "std       13.524621\n",
       "min        0.000000\n",
       "25%       21.000000\n",
       "50%       28.000000\n",
       "75%       37.000000\n",
       "max       80.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"Age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df.groupby('Age').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     889\n",
       "unique      3\n",
       "top         S\n",
       "freq      644\n",
       "Name: Embarked, dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Embarked'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    S\n",
       "Name: Embarked, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Embarked'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common_value = train_df['Embarked'].mode()\n",
    "#common_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_value = 'S'\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     418\n",
       "unique      3\n",
       "top         S\n",
       "freq      270\n",
       "Name: Embarked, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Embarked'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fare: Convert from float to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(0)\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean      31.785634\n",
       "std       49.703730\n",
       "min        0.000000\n",
       "25%        7.000000\n",
       "50%       14.000000\n",
       "75%       31.000000\n",
       "max      512.000000\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Fare'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Fare'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    418.000000\n",
       "mean      35.100478\n",
       "std       55.872752\n",
       "min        0.000000\n",
       "25%        7.000000\n",
       "50%       14.000000\n",
       "75%       31.000000\n",
       "max      512.000000\n",
       "Name: Fare, dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Fare'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Fare'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Fare'] = train_df['Fare'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Fare'] = test_df['Fare'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name: Extract titles from name and build a new feature from that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_titles = train_df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "type(train_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name\n",
       "Mr          517\n",
       "Miss        182\n",
       "Mrs         125\n",
       "Master       40\n",
       "Dr            7\n",
       "Rev           6\n",
       "Mlle          2\n",
       "Major         2\n",
       "Col           2\n",
       "Countess      1\n",
       "Capt          1\n",
       "Ms            1\n",
       "Sir           1\n",
       "Lady          1\n",
       "Mme           1\n",
       "Don           1\n",
       "Jonkheer      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_titles.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "titles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "\n",
    "for dataset in data:\n",
    "    # extract titles\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    # replace titles with a more common title or as Rare\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n",
    "                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    # convert titles into numbers\n",
    "    #dataset['Title'] = dataset['Title'].map(titles)\n",
    "    # filling NaN with 0, to get safe\n",
    "    dataset['Title'] = dataset['Title'].fillna(\"NA\")\n",
    "train_df = train_df.drop(['Name'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>relatives</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>0.575000</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>7.350000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>34.250000</td>\n",
       "      <td>3.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>0.702703</td>\n",
       "      <td>2.291892</td>\n",
       "      <td>23.167568</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>43.340541</td>\n",
       "      <td>1.243243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>0.156673</td>\n",
       "      <td>2.410058</td>\n",
       "      <td>31.568665</td>\n",
       "      <td>0.288201</td>\n",
       "      <td>0.152805</td>\n",
       "      <td>24.021277</td>\n",
       "      <td>0.441006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>0.793651</td>\n",
       "      <td>1.992063</td>\n",
       "      <td>34.531746</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>44.984127</td>\n",
       "      <td>1.515873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rare</th>\n",
       "      <td>0.347826</td>\n",
       "      <td>1.347826</td>\n",
       "      <td>44.565217</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>36.782609</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Survived    Pclass        Age     SibSp     Parch       Fare  \\\n",
       "Title                                                                  \n",
       "Master  0.575000  2.625000   7.350000  2.300000  1.375000  34.250000   \n",
       "Miss    0.702703  2.291892  23.167568  0.702703  0.540541  43.340541   \n",
       "Mr      0.156673  2.410058  31.568665  0.288201  0.152805  24.021277   \n",
       "Mrs     0.793651  1.992063  34.531746  0.690476  0.825397  44.984127   \n",
       "Rare    0.347826  1.347826  44.565217  0.347826  0.086957  36.782609   \n",
       "\n",
       "        relatives  \n",
       "Title              \n",
       "Master   3.675000  \n",
       "Miss     1.243243  \n",
       "Mr       0.441006  \n",
       "Mrs      1.515873  \n",
       "Rare     0.434783  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby(['Title']).mean('Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>relatives</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Master</th>\n",
       "      <td>1123.380952</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>28.095238</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>1.380952</td>\n",
       "      <td>38.142857</td>\n",
       "      <td>2.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>1100.240506</td>\n",
       "      <td>2.443038</td>\n",
       "      <td>28.835443</td>\n",
       "      <td>0.544304</td>\n",
       "      <td>0.392405</td>\n",
       "      <td>39.139241</td>\n",
       "      <td>0.936709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mr</th>\n",
       "      <td>1101.279167</td>\n",
       "      <td>2.320833</td>\n",
       "      <td>28.725000</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>25.016667</td>\n",
       "      <td>0.445833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>1090.097222</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>29.291667</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>59.611111</td>\n",
       "      <td>1.430556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rare</th>\n",
       "      <td>1117.500000</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>27.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Pclass        Age     SibSp     Parch       Fare  \\\n",
       "Title                                                                     \n",
       "Master  1123.380952  2.714286  28.095238  1.571429  1.380952  38.142857   \n",
       "Miss    1100.240506  2.443038  28.835443  0.544304  0.392405  39.139241   \n",
       "Mr      1101.279167  2.320833  28.725000  0.270833  0.175000  25.016667   \n",
       "Mrs     1090.097222  1.833333  29.291667  0.597222  0.833333  59.611111   \n",
       "Rare    1117.500000  1.333333  27.500000  0.500000  0.333333  80.500000   \n",
       "\n",
       "        relatives  \n",
       "Title              \n",
       "Master   2.952381  \n",
       "Miss     0.936709  \n",
       "Mr       0.445833  \n",
       "Mrs      1.430556  \n",
       "Rare     0.833333  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.groupby(['Title']).mean('Title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sex: Convert to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "male      577\n",
       "female    314\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngenders = {\"male\": 0, \"female\": 1}\\ndata = [train_df, test_df]\\n\\nfor dataset in data:\\n    dataset[\\'Sex\\'] = dataset[\\'Sex\\'].map(genders)\\n\\n'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "genders = {\"male\": 0, \"female\": 1}\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Sex'] = dataset['Sex'].map(genders)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ticket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        891\n",
       "unique       681\n",
       "top       347082\n",
       "freq           7\n",
       "Name: Ticket, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Ticket'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count          418\n",
       "unique         363\n",
       "top       PC 17608\n",
       "freq             5\n",
       "Name: Ticket, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Ticket'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since the Ticket attribute has too many unique values, it will be a bit tricky to convert them into useful categories. So we will drop it from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Ticket'], axis=1)\n",
    "test_df = test_df.drop(['Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked: Convert to Numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nports = {\"S\": 0, \"C\": 1, \"Q\": 2}\\ndata = [train_df, test_df]\\n\\nfor dataset in data:\\n    dataset[\\'Embarked\\'] = dataset[\\'Embarked\\'].map(ports)\\n    \\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map(ports)\n",
    "    \n",
    "'''    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age times class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset['Age_Class']= dataset['Age']* dataset['Pclass']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fare per Person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dataset in data:\n",
    "    dataset['Fare_Per_Person'] = dataset['Fare']/(dataset['relatives']+1)\n",
    "    dataset['Fare_Per_Person'] = dataset['Fare_Per_Person'].astype(int)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating categories:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age: Convert from float to int and create a new feature \"AgeGroup\" using bins "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "Adults          161\n",
       "Senior          156\n",
       "Middle Age      147\n",
       "Young Adults    138\n",
       "Youngsters      119\n",
       "Teens            95\n",
       "Children         68\n",
       "Retired           7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n",
    "    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n",
    "    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n",
    "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n",
    "    dataset.loc[ dataset['Age'] > 66, 'Age'] = 7\n",
    "    \n",
    "    dataset['Age'] = dataset['Age'].astype(str)\n",
    "    dataset.loc[ dataset['Age'] == '0', 'Age'] = \"Children\"\n",
    "    dataset.loc[ dataset['Age'] == '1', 'Age'] = \"Teens\"\n",
    "    dataset.loc[ dataset['Age'] == '2', 'Age'] = \"Youngsters\"\n",
    "    dataset.loc[ dataset['Age'] == '3', 'Age'] = \"Young Adults\"\n",
    "    dataset.loc[ dataset['Age'] == '4', 'Age'] = \"Adults\"\n",
    "    dataset.loc[ dataset['Age'] == '5', 'Age'] = \"Middle Age\"\n",
    "    dataset.loc[ dataset['Age'] == '6', 'Age'] = \"Senior\"\n",
    "    dataset.loc[ dataset['Age'] == '7', 'Age'] = \"Retired\"\n",
    "\n",
    "# let's see how it's distributed \n",
    "train_df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "Adults          82\n",
       "Middle Age      71\n",
       "Senior          65\n",
       "Youngsters      60\n",
       "Young Adults    60\n",
       "Teens           45\n",
       "Children        33\n",
       "Retired          2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Survived         891 non-null    int64 \n",
      " 1   Pclass           891 non-null    int64 \n",
      " 2   Sex              891 non-null    object\n",
      " 3   Age              891 non-null    object\n",
      " 4   SibSp            891 non-null    int64 \n",
      " 5   Parch            891 non-null    int64 \n",
      " 6   Fare             891 non-null    int64 \n",
      " 7   Embarked         891 non-null    object\n",
      " 8   relatives        891 non-null    int64 \n",
      " 9   travelled_alone  891 non-null    object\n",
      " 10  Deck             891 non-null    object\n",
      " 11  Title            891 non-null    object\n",
      " 12  Age_Class        891 non-null    int64 \n",
      " 13  Fare_Per_Person  891 non-null    int64 \n",
      "dtypes: int64(8), object(6)\n",
      "memory usage: 97.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 99), 'Fare']   = 3\n",
    "    dataset.loc[(dataset['Fare'] > 99) & (dataset['Fare'] <= 250), 'Fare']   = 4\n",
    "    dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    dataset['Fare'] = dataset['Fare'].astype(str)\n",
    "    dataset.loc[ dataset['Fare'] == '0', 'Fare'] = \"Extremely Low\"\n",
    "    dataset.loc[ dataset['Fare'] == '1', 'Fare'] = \"Very Low\"\n",
    "    dataset.loc[ dataset['Fare'] == '2', 'Fare'] = \"Low\"\n",
    "    dataset.loc[ dataset['Fare'] == '3', 'Fare'] = \"High\"\n",
    "    dataset.loc[ dataset['Fare'] == '4', 'Fare'] = \"Very High\"\n",
    "    dataset.loc[ dataset['Fare'] == '5', 'Fare'] = \"Extremely High\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fare\n",
       "Extremely Low     241\n",
       "Low               223\n",
       "Very Low          216\n",
       "High              158\n",
       "Very High          44\n",
       "Extremely High      9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Fare'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fare\n",
       "Extremely Low     120\n",
       "Low               102\n",
       "Very Low           96\n",
       "High               69\n",
       "Very High          23\n",
       "Extremely High      8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Fare'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Survived         891 non-null    int64 \n",
      " 1   Pclass           891 non-null    int64 \n",
      " 2   Sex              891 non-null    object\n",
      " 3   Age              891 non-null    object\n",
      " 4   SibSp            891 non-null    int64 \n",
      " 5   Parch            891 non-null    int64 \n",
      " 6   Fare             891 non-null    object\n",
      " 7   Embarked         891 non-null    object\n",
      " 8   relatives        891 non-null    int64 \n",
      " 9   travelled_alone  891 non-null    object\n",
      " 10  Deck             891 non-null    object\n",
      " 11  Title            891 non-null    object\n",
      " 12  Age_Class        891 non-null    int64 \n",
      " 13  Fare_Per_Person  891 non-null    int64 \n",
      "dtypes: int64(7), object(7)\n",
      "memory usage: 97.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   PassengerId      418 non-null    int64 \n",
      " 1   Pclass           418 non-null    int64 \n",
      " 2   Sex              418 non-null    object\n",
      " 3   Age              418 non-null    object\n",
      " 4   SibSp            418 non-null    int64 \n",
      " 5   Parch            418 non-null    int64 \n",
      " 6   Fare             418 non-null    object\n",
      " 7   Embarked         418 non-null    object\n",
      " 8   relatives        418 non-null    int64 \n",
      " 9   travelled_alone  418 non-null    object\n",
      " 10  Deck             418 non-null    object\n",
      " 11  Title            418 non-null    object\n",
      " 12  Age_Class        418 non-null    int64 \n",
      " 13  Fare_Per_Person  418 non-null    int64 \n",
      "dtypes: int64(7), object(7)\n",
      "memory usage: 45.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>relatives</th>\n",
       "      <th>travelled_alone</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Title</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>Fare_Per_Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Youngsters</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Extremely Low</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>U</td>\n",
       "      <td>Mr</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Middle Age</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adults</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Extremely Low</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>U</td>\n",
       "      <td>Miss</td>\n",
       "      <td>78</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Middle Age</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>35</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Middle Age</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Very Low</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>U</td>\n",
       "      <td>Mr</td>\n",
       "      <td>105</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adults</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Very Low</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>U</td>\n",
       "      <td>Mr</td>\n",
       "      <td>78</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>High</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>E</td>\n",
       "      <td>Mr</td>\n",
       "      <td>54</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Children</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>U</td>\n",
       "      <td>Master</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adults</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Very Low</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>U</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>81</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>Teens</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>U</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>28</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex           Age  SibSp  Parch           Fare  \\\n",
       "0         0       3    male    Youngsters      1      0  Extremely Low   \n",
       "1         1       1  female    Middle Age      1      0           High   \n",
       "2         1       3  female  Young Adults      0      0  Extremely Low   \n",
       "3         1       1  female    Middle Age      1      0           High   \n",
       "4         0       3    male    Middle Age      0      0       Very Low   \n",
       "5         0       3    male  Young Adults      0      0       Very Low   \n",
       "6         0       1    male        Senior      0      0           High   \n",
       "7         0       3    male      Children      3      1            Low   \n",
       "8         1       3  female  Young Adults      0      2       Very Low   \n",
       "9         1       2  female         Teens      1      0            Low   \n",
       "\n",
       "  Embarked  relatives travelled_alone Deck   Title  Age_Class  Fare_Per_Person  \n",
       "0        S          1              No    U      Mr         66                3  \n",
       "1        C          1              No    C     Mrs         38               35  \n",
       "2        S          0             Yes    U    Miss         78                7  \n",
       "3        S          1              No    C     Mrs         35               26  \n",
       "4        S          0             Yes    U      Mr        105                8  \n",
       "5        Q          0             Yes    U      Mr         78                8  \n",
       "6        S          0             Yes    E      Mr         54               51  \n",
       "7        S          4              No    U  Master          6                4  \n",
       "8        S          2              No    U     Mrs         81                3  \n",
       "9        C          1              No    U     Mrs         28               15  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a last look at the training set\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Survived         891 non-null    int64 \n",
      " 1   Pclass           891 non-null    int64 \n",
      " 2   Sex              891 non-null    object\n",
      " 3   Age              891 non-null    object\n",
      " 4   SibSp            891 non-null    int64 \n",
      " 5   Parch            891 non-null    int64 \n",
      " 6   Fare             891 non-null    object\n",
      " 7   Embarked         891 non-null    object\n",
      " 8   relatives        891 non-null    int64 \n",
      " 9   travelled_alone  891 non-null    object\n",
      " 10  Deck             891 non-null    object\n",
      " 11  Title            891 non-null    object\n",
      " 12  Age_Class        891 non-null    int64 \n",
      " 13  Fare_Per_Person  891 non-null    int64 \n",
      "dtypes: int64(7), object(7)\n",
      "memory usage: 97.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   PassengerId      418 non-null    int64 \n",
      " 1   Pclass           418 non-null    int64 \n",
      " 2   Sex              418 non-null    object\n",
      " 3   Age              418 non-null    object\n",
      " 4   SibSp            418 non-null    int64 \n",
      " 5   Parch            418 non-null    int64 \n",
      " 6   Fare             418 non-null    object\n",
      " 7   Embarked         418 non-null    object\n",
      " 8   relatives        418 non-null    int64 \n",
      " 9   travelled_alone  418 non-null    object\n",
      " 10  Deck             418 non-null    object\n",
      " 11  Title            418 non-null    object\n",
      " 12  Age_Class        418 non-null    int64 \n",
      " 13  Fare_Per_Person  418 non-null    int64 \n",
      "dtypes: int64(7), object(7)\n",
      "memory usage: 45.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "3    491\n",
       "1    216\n",
       "2    184\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Pclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Pclass'] = dataset['Pclass'].astype(str)\n",
    "    dataset.loc[ dataset['Pclass'] == '1', 'Pclass'] = \"Class1\"\n",
    "    dataset.loc[ dataset['Pclass'] == '2', 'Pclass'] = \"Class2\"\n",
    "    dataset.loc[ dataset['Pclass'] == '3', 'Pclass'] = \"Class3\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Survived         891 non-null    int64 \n",
      " 1   Pclass           891 non-null    object\n",
      " 2   Sex              891 non-null    object\n",
      " 3   Age              891 non-null    object\n",
      " 4   SibSp            891 non-null    int64 \n",
      " 5   Parch            891 non-null    int64 \n",
      " 6   Fare             891 non-null    object\n",
      " 7   Embarked         891 non-null    object\n",
      " 8   relatives        891 non-null    int64 \n",
      " 9   travelled_alone  891 non-null    object\n",
      " 10  Deck             891 non-null    object\n",
      " 11  Title            891 non-null    object\n",
      " 12  Age_Class        891 non-null    int64 \n",
      " 13  Fare_Per_Person  891 non-null    int64 \n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 97.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   PassengerId      418 non-null    int64 \n",
      " 1   Pclass           418 non-null    object\n",
      " 2   Sex              418 non-null    object\n",
      " 3   Age              418 non-null    object\n",
      " 4   SibSp            418 non-null    int64 \n",
      " 5   Parch            418 non-null    int64 \n",
      " 6   Fare             418 non-null    object\n",
      " 7   Embarked         418 non-null    object\n",
      " 8   relatives        418 non-null    int64 \n",
      " 9   travelled_alone  418 non-null    object\n",
      " 10  Deck             418 non-null    object\n",
      " 11  Title            418 non-null    object\n",
      " 12  Age_Class        418 non-null    int64 \n",
      " 13  Fare_Per_Person  418 non-null    int64 \n",
      "dtypes: int64(6), object(8)\n",
      "memory usage: 45.8+ KB\n"
     ]
    }
   ],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "Class3    491\n",
       "Class1    216\n",
       "Class2    184\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Pclass'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Survived', 'SibSp', 'Parch', 'relatives', 'Age_Class', 'Fare_Per_Person']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capture all the numerical features so that we can scale them later\n",
    "#data = [train_df, test_df]\n",
    "train_numerical_features = list(train_df.select_dtypes(include=['int64', 'float64', 'int32']).columns)\n",
    "train_numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SibSp', 'Parch', 'relatives', 'Age_Class', 'Fare_Per_Person']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_numerical_features[0]\n",
    "train_numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling - Standard scaler\n",
    "ss_scaler = StandardScaler()\n",
    "train_df_ss = pd.DataFrame(data = train_df)\n",
    "train_df_ss[train_numerical_features] = ss_scaler.fit_transform(train_df_ss[train_numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 14)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>relatives</th>\n",
       "      <th>travelled_alone</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Title</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>Fare_Per_Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Class3</td>\n",
       "      <td>male</td>\n",
       "      <td>Youngsters</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>Extremely Low</td>\n",
       "      <td>S</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>No</td>\n",
       "      <td>U</td>\n",
       "      <td>Mr</td>\n",
       "      <td>0.044101</td>\n",
       "      <td>-0.459218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Class1</td>\n",
       "      <td>female</td>\n",
       "      <td>Middle Age</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>High</td>\n",
       "      <td>C</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>No</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>-0.775127</td>\n",
       "      <td>0.434090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Class3</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adults</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>Extremely Low</td>\n",
       "      <td>S</td>\n",
       "      <td>-0.560975</td>\n",
       "      <td>Yes</td>\n",
       "      <td>U</td>\n",
       "      <td>Miss</td>\n",
       "      <td>0.395198</td>\n",
       "      <td>-0.347554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Class1</td>\n",
       "      <td>female</td>\n",
       "      <td>Middle Age</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>High</td>\n",
       "      <td>S</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>No</td>\n",
       "      <td>C</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>-0.862902</td>\n",
       "      <td>0.182847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Class3</td>\n",
       "      <td>male</td>\n",
       "      <td>Middle Age</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>Very Low</td>\n",
       "      <td>S</td>\n",
       "      <td>-0.560975</td>\n",
       "      <td>Yes</td>\n",
       "      <td>U</td>\n",
       "      <td>Mr</td>\n",
       "      <td>1.185168</td>\n",
       "      <td>-0.319638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex           Age     SibSp     Parch           Fare  \\\n",
       "0         0  Class3    male    Youngsters  0.432793 -0.473674  Extremely Low   \n",
       "1         1  Class1  female    Middle Age  0.432793 -0.473674           High   \n",
       "2         1  Class3  female  Young Adults -0.474545 -0.473674  Extremely Low   \n",
       "3         1  Class1  female    Middle Age  0.432793 -0.473674           High   \n",
       "4         0  Class3    male    Middle Age -0.474545 -0.473674       Very Low   \n",
       "\n",
       "  Embarked  relatives travelled_alone Deck Title  Age_Class  Fare_Per_Person  \n",
       "0        S   0.059160              No    U    Mr   0.044101        -0.459218  \n",
       "1        C   0.059160              No    C   Mrs  -0.775127         0.434090  \n",
       "2        S  -0.560975             Yes    U  Miss   0.395198        -0.347554  \n",
       "3        S   0.059160              No    C   Mrs  -0.862902         0.182847  \n",
       "4        S  -0.560975             Yes    U    Mr   1.185168        -0.319638  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId', 'SibSp', 'Parch', 'relatives', 'Age_Class', 'Fare_Per_Person']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_numerical_features = list(test_df.select_dtypes(include=['int64', 'float64', 'int32']).columns)\n",
    "test_numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SibSp', 'Parch', 'relatives', 'Age_Class', 'Fare_Per_Person']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test_numerical_features[0]\n",
    "test_numerical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling - Standard scaler\n",
    "test_ss_scaler = StandardScaler()\n",
    "test_df_ss = pd.DataFrame(data = test_df)\n",
    "test_df_ss[test_numerical_features] = test_ss_scaler.fit_transform(test_df_ss[test_numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 14)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>relatives</th>\n",
       "      <th>travelled_alone</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Title</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>Fare_Per_Person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>Class3</td>\n",
       "      <td>male</td>\n",
       "      <td>Youngsters</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Extremely Low</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>U</td>\n",
       "      <td>Mr</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>Class3</td>\n",
       "      <td>female</td>\n",
       "      <td>Middle Age</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Extremely Low</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>U</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>114</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>Class2</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adults</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Very Low</td>\n",
       "      <td>Q</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>U</td>\n",
       "      <td>Mr</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>Class3</td>\n",
       "      <td>male</td>\n",
       "      <td>Middle Age</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Very Low</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>U</td>\n",
       "      <td>Mr</td>\n",
       "      <td>105</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>Class3</td>\n",
       "      <td>female</td>\n",
       "      <td>Middle Age</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Very Low</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>U</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>105</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass     Sex           Age  SibSp  Parch           Fare  \\\n",
       "0          892  Class3    male    Youngsters      0      0  Extremely Low   \n",
       "1          893  Class3  female    Middle Age      1      0  Extremely Low   \n",
       "2          894  Class2    male  Young Adults      0      0       Very Low   \n",
       "3          895  Class3    male    Middle Age      0      0       Very Low   \n",
       "4          896  Class3  female    Middle Age      1      1       Very Low   \n",
       "\n",
       "  Embarked  relatives travelled_alone Deck Title  Age_Class  Fare_Per_Person  \n",
       "0        Q          0             Yes    U    Mr         66                7  \n",
       "1        S          1              No    U   Mrs        114                3  \n",
       "2        Q          0             Yes    U    Mr         52                9  \n",
       "3        S          0             Yes    U    Mr        105                8  \n",
       "4        S          2              No    U   Mrs        105                4  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot encoding / Dummy variables\n",
    "encode_col_list = list(train_df.select_dtypes(include=['object']).columns)\n",
    "for i in encode_col_list:\n",
    "    train_df_ss = pd.concat([train_df_ss,pd.get_dummies(train_df_ss[i], prefix=i)],axis=1)\n",
    "    train_df_ss.drop(i, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 43)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>relatives</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>Fare_Per_Person</th>\n",
       "      <th>Pclass_Class1</th>\n",
       "      <th>Pclass_Class2</th>\n",
       "      <th>Pclass_Class3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>...</th>\n",
       "      <th>Deck_D</th>\n",
       "      <th>Deck_E</th>\n",
       "      <th>Deck_F</th>\n",
       "      <th>Deck_G</th>\n",
       "      <th>Deck_U</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>0.044101</td>\n",
       "      <td>-0.459218</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>-0.775127</td>\n",
       "      <td>0.434090</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.560975</td>\n",
       "      <td>0.395198</td>\n",
       "      <td>-0.347554</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.432793</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>-0.862902</td>\n",
       "      <td>0.182847</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.474545</td>\n",
       "      <td>-0.473674</td>\n",
       "      <td>-0.560975</td>\n",
       "      <td>1.185168</td>\n",
       "      <td>-0.319638</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived     SibSp     Parch  relatives  Age_Class  Fare_Per_Person  \\\n",
       "0         0  0.432793 -0.473674   0.059160   0.044101        -0.459218   \n",
       "1         1  0.432793 -0.473674   0.059160  -0.775127         0.434090   \n",
       "2         1 -0.474545 -0.473674  -0.560975   0.395198        -0.347554   \n",
       "3         1  0.432793 -0.473674   0.059160  -0.862902         0.182847   \n",
       "4         0 -0.474545 -0.473674  -0.560975   1.185168        -0.319638   \n",
       "\n",
       "   Pclass_Class1  Pclass_Class2  Pclass_Class3  Sex_female  ...  Deck_D  \\\n",
       "0          False          False           True       False  ...   False   \n",
       "1           True          False          False        True  ...   False   \n",
       "2          False          False           True        True  ...   False   \n",
       "3           True          False          False        True  ...   False   \n",
       "4          False          False           True       False  ...   False   \n",
       "\n",
       "   Deck_E  Deck_F  Deck_G  Deck_U  Title_Master  Title_Miss  Title_Mr  \\\n",
       "0   False   False   False    True         False       False      True   \n",
       "1   False   False   False   False         False       False     False   \n",
       "2   False   False   False    True         False        True     False   \n",
       "3   False   False   False   False         False       False     False   \n",
       "4   False   False   False    True         False       False      True   \n",
       "\n",
       "   Title_Mrs  Title_Rare  \n",
       "0      False       False  \n",
       "1       True       False  \n",
       "2      False       False  \n",
       "3       True       False  \n",
       "4      False       False  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot encoding / Dummy variables\n",
    "test_encode_col_list = list(test_df.select_dtypes(include=['object']).columns)\n",
    "for i in test_encode_col_list:\n",
    "    test_df_ss = pd.concat([test_df_ss,pd.get_dummies(test_df_ss[i], prefix=i)],axis=1)\n",
    "    test_df_ss.drop(i, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 43)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>relatives</th>\n",
       "      <th>Age_Class</th>\n",
       "      <th>Fare_Per_Person</th>\n",
       "      <th>Pclass_Class1</th>\n",
       "      <th>Pclass_Class2</th>\n",
       "      <th>Pclass_Class3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>...</th>\n",
       "      <th>Deck_D</th>\n",
       "      <th>Deck_E</th>\n",
       "      <th>Deck_F</th>\n",
       "      <th>Deck_G</th>\n",
       "      <th>Deck_U</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>-0.499470</td>\n",
       "      <td>-0.400248</td>\n",
       "      <td>-0.553443</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>-0.401204</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0.616992</td>\n",
       "      <td>-0.400248</td>\n",
       "      <td>0.105643</td>\n",
       "      <td>1.197300</td>\n",
       "      <td>-0.513662</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>-0.499470</td>\n",
       "      <td>-0.400248</td>\n",
       "      <td>-0.553443</td>\n",
       "      <td>-0.340399</td>\n",
       "      <td>-0.344975</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>-0.499470</td>\n",
       "      <td>-0.400248</td>\n",
       "      <td>-0.553443</td>\n",
       "      <td>0.974085</td>\n",
       "      <td>-0.373089</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0.616992</td>\n",
       "      <td>0.619896</td>\n",
       "      <td>0.764728</td>\n",
       "      <td>0.974085</td>\n",
       "      <td>-0.485547</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId     SibSp     Parch  relatives  Age_Class  Fare_Per_Person  \\\n",
       "0          892 -0.499470 -0.400248  -0.553443   0.006823        -0.401204   \n",
       "1          893  0.616992 -0.400248   0.105643   1.197300        -0.513662   \n",
       "2          894 -0.499470 -0.400248  -0.553443  -0.340399        -0.344975   \n",
       "3          895 -0.499470 -0.400248  -0.553443   0.974085        -0.373089   \n",
       "4          896  0.616992  0.619896   0.764728   0.974085        -0.485547   \n",
       "\n",
       "   Pclass_Class1  Pclass_Class2  Pclass_Class3  Sex_female  ...  Deck_D  \\\n",
       "0          False          False           True       False  ...   False   \n",
       "1          False          False           True        True  ...   False   \n",
       "2          False           True          False       False  ...   False   \n",
       "3          False          False           True       False  ...   False   \n",
       "4          False          False           True        True  ...   False   \n",
       "\n",
       "   Deck_E  Deck_F  Deck_G  Deck_U  Title_Master  Title_Miss  Title_Mr  \\\n",
       "0   False   False   False    True         False       False      True   \n",
       "1   False   False   False    True         False       False     False   \n",
       "2   False   False   False    True         False       False      True   \n",
       "3   False   False   False    True         False       False      True   \n",
       "4   False   False   False    True         False       False     False   \n",
       "\n",
       "   Title_Mrs  Title_Rare  \n",
       "0      False       False  \n",
       "1       True       False  \n",
       "2      False       False  \n",
       "3      False       False  \n",
       "4       True       False  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_ss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df_ss.drop(\"Survived\", axis=1)\n",
    "Y_train = train_df_ss[\"Survived\"]\n",
    "X_test  = test_df_ss.drop(\"PassengerId\", axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 42)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 42)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 42 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   SibSp                891 non-null    float64\n",
      " 1   Parch                891 non-null    float64\n",
      " 2   relatives            891 non-null    float64\n",
      " 3   Age_Class            891 non-null    float64\n",
      " 4   Fare_Per_Person      891 non-null    float64\n",
      " 5   Pclass_Class1        891 non-null    bool   \n",
      " 6   Pclass_Class2        891 non-null    bool   \n",
      " 7   Pclass_Class3        891 non-null    bool   \n",
      " 8   Sex_female           891 non-null    bool   \n",
      " 9   Sex_male             891 non-null    bool   \n",
      " 10  Age_Adults           891 non-null    bool   \n",
      " 11  Age_Children         891 non-null    bool   \n",
      " 12  Age_Middle Age       891 non-null    bool   \n",
      " 13  Age_Retired          891 non-null    bool   \n",
      " 14  Age_Senior           891 non-null    bool   \n",
      " 15  Age_Teens            891 non-null    bool   \n",
      " 16  Age_Young Adults     891 non-null    bool   \n",
      " 17  Age_Youngsters       891 non-null    bool   \n",
      " 18  Fare_Extremely High  891 non-null    bool   \n",
      " 19  Fare_Extremely Low   891 non-null    bool   \n",
      " 20  Fare_High            891 non-null    bool   \n",
      " 21  Fare_Low             891 non-null    bool   \n",
      " 22  Fare_Very High       891 non-null    bool   \n",
      " 23  Fare_Very Low        891 non-null    bool   \n",
      " 24  Embarked_C           891 non-null    bool   \n",
      " 25  Embarked_Q           891 non-null    bool   \n",
      " 26  Embarked_S           891 non-null    bool   \n",
      " 27  travelled_alone_No   891 non-null    bool   \n",
      " 28  travelled_alone_Yes  891 non-null    bool   \n",
      " 29  Deck_A               891 non-null    bool   \n",
      " 30  Deck_B               891 non-null    bool   \n",
      " 31  Deck_C               891 non-null    bool   \n",
      " 32  Deck_D               891 non-null    bool   \n",
      " 33  Deck_E               891 non-null    bool   \n",
      " 34  Deck_F               891 non-null    bool   \n",
      " 35  Deck_G               891 non-null    bool   \n",
      " 36  Deck_U               891 non-null    bool   \n",
      " 37  Title_Master         891 non-null    bool   \n",
      " 38  Title_Miss           891 non-null    bool   \n",
      " 39  Title_Mr             891 non-null    bool   \n",
      " 40  Title_Mrs            891 non-null    bool   \n",
      " 41  Title_Rare           891 non-null    bool   \n",
      "dtypes: bool(37), float64(5)\n",
      "memory usage: 67.1 KB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Fit our model to the training data\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "logreg_predictions = logreg.predict(X_test)\n",
    "\n",
    "logreg_data = pd.read_csv('Dataset/test.csv')\n",
    "logreg_data.insert((logreg_data.shape[1]),'Survived',logreg_predictions)\n",
    "\n",
    "logreg_data.to_csv('LogisticRegression_SS_OH_FE2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our model\n",
    "adaboost = AdaBoostClassifier()\n",
    "\n",
    "# Fit our model to the training data\n",
    "adaboost.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "adaboost_predictions = adaboost.predict(X_test)\n",
    "\n",
    "adaboost_data = pd.read_csv('Dataset/test.csv')\n",
    "adaboost_data.insert((adaboost_data.shape[1]),'Survived',adaboost_predictions)\n",
    "\n",
    "adaboost_data.to_csv('AdaptiveBoosting_SS_OH_FE.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our model\n",
    "bag = BaggingClassifier()\n",
    "\n",
    "# Fit our model to the training data\n",
    "bag.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "bag_predictions = bag.predict(X_test)\n",
    "\n",
    "bag_data = pd.read_csv('Dataset/test.csv')\n",
    "bag_data.insert((bag_data.shape[1]),'Survived',bag_predictions)\n",
    "\n",
    "bag_data.to_csv('Bagging.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "\n",
    "random_forest_predictions = random_forest.predict(X_test)\n",
    "\n",
    "rf_data = pd.read_csv('Dataset/test.csv')\n",
    "rf_data.insert((rf_data.shape[1]),'Survived',random_forest_predictions)\n",
    "\n",
    "rf_data.to_csv('RandomForest_SS_OH.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our model\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(X_train, Y_train)\n",
    "\n",
    "dt_predictions = dt.predict(X_test)\n",
    "\n",
    "dt_data = pd.read_csv('Dataset/test.csv')\n",
    "dt_data.insert((dt_data.shape[1]),'Survived',dt_predictions)\n",
    "\n",
    "dt_data.to_csv('DecisionTrees.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our model\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, Y_train)\n",
    "\n",
    "gb_predictions = gb.predict(X_test)\n",
    "\n",
    "gb_data = pd.read_csv('Dataset/test.csv')\n",
    "gb_data.insert((gb_data.shape[1]),'Survived',gb_predictions)\n",
    "\n",
    "gb_data.to_csv('GradientBoost_SS_OH_FE.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our model\n",
    "xg = XGBClassifier(learning_rate=0.02, n_estimators=750,\n",
    "                   max_depth= 3, min_child_weight= 1, \n",
    "                   colsample_bytree= 0.6, gamma= 0.0, \n",
    "                   reg_alpha= 0.001, subsample= 0.8\n",
    "                  )\n",
    "xg.fit(X_train, Y_train)\n",
    "\n",
    "xg_predictions = xg.predict(X_test)\n",
    "\n",
    "xg_data = pd.read_csv('Dataset/test.csv')\n",
    "xg_data.insert((xg_data.shape[1]),'Survived',xg_predictions)\n",
    "\n",
    "xg_data.to_csv('XGBoost_SS_OH_FE_GSCV.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning - using GridSearchCV to find the best set of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 560 candidates, totalling 1680 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.798) total time=   9.7s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.4s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.855) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0, subsample=0.9; AUC: (test=0.889) Accuracy: (test=0.835) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.001, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.001, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.001, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.001, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.798) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.001, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.001, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.001, subsample=0.8; AUC: (test=0.827) Accuracy: (test=0.801) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.001, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.001, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.001, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.001, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.5s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.001, subsample=0.9; AUC: (test=0.889) Accuracy: (test=0.835) total time=   4.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.005, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.798) total time=   8.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.005, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=  10.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.005, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.828) total time=   1.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.005, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   2.8s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.005, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.859) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.005, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.005, subsample=0.8; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.005, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.005, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.005, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.808) total time=   3.3s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.005, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.005, subsample=0.9; AUC: (test=0.889) Accuracy: (test=0.835) total time=   2.5s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.01, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   3.3s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.01, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.855) total time=   2.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.01, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.822) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.01, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.01, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.01, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.01, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.01, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.01, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.01, subsample=0.9; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.4s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.01, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.852) total time=   2.3s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.01, subsample=0.9; AUC: (test=0.890) Accuracy: (test=0.838) total time=   2.4s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.05, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   4.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.05, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.852) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.05, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.05, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.05, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.05, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   2.3s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.05, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.05, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.05, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.05, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.05, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.05, subsample=0.9; AUC: (test=0.888) Accuracy: (test=0.835) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.1, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.852) total time=   2.3s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.1, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.835) total time=   2.8s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.1, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.1, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.848) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.1, subsample=0.7; AUC: (test=0.889) Accuracy: (test=0.835) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.1, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.1, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.1, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.1, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=0.1, subsample=0.9; AUC: (test=0.889) Accuracy: (test=0.835) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=1, subsample=0.6; AUC: (test=0.827) Accuracy: (test=0.801) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=1, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.852) total time=   2.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=1, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.828) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=1, subsample=0.7; AUC: (test=0.827) Accuracy: (test=0.805) total time=   2.3s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=1, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.848) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=1, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.828) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=1, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=1, subsample=0.8; AUC: (test=0.885) Accuracy: (test=0.848) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=1, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.828) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.848) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.0, reg_alpha=1, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.842) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0, subsample=0.9; AUC: (test=0.890) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.001, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.3s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.001, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.855) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.001, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.001, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.001, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.001, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.001, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.001, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.001, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.4s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.001, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.001, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.5s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.001, subsample=0.9; AUC: (test=0.889) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.005, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.798) total time=   2.3s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.005, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.005, subsample=0.6; AUC: (test=0.889) Accuracy: (test=0.835) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.005, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.005, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.005, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.005, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.005, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.005, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.835) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.005, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.005, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.005, subsample=0.9; AUC: (test=0.890) Accuracy: (test=0.838) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.01, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.01, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.01, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.01, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.798) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.01, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.01, subsample=0.7; AUC: (test=0.889) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.01, subsample=0.8; AUC: (test=0.827) Accuracy: (test=0.801) total time=   2.3s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.01, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.01, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.01, subsample=0.9; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.01, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.01, subsample=0.9; AUC: (test=0.889) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.05, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.05, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.05, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.828) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.05, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.795) total time=   2.5s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.05, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.05, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.05, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.05, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.05, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.05, subsample=0.9; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.05, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.05, subsample=0.9; AUC: (test=0.889) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.1, subsample=0.6; AUC: (test=0.827) Accuracy: (test=0.801) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.852) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.1, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.1, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.795) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.1, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.1, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.1, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.1, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.855) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=0.1, subsample=0.9; AUC: (test=0.890) Accuracy: (test=0.838) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=1, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.3s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=1, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.852) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=1, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=1, subsample=0.7; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=1, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.848) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=1, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.848) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=1, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.828) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=1, subsample=0.9; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.848) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.1, reg_alpha=1, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.842) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.798) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.828) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0, subsample=0.9; AUC: (test=0.890) Accuracy: (test=0.838) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.001, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.001, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.3s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.001, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.001, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   2.3s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.001, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.001, subsample=0.7; AUC: (test=0.889) Accuracy: (test=0.835) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.001, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.3s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.001, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.001, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.001, subsample=0.9; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.001, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.4s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.001, subsample=0.9; AUC: (test=0.890) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.005, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.005, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.005, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.3s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.005, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.798) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.005, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.852) total time=   2.3s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.005, subsample=0.7; AUC: (test=0.889) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.005, subsample=0.8; AUC: (test=0.827) Accuracy: (test=0.801) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.005, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.005, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.005, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.005, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.005, subsample=0.9; AUC: (test=0.890) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.01, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.5s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.01, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.01, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.01, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.795) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.01, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.01, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.01, subsample=0.8; AUC: (test=0.827) Accuracy: (test=0.801) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.01, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.01, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.01, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.01, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.852) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.01, subsample=0.9; AUC: (test=0.890) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.05, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.05, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.05, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.828) total time=   2.5s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.05, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.795) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.05, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.05, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.05, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.05, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.05, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.05, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.05, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.05, subsample=0.9; AUC: (test=0.890) Accuracy: (test=0.842) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.1, subsample=0.6; AUC: (test=0.827) Accuracy: (test=0.798) total time=   2.4s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.852) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.1, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.1, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.1, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.855) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.1, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.1, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.1, subsample=0.8; AUC: (test=0.886) Accuracy: (test=0.835) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.855) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=0.1, subsample=0.9; AUC: (test=0.890) Accuracy: (test=0.835) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=1, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.4s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=1, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.852) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=1, subsample=0.6; AUC: (test=0.889) Accuracy: (test=0.832) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=1, subsample=0.7; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=1, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.848) total time=   2.4s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=1, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=1, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.828) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=1, subsample=0.9; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.848) total time=   2.4s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.2, reg_alpha=1, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.842) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.798) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.795) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.795) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0, subsample=0.9; AUC: (test=0.891) Accuracy: (test=0.838) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.001, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.798) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.001, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.001, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.001, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.795) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.001, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.001, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.001, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.001, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.001, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.3s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.001, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.001, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.3s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.001, subsample=0.9; AUC: (test=0.891) Accuracy: (test=0.838) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.005, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.798) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.005, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.005, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.005, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.795) total time=   6.8s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.005, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.005, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.005, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.005, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.005, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.005, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.005, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.005, subsample=0.9; AUC: (test=0.891) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.01, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.01, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.01, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.01, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.795) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.01, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.01, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.01, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.01, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.01, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.01, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.01, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.855) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.01, subsample=0.9; AUC: (test=0.891) Accuracy: (test=0.838) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.05, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.05, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.859) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.05, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.05, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.798) total time=   2.4s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.05, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.05, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.9s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.05, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.05, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.855) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.05, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.835) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.05, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.05, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.05, subsample=0.9; AUC: (test=0.890) Accuracy: (test=0.842) total time=   2.8s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.1, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.852) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.1, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.1, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.1, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.1, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.1, subsample=0.9; AUC: (test=0.825) Accuracy: (test=0.805) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.1, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=0.1, subsample=0.9; AUC: (test=0.890) Accuracy: (test=0.842) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=1, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.7s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=1, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.852) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=1, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=1, subsample=0.7; AUC: (test=0.827) Accuracy: (test=0.805) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=1, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.852) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=1, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.828) total time=   2.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.3s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.855) total time=   2.5s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=1, subsample=0.8; AUC: (test=0.889) Accuracy: (test=0.828) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   3.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.848) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.3, reg_alpha=1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.842) total time=   2.9s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.798) total time=   2.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.855) total time=   2.5s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.795) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   2.4s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0, subsample=0.8; AUC: (test=0.885) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   2.5s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.852) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0, subsample=0.9; AUC: (test=0.890) Accuracy: (test=0.835) total time=   2.5s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.001, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.798) total time=   2.3s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.001, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.855) total time=   3.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.001, subsample=0.6; AUC: (test=0.889) Accuracy: (test=0.832) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.001, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.795) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.001, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.855) total time=   7.7s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.001, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   2.3s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.001, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.001, subsample=0.8; AUC: (test=0.885) Accuracy: (test=0.859) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.001, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.001, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.001, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.001, subsample=0.9; AUC: (test=0.891) Accuracy: (test=0.835) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.005, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.005, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.005, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.005, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.795) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.005, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.859) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.005, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.005, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.798) total time=   2.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.005, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.005, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   2.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.005, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.3s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.005, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.005, subsample=0.9; AUC: (test=0.891) Accuracy: (test=0.838) total time=   4.1s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.01, subsample=0.6; AUC: (test=0.827) Accuracy: (test=0.798) total time=   7.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.01, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.855) total time=   2.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.01, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.5s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.01, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.795) total time=   7.8s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.01, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   3.9s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.01, subsample=0.7; AUC: (test=0.889) Accuracy: (test=0.832) total time=   2.5s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.01, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.01, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   7.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.01, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   4.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.01, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.01, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.01, subsample=0.9; AUC: (test=0.891) Accuracy: (test=0.838) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.05, subsample=0.6; AUC: (test=0.827) Accuracy: (test=0.798) total time=   2.4s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.05, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.05, subsample=0.6; AUC: (test=0.889) Accuracy: (test=0.832) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.05, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.795) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.05, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.05, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.05, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.05, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.05, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.05, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.05, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.05, subsample=0.9; AUC: (test=0.891) Accuracy: (test=0.842) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.1, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.1, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.1, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.1, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.1, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.1, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.4s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.1, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.1, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.1, subsample=0.9; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.1, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=0.1, subsample=0.9; AUC: (test=0.891) Accuracy: (test=0.842) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=1, subsample=0.6; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=1, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.852) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=1, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=1, subsample=0.7; AUC: (test=0.827) Accuracy: (test=0.801) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=1, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.852) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=1, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=1, subsample=0.8; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=1, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.828) total time=   2.3s\n",
      "[CV 1/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=1, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.852) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.6, gamma=0.4, reg_alpha=1, subsample=0.9; AUC: (test=0.888) Accuracy: (test=0.838) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.825) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.801) total time=   2.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.832) total time=   3.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   4.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.838) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.001, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.001, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.001, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.825) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.001, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.001, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.001, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.001, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.001, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.001, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.001, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.001, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.862) total time=   2.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.001, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.838) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.005, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.005, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.005, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.825) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.005, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.801) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.005, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.005, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.005, subsample=0.8; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.005, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.862) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.005, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.005, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.005, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.865) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.005, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.838) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.01, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.01, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.01, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.825) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.01, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.805) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.01, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.848) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.01, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.01, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.01, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.01, subsample=0.8; AUC: (test=0.886) Accuracy: (test=0.832) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.01, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.01, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.01, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.838) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.05, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.05, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.05, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.828) total time=   5.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.05, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.805) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.05, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.05, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.832) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.05, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.05, subsample=0.8; AUC: (test=0.885) Accuracy: (test=0.862) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.05, subsample=0.8; AUC: (test=0.886) Accuracy: (test=0.832) total time=   7.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.05, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.808) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.05, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.05, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.1, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.1, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.1, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.798) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.1, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.852) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.1, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.832) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.1, subsample=0.8; AUC: (test=0.886) Accuracy: (test=0.832) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.811) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.1, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=0.1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.838) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=1, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=1, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.845) total time=   2.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=1, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=1, subsample=0.8; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=1, subsample=0.9; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=1, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.845) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.0, reg_alpha=1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.832) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.825) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.805) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.852) total time=   2.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.838) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.001, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.001, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.001, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.825) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.001, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.805) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.001, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.848) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.001, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.828) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.001, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.001, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.862) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.001, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.001, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.801) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.001, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.001, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.838) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.005, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.005, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.005, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.825) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.005, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.005, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.855) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.005, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.005, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.005, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.862) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.005, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.005, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.005, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.859) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.005, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.838) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.01, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.01, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.01, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.825) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.01, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.801) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.01, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.01, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.832) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.01, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.01, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.01, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.01, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.01, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.01, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.838) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.05, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.05, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.05, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.825) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.05, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.801) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.05, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.05, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.05, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.05, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.05, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.05, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.05, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.05, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.1, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.1, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.825) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.1, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.1, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.848) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.1, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.1, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   2.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.1, subsample=0.8; AUC: (test=0.885) Accuracy: (test=0.832) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.1, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=0.1, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.838) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=1, subsample=0.6; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=1, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=1, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.845) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=1, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=1, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.852) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=1, subsample=0.8; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=1, subsample=0.9; AUC: (test=0.825) Accuracy: (test=0.808) total time=   2.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.845) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.1, reg_alpha=1, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.825) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.848) total time=   2.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0, subsample=0.8; AUC: (test=0.886) Accuracy: (test=0.832) total time=  12.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   4.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.859) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.838) total time=   4.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.001, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.001, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.001, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.825) total time=   2.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.001, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.795) total time=   2.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.001, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.852) total time=   4.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.001, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.832) total time=   4.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.001, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   4.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.001, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   4.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.001, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   5.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.001, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.001, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.859) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.001, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.838) total time=   2.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.005, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.005, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   4.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.005, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.825) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.005, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.005, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.005, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.828) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.005, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.005, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.862) total time=   3.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.005, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.005, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.805) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.005, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.862) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.005, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.838) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.01, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.01, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.01, subsample=0.6; AUC: (test=0.888) Accuracy: (test=0.825) total time=   2.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.01, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.01, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.01, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.01, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.01, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.01, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.01, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.811) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.01, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.01, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.838) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.05, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.798) total time=   2.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.05, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.05, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.828) total time=   3.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.05, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.05, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.05, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.05, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.798) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.05, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.05, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.05, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.05, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.859) total time=   2.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.05, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.838) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.1, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   3.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.1, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.1, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.825) total time=   2.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.1, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.801) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   2.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.1, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.795) total time=   3.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.1, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.1, subsample=0.8; AUC: (test=0.886) Accuracy: (test=0.832) total time=   2.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.1, subsample=0.9; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.1, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=0.1, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   2.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=1, subsample=0.6; AUC: (test=0.827) Accuracy: (test=0.808) total time=   2.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.852) total time=   2.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.828) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=1, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.848) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=1, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.828) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.852) total time=   2.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=1, subsample=0.8; AUC: (test=0.886) Accuracy: (test=0.828) total time=   2.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=1, subsample=0.9; AUC: (test=0.825) Accuracy: (test=0.808) total time=   3.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.845) total time=   3.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.2, reg_alpha=1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.828) total time=   4.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.801) total time=   3.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0, subsample=0.6; AUC: (test=0.882) Accuracy: (test=0.859) total time=   4.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.825) total time=   3.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   5.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.848) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.835) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.805) total time=   2.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.838) total time=   3.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.001, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.001, subsample=0.6; AUC: (test=0.882) Accuracy: (test=0.859) total time=   8.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.001, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.825) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.001, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   2.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.001, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.848) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.001, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.001, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.001, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.001, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.001, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.001, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.859) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.001, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.838) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.005, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.005, subsample=0.6; AUC: (test=0.882) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.005, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.825) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.005, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.798) total time=   2.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.005, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   2.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.005, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.005, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.005, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.005, subsample=0.8; AUC: (test=0.886) Accuracy: (test=0.832) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.005, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.005, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.005, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.838) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.01, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.01, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.01, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.825) total time=   2.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.01, subsample=0.7; AUC: (test=0.822) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.01, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.01, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.01, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.01, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.01, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.01, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.01, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.01, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.835) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.05, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.05, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.05, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.828) total time=   3.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.05, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   2.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.05, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   6.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.05, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.828) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.05, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   4.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.05, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.862) total time=   7.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.05, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.05, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.05, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.05, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.838) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.1, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.1, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.822) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.1, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.801) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   2.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.1, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.798) total time=   2.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.862) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.1, subsample=0.8; AUC: (test=0.886) Accuracy: (test=0.832) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.1, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=0.1, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.838) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=1, subsample=0.6; AUC: (test=0.827) Accuracy: (test=0.805) total time=   2.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.852) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=1, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.828) total time=   2.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=1, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.848) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=1, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.855) total time=   3.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=1, subsample=0.8; AUC: (test=0.886) Accuracy: (test=0.828) total time=   2.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=1, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.845) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.3, reg_alpha=1, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.805) total time=   3.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.859) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.838) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.001, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.001, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.001, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.825) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.001, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.001, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.001, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.001, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.001, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.865) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.001, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.001, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.001, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.001, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.838) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.005, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.005, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.005, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.825) total time=   2.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.005, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.795) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.005, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.852) total time=   2.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.005, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.005, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.005, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   2.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.005, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.005, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.005, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.005, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.838) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.01, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.01, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.01, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.825) total time=   2.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.01, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.795) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.01, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.01, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.828) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.01, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.01, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.862) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.01, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.01, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.01, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.859) total time=   2.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.01, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.838) total time=   3.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.05, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.05, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   4.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.05, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.828) total time=   4.0s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.05, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.801) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.05, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.05, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.05, subsample=0.8; AUC: (test=0.827) Accuracy: (test=0.801) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.05, subsample=0.8; AUC: (test=0.885) Accuracy: (test=0.859) total time=   2.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.05, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.05, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.808) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.05, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.05, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.842) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.1, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.1, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.825) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.1, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.1, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   2.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.1, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.1, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   2.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.1, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=0.1, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.838) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=1, subsample=0.6; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.855) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=1, subsample=0.7; AUC: (test=0.826) Accuracy: (test=0.801) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=1, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.845) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=1, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.828) total time=   2.4s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=1, subsample=0.8; AUC: (test=0.827) Accuracy: (test=0.808) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.862) total time=   2.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=1, subsample=0.8; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=1, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.801) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.845) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=0.4, reg_alpha=1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   2.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.828) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.798) total time=   2.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.859) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.825) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.855) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0, subsample=0.9; AUC: (test=0.828) Accuracy: (test=0.808) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.001, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.001, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.001, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.825) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.001, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.801) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.001, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.001, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.828) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.001, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.001, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.001, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.001, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.001, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.865) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.001, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.835) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.005, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.005, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.855) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.005, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.005, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.005, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.855) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.005, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.005, subsample=0.8; AUC: (test=0.824) Accuracy: (test=0.805) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.005, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.005, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.005, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.005, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.859) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.005, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.01, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.01, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.855) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.01, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.825) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.01, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.01, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.01, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.825) total time=   2.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.01, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.808) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.01, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.01, subsample=0.8; AUC: (test=0.889) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.01, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.01, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.865) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.01, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.05, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.795) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.05, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.05, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.05, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.05, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.05, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.825) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.05, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.05, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.855) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.05, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.05, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.05, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.05, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.1, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.1, subsample=0.6; AUC: (test=0.882) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.1, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.848) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.1, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.828) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.1, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.1, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.835) total time=   2.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.808) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.1, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=0.1, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=1, subsample=0.6; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.855) total time=   2.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=1, subsample=0.7; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=1, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=1, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.852) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=1, subsample=0.8; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=1, subsample=0.9; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=1, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.852) total time=   2.6s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.0, reg_alpha=1, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.828) total time=   2.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.855) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.801) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.808) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0, subsample=0.8; AUC: (test=0.886) Accuracy: (test=0.835) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.865) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.835) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.001, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.001, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.001, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.001, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.801) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.001, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.001, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.828) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.001, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.001, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.001, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.001, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.001, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.865) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.001, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.835) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.005, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.795) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.005, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.005, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.005, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.005, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.005, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.005, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.005, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.005, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.005, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.005, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.005, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.835) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.01, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.795) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.01, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.855) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.01, subsample=0.6; AUC: (test=0.882) Accuracy: (test=0.825) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.01, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.01, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.855) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.01, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   2.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.01, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.01, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   2.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.01, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.01, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.01, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.01, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.05, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.795) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.05, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.855) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.05, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.825) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.05, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.05, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.05, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.828) total time=   2.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.05, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.05, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.05, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.05, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.05, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.05, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.1, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.1, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.828) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.1, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.848) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.1, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.825) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.1, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.1, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.1, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.1, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.1, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=0.1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=1, subsample=0.6; AUC: (test=0.827) Accuracy: (test=0.801) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.852) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=1, subsample=0.7; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=1, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.852) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=1, subsample=0.8; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=1, subsample=0.9; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=1, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.1, reg_alpha=1, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.825) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.825) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.855) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.855) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.001, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.001, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.001, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.832) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.001, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.001, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.001, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.825) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.001, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.001, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.001, subsample=0.8; AUC: (test=0.889) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.001, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.001, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.865) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.001, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.005, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.005, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.855) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.005, subsample=0.6; AUC: (test=0.882) Accuracy: (test=0.828) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.005, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.005, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.005, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.825) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.005, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.005, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.005, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.005, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.005, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.855) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.005, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.01, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.01, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.01, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.825) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.01, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.01, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.01, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.825) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.01, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.01, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.01, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.01, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.01, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.01, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.05, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.05, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.05, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.05, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.05, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.848) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.05, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.828) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.05, subsample=0.8; AUC: (test=0.827) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.05, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.05, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.05, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.05, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.865) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.05, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.1, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.795) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.1, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.825) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.1, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.801) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.848) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.1, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.822) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.1, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.1, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.1, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.1, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.1, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=0.1, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=1, subsample=0.6; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.855) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=1, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.808) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=1, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.848) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=1, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=1, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.852) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=1, subsample=0.8; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=1, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.848) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.2, reg_alpha=1, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.828) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0, subsample=0.8; AUC: (test=0.824) Accuracy: (test=0.801) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.855) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.001, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.001, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.001, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.001, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.795) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.001, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   2.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.001, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.825) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.001, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.001, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.862) total time=   2.4s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.001, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.001, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.001, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.865) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.001, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.005, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.005, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.005, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.828) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.005, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.005, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.005, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.005, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.005, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.005, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.005, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.005, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.865) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.005, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.01, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.795) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.01, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.01, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.01, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.795) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.01, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.852) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.01, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.01, subsample=0.8; AUC: (test=0.824) Accuracy: (test=0.801) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.01, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.862) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.01, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.01, subsample=0.9; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.01, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.859) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.01, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.05, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.801) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.05, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.859) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.05, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.828) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.05, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.05, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.05, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.822) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.05, subsample=0.8; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.05, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.05, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.05, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.811) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.05, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.865) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.05, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.835) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.1, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.795) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.1, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.1, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.825) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.1, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.1, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.1, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.1, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.811) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.1, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=0.1, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=1, subsample=0.6; AUC: (test=0.827) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=1, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=1, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=1, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=1, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.828) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=1, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.848) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.3, reg_alpha=1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.795) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.822) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.795) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.855) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.001, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.001, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.001, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.822) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.001, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.001, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.001, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.828) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.001, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.001, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.001, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.001, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.001, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.865) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.001, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.835) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.005, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.005, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.005, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.825) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.005, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.795) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.005, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.005, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.005, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.005, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.005, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.005, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.005, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.865) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.005, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.01, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.01, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.01, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.825) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.01, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.795) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.01, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.01, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.01, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.5s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.01, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.852) total time=   6.0s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.01, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.01, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.01, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.01, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.05, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.795) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.05, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.05, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.05, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.05, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.05, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.05, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.05, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.05, subsample=0.8; AUC: (test=0.889) Accuracy: (test=0.835) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.05, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.05, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.05, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.1, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.1, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.822) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.1, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.1, subsample=0.7; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.1, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.1, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.1, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.1, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.855) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=0.1, subsample=0.9; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=1, subsample=0.6; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.828) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=1, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=1, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=1, subsample=0.7; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=1, subsample=0.8; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=1, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=1, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.848) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.8, gamma=0.4, reg_alpha=1, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.795) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0, subsample=0.6; AUC: (test=0.882) Accuracy: (test=0.825) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   2.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.865) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.001, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.795) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.001, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.001, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.825) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.001, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.001, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.862) total time=   2.4s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.001, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.001, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.001, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.001, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.001, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.001, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.865) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.001, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   2.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.005, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.795) total time=   2.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.005, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.005, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.825) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.005, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.005, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.865) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.005, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.005, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.005, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.005, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.005, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.005, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.865) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.005, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.832) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.01, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.795) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.01, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.01, subsample=0.6; AUC: (test=0.882) Accuracy: (test=0.825) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.01, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.01, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.865) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.01, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.01, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.01, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.01, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.01, subsample=0.9; AUC: (test=0.828) Accuracy: (test=0.805) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.01, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.865) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.01, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.05, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.795) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.05, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.05, subsample=0.6; AUC: (test=0.882) Accuracy: (test=0.825) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.05, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.05, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.05, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.05, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.05, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.05, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.05, subsample=0.9; AUC: (test=0.828) Accuracy: (test=0.805) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.05, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.05, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.1, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.795) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.1, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.825) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.1, subsample=0.7; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.1, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.1, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.825) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.1, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.1, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.1, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.1, subsample=0.9; AUC: (test=0.828) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.1, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.862) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=0.1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=1, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=1, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.855) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=1, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=1, subsample=0.7; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=1, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.852) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.825) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=1, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.0, reg_alpha=1, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.825) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.795) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.825) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0, subsample=0.7; AUC: (test=0.889) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0, subsample=0.9; AUC: (test=0.828) Accuracy: (test=0.805) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0, subsample=0.9; AUC: (test=0.881) Accuracy: (test=0.865) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.001, subsample=0.6; AUC: (test=0.825) Accuracy: (test=0.795) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.001, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.001, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.825) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.001, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.001, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.862) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.001, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.001, subsample=0.8; AUC: (test=0.824) Accuracy: (test=0.801) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.001, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.001, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.001, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.001, subsample=0.9; AUC: (test=0.881) Accuracy: (test=0.859) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.001, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.005, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.005, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.859) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.005, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.825) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.005, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.005, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.005, subsample=0.7; AUC: (test=0.887) Accuracy: (test=0.828) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.005, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.005, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.862) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.005, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.005, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.005, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.865) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.005, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.01, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.01, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.01, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.825) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.01, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.01, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.01, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.01, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.01, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.01, subsample=0.8; AUC: (test=0.889) Accuracy: (test=0.835) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.01, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.01, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.865) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.01, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.05, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.801) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.05, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.05, subsample=0.6; AUC: (test=0.882) Accuracy: (test=0.825) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.05, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.05, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.05, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.05, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.05, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.05, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.05, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.05, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.05, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.1, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.795) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.859) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.1, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.825) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.1, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.1, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.1, subsample=0.7; AUC: (test=0.889) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.1, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.1, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.1, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.1, subsample=0.9; AUC: (test=0.828) Accuracy: (test=0.808) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.1, subsample=0.9; AUC: (test=0.881) Accuracy: (test=0.859) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=0.1, subsample=0.9; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=1, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=1, subsample=0.6; AUC: (test=0.887) Accuracy: (test=0.852) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=1, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=1, subsample=0.7; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.852) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=1, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.852) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.825) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=1, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.1, reg_alpha=1, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.825) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0, subsample=0.6; AUC: (test=0.882) Accuracy: (test=0.825) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0, subsample=0.9; AUC: (test=0.828) Accuracy: (test=0.808) total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0, subsample=0.9; AUC: (test=0.881) Accuracy: (test=0.865) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.001, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.795) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.001, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.001, subsample=0.6; AUC: (test=0.882) Accuracy: (test=0.825) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.001, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.001, subsample=0.7; AUC: (test=0.882) Accuracy: (test=0.859) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.001, subsample=0.7; AUC: (test=0.889) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.001, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.001, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.859) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.001, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.001, subsample=0.9; AUC: (test=0.828) Accuracy: (test=0.808) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.001, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.865) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.001, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.005, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.795) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.005, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.005, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.825) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.005, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.005, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.865) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.005, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.005, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.005, subsample=0.8; AUC: (test=0.881) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.005, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.005, subsample=0.9; AUC: (test=0.828) Accuracy: (test=0.811) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.005, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.865) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.005, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   2.4s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.01, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.798) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.01, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.01, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.825) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.01, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.801) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.01, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.01, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.01, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.01, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.862) total time=   2.4s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.01, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.01, subsample=0.9; AUC: (test=0.828) Accuracy: (test=0.808) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.01, subsample=0.9; AUC: (test=0.881) Accuracy: (test=0.862) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.01, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.05, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.795) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.05, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.05, subsample=0.6; AUC: (test=0.882) Accuracy: (test=0.825) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.05, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.05, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.865) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.05, subsample=0.7; AUC: (test=0.889) Accuracy: (test=0.828) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.05, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.05, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.05, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.05, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.05, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.05, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.1, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.1, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.825) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.1, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.1, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.869) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.1, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.1, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.1, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.859) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.1, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.1, subsample=0.9; AUC: (test=0.828) Accuracy: (test=0.808) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.1, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.859) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=0.1, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=1, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=1, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=1, subsample=0.7; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=1, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.852) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=1, subsample=0.8; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.798) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=1, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.2, reg_alpha=1, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.825) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.795) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.825) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0, subsample=0.7; AUC: (test=0.882) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0, subsample=0.7; AUC: (test=0.889) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0, subsample=0.9; AUC: (test=0.828) Accuracy: (test=0.808) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0, subsample=0.9; AUC: (test=0.881) Accuracy: (test=0.865) total time=   1.6s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.001, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.001, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.001, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.825) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.001, subsample=0.7; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.001, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.865) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.001, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.001, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.001, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.001, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.001, subsample=0.9; AUC: (test=0.828) Accuracy: (test=0.808) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.001, subsample=0.9; AUC: (test=0.881) Accuracy: (test=0.865) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.001, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.005, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.795) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.005, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.005, subsample=0.6; AUC: (test=0.882) Accuracy: (test=0.825) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.005, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.005, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.855) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.005, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.005, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.005, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.005, subsample=0.8; AUC: (test=0.889) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.005, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.005, subsample=0.9; AUC: (test=0.881) Accuracy: (test=0.862) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.005, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.838) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.01, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.01, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.01, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.825) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.01, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.801) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.01, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.01, subsample=0.7; AUC: (test=0.890) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.01, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.01, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.01, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.01, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.5s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.01, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.865) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.01, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.832) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.05, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.795) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.05, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.05, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.825) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.05, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.05, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.05, subsample=0.7; AUC: (test=0.888) Accuracy: (test=0.828) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.05, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.6s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.05, subsample=0.8; AUC: (test=0.883) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.05, subsample=0.8; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.05, subsample=0.9; AUC: (test=0.828) Accuracy: (test=0.808) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.05, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.859) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.05, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.1, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.1, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.1, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.825) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.1, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.801) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.1, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.1, subsample=0.7; AUC: (test=0.889) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.1, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.1, subsample=0.8; AUC: (test=0.889) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.1, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.1, subsample=0.9; AUC: (test=0.883) Accuracy: (test=0.859) total time=   2.1s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=0.1, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=1, subsample=0.6; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.855) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=1, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=1, subsample=0.7; AUC: (test=0.826) Accuracy: (test=0.811) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=1, subsample=0.8; AUC: (test=0.885) Accuracy: (test=0.825) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=1, subsample=0.9; AUC: (test=0.826) Accuracy: (test=0.808) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=1, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.3, reg_alpha=1, subsample=0.9; AUC: (test=0.884) Accuracy: (test=0.825) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.825) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.801) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.862) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0, subsample=0.7; AUC: (test=0.890) Accuracy: (test=0.828) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0, subsample=0.8; AUC: (test=0.889) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.865) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0, subsample=0.9; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.001, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.001, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.001, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.825) total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.001, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.801) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.001, subsample=0.7; AUC: (test=0.882) Accuracy: (test=0.859) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.001, subsample=0.7; AUC: (test=0.890) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.001, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.001, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.5s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.001, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.001, subsample=0.9; AUC: (test=0.828) Accuracy: (test=0.808) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.001, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.865) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.001, subsample=0.9; AUC: (test=0.888) Accuracy: (test=0.838) total time=   1.2s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.005, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.801) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.005, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.005, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.825) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.005, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.005, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.865) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.005, subsample=0.7; AUC: (test=0.890) Accuracy: (test=0.825) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.005, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   2.0s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.005, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.005, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.005, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.005, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.865) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.005, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.838) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.01, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.801) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.01, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.01, subsample=0.6; AUC: (test=0.883) Accuracy: (test=0.825) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.01, subsample=0.7; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.01, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.865) total time=   1.9s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.01, subsample=0.7; AUC: (test=0.889) Accuracy: (test=0.832) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.01, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.01, subsample=0.8; AUC: (test=0.881) Accuracy: (test=0.859) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.01, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.832) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.01, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.01, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.01, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.05, subsample=0.6; AUC: (test=0.824) Accuracy: (test=0.795) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.05, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.05, subsample=0.6; AUC: (test=0.882) Accuracy: (test=0.825) total time=   1.7s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.05, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.05, subsample=0.7; AUC: (test=0.883) Accuracy: (test=0.862) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.05, subsample=0.7; AUC: (test=0.889) Accuracy: (test=0.825) total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.05, subsample=0.8; AUC: (test=0.825) Accuracy: (test=0.805) total time=   1.9s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.05, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.859) total time=   2.2s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.05, subsample=0.8; AUC: (test=0.889) Accuracy: (test=0.832) total time=   2.2s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.05, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   2.2s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.05, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.859) total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.05, subsample=0.9; AUC: (test=0.887) Accuracy: (test=0.835) total time=   2.0s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.1, subsample=0.6; AUC: (test=0.823) Accuracy: (test=0.798) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.1, subsample=0.6; AUC: (test=0.884) Accuracy: (test=0.855) total time=   2.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.1, subsample=0.6; AUC: (test=0.882) Accuracy: (test=0.825) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.1, subsample=0.7; AUC: (test=0.824) Accuracy: (test=0.798) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.862) total time=   2.0s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.1, subsample=0.7; AUC: (test=0.889) Accuracy: (test=0.832) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.1, subsample=0.8; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.1, subsample=0.8; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.7s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.1, subsample=0.8; AUC: (test=0.888) Accuracy: (test=0.835) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.1, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.808) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.1, subsample=0.9; AUC: (test=0.882) Accuracy: (test=0.862) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=0.1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.835) total time=   1.9s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=1, subsample=0.6; AUC: (test=0.827) Accuracy: (test=0.805) total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=1, subsample=0.6; AUC: (test=0.885) Accuracy: (test=0.852) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=1, subsample=0.6; AUC: (test=0.886) Accuracy: (test=0.828) total time=   1.4s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=1, subsample=0.7; AUC: (test=0.826) Accuracy: (test=0.808) total time=   1.8s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.855) total time=   1.4s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=1, subsample=0.7; AUC: (test=0.884) Accuracy: (test=0.828) total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=1, subsample=0.8; AUC: (test=0.826) Accuracy: (test=0.805) total time=   1.3s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=1, subsample=0.8; AUC: (test=0.884) Accuracy: (test=0.852) total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=1, subsample=0.8; AUC: (test=0.885) Accuracy: (test=0.828) total time=   1.6s\n",
      "[CV 1/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=1, subsample=0.9; AUC: (test=0.827) Accuracy: (test=0.801) total time=   1.7s\n",
      "[CV 2/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=1, subsample=0.9; AUC: (test=0.886) Accuracy: (test=0.855) total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.9, gamma=0.4, reg_alpha=1, subsample=0.9; AUC: (test=0.885) Accuracy: (test=0.832) total time=   1.8s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.02,...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=750, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.6, 0.7, 0.8, 0.9],\n",
       "                         &#x27;gamma&#x27;: [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                         &#x27;reg_alpha&#x27;: [0, 0.001, 0.005, 0.01, 0.05, 0.1, 1],\n",
       "                         &#x27;subsample&#x27;: [0.6, 0.7, 0.8, 0.9]},\n",
       "             refit=&#x27;Accuracy&#x27;,\n",
       "             scoring={&#x27;AUC&#x27;: &#x27;roc_auc&#x27;,\n",
       "                      &#x27;Accuracy&#x27;: make_scorer(accuracy_score)},\n",
       "             verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.02,...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=750, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.6, 0.7, 0.8, 0.9],\n",
       "                         &#x27;gamma&#x27;: [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                         &#x27;reg_alpha&#x27;: [0, 0.001, 0.005, 0.01, 0.05, 0.1, 1],\n",
       "                         &#x27;subsample&#x27;: [0.6, 0.7, 0.8, 0.9]},\n",
       "             refit=&#x27;Accuracy&#x27;,\n",
       "             scoring={&#x27;AUC&#x27;: &#x27;roc_auc&#x27;,\n",
       "                      &#x27;Accuracy&#x27;: make_scorer(accuracy_score)},\n",
       "             verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=750, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.02, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=750, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=0.02,...\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=750, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.6, 0.7, 0.8, 0.9],\n",
       "                         'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                         'reg_alpha': [0, 0.001, 0.005, 0.01, 0.05, 0.1, 1],\n",
       "                         'subsample': [0.6, 0.7, 0.8, 0.9]},\n",
       "             refit='Accuracy',\n",
       "             scoring={'AUC': 'roc_auc',\n",
       "                      'Accuracy': make_scorer(accuracy_score)},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "param_test1 = {\n",
    "    #'n_estimators': [100,200,500,750,1000],\n",
    "    #'max_depth': [3,5,7,9],\n",
    "    #'min_child_weight': [1,3,5],\n",
    "    'gamma':[i/10.0 for i in range(0,5)],\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "    'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05, 0.1, 1]\n",
    "    #'learning_rate': [0.01, 0.02, 0.05, 0.1]\n",
    "}\n",
    "\n",
    "scoring = {'AUC': 'roc_auc', 'Accuracy': make_scorer(accuracy_score)}\n",
    "\n",
    "'''\n",
    "fit_params={\"early_stopping_rounds\":42, \n",
    "            \"eval_metric\" : \"mae\", \n",
    "            \"eval_set\" : [[test_features, test_labels]]}\n",
    "            \n",
    "'''\n",
    "\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier(learning_rate=0.02, n_estimators=750,\n",
    "                   max_depth= 3, min_child_weight= 1), \n",
    "                       param_grid = param_test1, #fit_params=fit_params,\n",
    "                       scoring=scoring, cv=3, verbose = 5, refit='Accuracy')\n",
    "gsearch1.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0.005, 'subsample': 0.9},\n",
       " 0.8372615039281706)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gsearch1.grid_scores_, \n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = gsearch1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\porvakan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\porvakan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\porvakan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\porvakan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\porvakan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_AUC'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\porvakan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\porvakan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\porvakan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\porvakan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "C:\\Users\\porvakan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_Accuracy'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.50171216, 0.48533201, 0.44432712, 0.43032408, 0.52132289,\n",
       "        0.50332848, 0.49100502, 0.42567857, 0.47033389, 0.51866531,\n",
       "        0.4810005 , 0.43034784, 0.49627948, 0.53554138, 0.52671417,\n",
       "        0.56016843, 0.53707266, 0.54496495, 0.46766321, 0.69413503,\n",
       "        1.0046157 , 0.89752666, 0.58700053, 0.4650054 , 0.73066799,\n",
       "        0.61600272, 0.70261327, 0.58838892, 0.582244  , 0.60976156,\n",
       "        0.5636394 , 0.53266454, 0.60933582, 0.58867017, 0.55732902,\n",
       "        0.46900511, 0.54167287, 0.51334159, 0.45300921, 0.43101072,\n",
       "        0.48300123, 0.47600142, 0.45100602, 0.44966857, 0.48200782,\n",
       "        0.56237817, 0.45967484, 0.46334751, 0.49396261, 0.54905574,\n",
       "        0.50133999, 0.48633798, 0.48632852, 0.51699956, 0.58482448,\n",
       "        0.53633714, 0.48900795, 0.48967687, 0.51033711, 0.53226527,\n",
       "        0.49367023, 0.55166936, 0.67533644, 0.44101   , 0.5443422 ,\n",
       "        0.48352631, 0.46533593, 0.47167031, 0.47233534, 0.46934215,\n",
       "        0.45400675, 0.45467122, 0.54449956, 0.53966761, 0.44800679,\n",
       "        0.44633738, 0.52347644, 0.52766458, 0.47348793, 0.43101525,\n",
       "        0.49033483, 0.49334248, 0.45733492, 0.5793403 , 0.49400751,\n",
       "        0.50043511, 0.66301107, 0.53200277, 0.7090253 , 0.66892719,\n",
       "        0.51566927, 0.46266484, 0.50267418, 0.5413723 , 0.52667578,\n",
       "        0.45366979, 0.47233796, 0.49100804, 0.53225239, 0.68736529,\n",
       "        0.53222235, 0.73407451, 0.75169683, 0.56834507, 0.53200618,\n",
       "        0.53193212, 0.93345658, 0.68961692, 0.88904039, 1.22085826,\n",
       "        0.80228051, 0.66512005, 0.77161717, 0.55100155, 0.62400738,\n",
       "        0.59433722, 0.62616611, 0.55333185, 1.05874602, 0.58400281,\n",
       "        0.47668552, 0.51034705, 0.4760077 , 0.46102158, 0.49967162,\n",
       "        0.50211294, 0.46034018, 0.48719939, 0.49900587, 0.57547927,\n",
       "        0.63851261, 0.47466811, 0.54229426, 0.52515833, 0.50906928,\n",
       "        0.53586507, 0.63433949, 0.51766992, 0.57600069, 0.64529339,\n",
       "        0.72833745, 0.60541129, 0.56533376, 0.54407422, 0.59855962,\n",
       "        0.63615823, 0.59949986, 0.52209767, 0.71108476, 0.58667374,\n",
       "        0.66242528, 0.58555349, 0.64081081, 0.59917672, 0.58087818,\n",
       "        0.66533359, 0.62775795, 0.58374834, 0.51368292, 0.49580264,\n",
       "        0.55633863, 0.52167598, 0.50268189, 0.5056622 , 0.55969779,\n",
       "        0.63094505, 0.56833609, 0.58011937, 0.61581953, 0.5506777 ,\n",
       "        0.59136176, 0.54240123, 0.61706058, 0.56366706, 0.58972875,\n",
       "        0.5508217 , 0.61466996, 0.58833536, 0.64375647, 0.68597794,\n",
       "        0.56866121, 0.88652007, 0.75973137, 0.47700882, 0.55302151,\n",
       "        1.07971891, 0.66737676, 0.63568107, 1.78170498, 2.89823826,\n",
       "        1.16923682, 0.66254512, 0.64525255, 0.57392995, 0.58795214,\n",
       "        0.52467362, 0.56809187, 0.6337986 , 0.58267268, 0.49734155,\n",
       "        0.55851984, 0.59715064, 0.57367349, 0.63834771, 0.77175411,\n",
       "        0.67167719, 0.65902869, 0.64867417, 0.64526916, 0.65025703,\n",
       "        0.54131564, 0.573481  , 0.58386461, 0.62354334, 0.6376702 ,\n",
       "        0.64933896, 0.60708475, 0.62467257, 0.72888446, 0.58134039,\n",
       "        0.5943919 , 0.60000237, 0.54866862, 0.5643998 , 0.62319032,\n",
       "        0.57303596, 0.57313768, 0.56434536, 0.66497819, 0.62438941,\n",
       "        0.56166712, 0.58286985, 0.63911589, 0.66736348, 0.64200735,\n",
       "        0.55467383, 0.58067457, 0.65557607, 0.61467338, 0.61604397,\n",
       "        0.57988946, 0.58693926, 0.58113098, 0.62326511, 0.64113744,\n",
       "        0.59929848, 0.52235397, 0.57473191, 0.59701459, 0.65667534,\n",
       "        0.53800535, 0.47134018, 0.63833658, 0.57731366, 0.60603396,\n",
       "        0.50998886, 0.57464663, 0.56865454, 0.58565998, 0.53895322,\n",
       "        0.56131617, 0.70113571, 0.56882819, 0.58270566, 0.63863595,\n",
       "        0.64604632, 0.52832063, 0.566161  , 0.67503778, 0.58911626,\n",
       "        0.61631838, 0.53965831, 0.58531308, 0.57232149, 0.49798854,\n",
       "        0.48733433, 0.63232279, 0.5959874 , 0.57673955, 0.60085996,\n",
       "        0.78130746, 0.73864428, 0.56831837, 0.5998199 , 0.66283973,\n",
       "        0.6129849 , 0.62289143, 0.63497678, 0.63518834, 0.6220452 ,\n",
       "        0.60889173, 0.59799019, 0.62497894, 0.6816415 , 0.69965744,\n",
       "        0.61221377, 0.64597901, 0.62198257, 0.543516  , 0.54481236,\n",
       "        0.6944414 , 0.65278172, 0.58432388, 0.63971281, 0.61298251,\n",
       "        0.66391079, 0.71398067, 0.75119805, 0.76380777, 0.89457766,\n",
       "        0.59798694, 0.67297737, 0.74192381, 0.65770682, 0.56050316,\n",
       "        0.57431118, 0.68131455, 0.54531852, 0.56589635, 0.51998639,\n",
       "        0.56732853, 0.59031534, 0.68853156, 0.63953686, 0.7898767 ,\n",
       "        0.6325984 , 0.63998675, 0.52665305, 0.56953939, 0.5805672 ,\n",
       "        0.76017388, 0.60065802, 0.81645004, 0.60864981, 0.77288532,\n",
       "        0.59725523, 0.70838801, 0.81339097, 0.65229869, 0.63618731,\n",
       "        0.64932187, 0.67268586, 0.63075932, 0.58042288, 0.62431661,\n",
       "        0.60456427, 0.72589954, 0.62673251, 0.65202149, 0.63038508,\n",
       "        0.63618207, 0.69338536, 0.69650078, 0.65934269, 0.65370297,\n",
       "        0.62395223, 0.65185833, 0.62226876, 0.59265192, 0.58459266,\n",
       "        0.66856003, 0.59650882, 0.56501714, 0.54442946, 0.58065494,\n",
       "        0.71104193, 0.62131643, 0.72812144, 0.74230997, 0.65544057,\n",
       "        0.81479049, 0.59618362, 0.98730763, 0.58699218, 0.88895043,\n",
       "        0.84954707, 0.58199024, 0.60342431, 0.62697864, 0.60831785,\n",
       "        0.64430992, 0.58799044, 0.68798161, 0.56097881, 0.57931781,\n",
       "        0.59015218, 0.57165623, 0.54340728, 0.58605512, 0.62715069,\n",
       "        0.5733215 , 0.53958797, 0.75134635, 0.7764345 , 0.67698352,\n",
       "        0.5943106 , 0.644648  , 0.62465684, 0.59799226, 0.59018286,\n",
       "        0.64111392, 0.60165675, 0.65144936, 0.57069095, 0.63565715,\n",
       "        0.6439863 , 0.73649319, 0.55966012, 0.735485  , 0.60381619,\n",
       "        0.60654306, 0.6589911 , 0.68020193, 0.64497423, 0.58966049,\n",
       "        0.63097207, 0.65471228, 0.66637699, 0.59089812, 0.58228763,\n",
       "        0.70214391, 0.79703244, 0.87576429, 0.61533125, 0.82400179,\n",
       "        0.78615642, 0.62466399, 0.63625391, 0.71731965, 0.70399046,\n",
       "        0.68224104, 0.68705177, 0.6929961 , 0.64674568, 0.69144384,\n",
       "        0.86712941, 0.77165596, 0.68921844, 0.74910673, 0.64332143,\n",
       "        0.69666433, 0.66332277, 0.70161088, 0.69632419, 0.64665604,\n",
       "        0.62032056, 0.58432992, 0.58433374, 0.68532761, 0.69998884,\n",
       "        0.65166322, 0.6039834 , 0.67955256, 0.61709706, 0.63459667,\n",
       "        0.59198602, 0.6986866 , 0.59465702, 0.64614256, 0.56166617,\n",
       "        0.60933145, 0.60965943, 0.59398524, 0.74766167, 0.78921461,\n",
       "        0.68670154, 0.67966596, 0.68665942, 0.71165744, 0.64427408,\n",
       "        0.6336542 , 0.7146341 , 0.70466073, 0.71798857, 0.70165793,\n",
       "        0.64399831, 0.7259868 , 0.79991547, 0.73033094, 0.93098672,\n",
       "        0.7262764 , 0.68099244, 0.6961298 , 0.70098527, 0.76615143,\n",
       "        0.67490975, 0.60899949, 0.59466084, 0.68233069, 0.68365343,\n",
       "        0.67839503, 0.58252382, 0.75476956, 0.661666  , 0.69267615,\n",
       "        0.59600051, 0.68232489, 0.63665779, 0.58432817, 0.60165922,\n",
       "        0.67941769, 0.7253325 , 0.71251456, 0.69079614, 0.70432512,\n",
       "        0.66631269, 0.57299058, 0.5676566 , 0.60465789, 0.65342156,\n",
       "        0.6556553 , 0.63969509, 0.64531946, 0.71372557, 0.71507295,\n",
       "        0.6706593 , 0.64299774, 0.77469254, 0.79679966, 0.65455174,\n",
       "        0.72927237, 0.73754795, 0.94932119, 0.88352299, 0.70327131,\n",
       "        0.81198859, 0.61599731, 0.59199293, 0.6189882 , 0.70098893,\n",
       "        1.03549131, 0.90821791, 0.90416288, 0.78651245, 0.66662653,\n",
       "        0.62668284, 0.64190777, 0.6196719 , 0.62533418, 0.63266754,\n",
       "        0.7046651 , 0.68576018, 0.7062916 , 0.81566525, 0.75166035,\n",
       "        0.74513714, 0.71606755, 0.61899829, 0.64699109, 0.73116366,\n",
       "        0.70101015, 0.64172753, 0.68400288, 0.75128889, 0.64308596,\n",
       "        0.73204311, 0.77353056, 0.67515604, 0.62030983, 0.67359312]),\n",
       " 'std_fit_time': array([2.30831561e-02, 2.58867344e-02, 1.69722798e-03, 3.29521371e-03,\n",
       "        4.38251317e-02, 2.17391167e-02, 6.54601231e-02, 1.22581445e-02,\n",
       "        1.16016661e-02, 3.54276921e-02, 3.05389841e-02, 5.72905662e-03,\n",
       "        1.25825588e-02, 5.58422174e-02, 2.51799685e-02, 1.60115378e-01,\n",
       "        5.10310324e-02, 2.43280907e-02, 2.50015829e-02, 2.03687537e-01,\n",
       "        2.53035019e-01, 9.93890497e-02, 1.14056391e-01, 2.67267351e-02,\n",
       "        7.58612375e-02, 1.62552626e-01, 1.36079612e-01, 9.03320196e-02,\n",
       "        3.51671664e-02, 8.60219346e-02, 9.90008468e-02, 4.39365443e-02,\n",
       "        6.46283926e-02, 7.64353078e-02, 4.19691412e-02, 3.82173026e-02,\n",
       "        4.61980598e-02, 1.77747455e-02, 2.08301248e-02, 9.94101476e-03,\n",
       "        6.97580372e-03, 2.35097594e-02, 2.40925037e-02, 3.35565529e-02,\n",
       "        2.22046415e-02, 1.05784492e-01, 3.70252075e-02, 5.91799766e-02,\n",
       "        3.32279852e-02, 5.93208515e-02, 6.48818002e-02, 5.15289626e-02,\n",
       "        1.25441535e-03, 4.01025279e-02, 5.76817478e-02, 2.16385569e-02,\n",
       "        1.20204006e-02, 4.76167895e-02, 5.18963977e-02, 9.78525985e-02,\n",
       "        3.08153317e-02, 1.22666368e-01, 9.53153060e-03, 8.82815481e-03,\n",
       "        6.69495066e-02, 3.14604320e-02, 4.22095917e-02, 5.40915471e-02,\n",
       "        1.38190383e-02, 2.16377765e-02, 2.00084555e-02, 2.36975961e-02,\n",
       "        5.45938575e-02, 4.37157846e-02, 5.71888896e-03, 3.29975318e-02,\n",
       "        3.29481693e-02, 3.14125606e-02, 2.64571768e-02, 3.55338884e-03,\n",
       "        2.81974071e-02, 4.35340865e-02, 2.22304037e-02, 1.11862495e-01,\n",
       "        2.50148197e-02, 4.28208307e-02, 4.65534454e-02, 4.38490469e-02,\n",
       "        1.27072331e-01, 7.87363077e-02, 1.79318967e-02, 5.29193478e-02,\n",
       "        4.27056935e-02, 5.09437161e-02, 1.11547670e-01, 3.26735767e-02,\n",
       "        1.20460641e-02, 4.76811447e-02, 3.11494538e-02, 1.90399771e-01,\n",
       "        3.12212425e-02, 2.12783903e-01, 1.83526864e-01, 7.74577708e-02,\n",
       "        5.47880162e-02, 3.82130100e-02, 1.45425309e-01, 1.21867819e-01,\n",
       "        1.18110238e-01, 1.39357464e-01, 1.26582087e-01, 3.08382516e-01,\n",
       "        1.56141192e-01, 6.29945524e-02, 1.03701415e-01, 1.11655221e-01,\n",
       "        4.23517237e-02, 4.98733079e-02, 2.34318806e-01, 4.80044909e-02,\n",
       "        1.15553532e-02, 3.97450481e-02, 1.76542238e-02, 2.48312942e-02,\n",
       "        3.70399953e-02, 2.50502065e-02, 1.06545756e-02, 4.05233120e-02,\n",
       "        2.09799328e-02, 1.26871454e-02, 1.71343285e-01, 3.86106328e-03,\n",
       "        2.85480713e-02, 4.33977416e-02, 6.50818978e-02, 1.23076032e-02,\n",
       "        1.53215041e-01, 4.08272251e-02, 7.47412316e-02, 1.86061864e-01,\n",
       "        2.18981818e-01, 7.09870630e-02, 5.85169078e-02, 3.39283762e-02,\n",
       "        2.03451725e-02, 4.61872454e-02, 1.18762661e-02, 4.62185884e-02,\n",
       "        9.46424204e-02, 5.17932041e-02, 7.26762251e-02, 7.39055173e-02,\n",
       "        1.16446069e-01, 6.00157038e-02, 3.58196735e-02, 9.16857510e-02,\n",
       "        5.01536979e-03, 9.32056891e-02, 3.42039867e-02, 1.38945405e-02,\n",
       "        4.53450283e-02, 3.19346465e-02, 2.92268407e-02, 3.27050974e-02,\n",
       "        1.87153525e-02, 7.14366022e-02, 9.80951073e-03, 8.22672377e-02,\n",
       "        3.32804713e-02, 2.72640158e-02, 1.18128641e-01, 5.78830519e-02,\n",
       "        7.73948917e-02, 5.64033110e-02, 1.65438608e-02, 4.19375231e-02,\n",
       "        1.32704603e-02, 3.24992044e-02, 1.13001553e-01, 1.31963770e-01,\n",
       "        3.83890912e-02, 1.97685606e-01, 2.33055086e-01, 1.04237866e-02,\n",
       "        1.86838482e-02, 5.03649386e-02, 1.80651719e-01, 1.29386815e-01,\n",
       "        1.27733202e+00, 5.03330144e-01, 1.41048218e-01, 1.72473274e-02,\n",
       "        7.32481282e-02, 4.40860675e-02, 5.59404285e-02, 4.64569071e-02,\n",
       "        3.61751345e-02, 3.48658825e-02, 5.74453853e-02, 2.10733455e-02,\n",
       "        3.22980245e-02, 7.69822428e-02, 5.47794400e-02, 6.83744754e-02,\n",
       "        5.47388816e-02, 5.93996171e-02, 6.76485936e-02, 1.07128380e-01,\n",
       "        2.96117524e-02, 1.03023790e-01, 4.59120501e-02, 3.09813765e-02,\n",
       "        8.46578648e-02, 3.47090203e-02, 4.57408491e-02, 8.34276160e-02,\n",
       "        6.98564411e-02, 7.67362641e-02, 1.57952668e-01, 6.37318829e-02,\n",
       "        5.63806824e-02, 5.30761607e-02, 3.28924075e-02, 3.56234028e-02,\n",
       "        2.08644952e-02, 3.12719842e-02, 7.28894970e-02, 3.39023845e-02,\n",
       "        7.65324776e-02, 8.00631891e-02, 8.09651298e-02, 7.04333087e-02,\n",
       "        9.29237610e-02, 4.34385346e-02, 8.87293424e-02, 1.86620169e-02,\n",
       "        6.21917641e-02, 1.51112531e-02, 3.07297920e-02, 2.51876383e-02,\n",
       "        5.53927574e-02, 2.69725740e-02, 4.13506563e-02, 5.30265003e-02,\n",
       "        9.93356405e-02, 4.06129849e-02, 5.21352030e-02, 5.66314869e-02,\n",
       "        8.28488089e-02, 1.36716923e-01, 3.02450170e-02, 8.65363209e-03,\n",
       "        1.65006318e-02, 3.73138240e-02, 6.19597681e-02, 1.71442816e-02,\n",
       "        9.88117912e-03, 2.51027876e-02, 3.81293225e-02, 6.93151469e-02,\n",
       "        3.04417932e-02, 1.27909937e-01, 1.73480520e-02, 5.67116265e-02,\n",
       "        8.74699217e-02, 1.00184282e-01, 2.74730176e-02, 4.73853906e-02,\n",
       "        8.90372421e-02, 9.21827073e-02, 1.36604316e-01, 3.69654368e-02,\n",
       "        1.99444529e-02, 6.25283711e-02, 1.06144650e-02, 2.13055248e-02,\n",
       "        3.41637730e-02, 7.14815819e-02, 3.52484330e-02, 2.18753304e-02,\n",
       "        2.37881824e-02, 1.04850595e-01, 3.96761637e-02, 6.15126997e-02,\n",
       "        2.89403069e-02, 3.11541875e-02, 8.10300247e-02, 2.47059111e-02,\n",
       "        5.54999843e-02, 3.03370278e-02, 2.06218558e-02, 6.20357686e-02,\n",
       "        3.34416827e-02, 1.29567141e-01, 1.34132109e-01, 5.53212849e-02,\n",
       "        5.35914499e-02, 6.37215592e-02, 1.79171740e-02, 2.01431982e-02,\n",
       "        4.52187161e-02, 6.80174357e-02, 2.98252371e-02, 5.58536827e-02,\n",
       "        2.03170376e-02, 5.51923310e-02, 5.18900693e-02, 7.60154765e-02,\n",
       "        1.59410218e-01, 9.37604720e-02, 9.11263100e-02, 2.83351761e-02,\n",
       "        4.75504610e-02, 2.79836410e-02, 1.11200983e-02, 4.65553795e-02,\n",
       "        4.85774293e-02, 9.39297209e-03, 1.74718873e-02, 8.03877203e-03,\n",
       "        3.67493005e-03, 2.47295282e-02, 7.55361297e-02, 4.91344485e-02,\n",
       "        2.01895328e-01, 4.76035748e-02, 1.22502234e-01, 1.35222623e-02,\n",
       "        1.77763874e-02, 1.80546804e-02, 2.14439074e-01, 7.19436952e-02,\n",
       "        8.79967205e-02, 2.83934595e-02, 2.77701461e-01, 4.28395478e-02,\n",
       "        5.50833554e-02, 1.28512212e-01, 3.96553001e-02, 7.32234893e-02,\n",
       "        6.03927896e-02, 7.18908873e-02, 1.60676782e-02, 4.19785058e-02,\n",
       "        1.97697853e-02, 1.11813047e-02, 2.44326441e-01, 9.01981973e-02,\n",
       "        4.49242522e-02, 6.84518898e-02, 4.75765821e-02, 7.83485808e-02,\n",
       "        9.37081235e-02, 3.50724995e-02, 6.22484197e-02, 7.76878044e-02,\n",
       "        4.32669164e-02, 4.79081321e-02, 1.64399018e-02, 6.10515983e-02,\n",
       "        1.99205143e-02, 5.49382123e-02, 1.59088947e-02, 2.97695330e-02,\n",
       "        3.29168327e-03, 4.12244891e-02, 5.15435055e-02, 1.57442798e-01,\n",
       "        6.30717734e-02, 6.69710404e-02, 1.88123733e-01, 4.46728252e-02,\n",
       "        2.83784336e-01, 2.24686677e-02, 1.74381850e-01, 2.74018461e-01,\n",
       "        4.07732706e-03, 5.88678032e-02, 6.70852070e-02, 4.12471399e-02,\n",
       "        4.97524126e-02, 1.33754786e-02, 1.51395744e-01, 2.19626866e-02,\n",
       "        1.81170169e-02, 1.78745958e-02, 3.85930478e-02, 2.34664535e-02,\n",
       "        2.38079090e-02, 3.36477465e-02, 3.78057070e-02, 1.11060155e-02,\n",
       "        1.45277326e-01, 1.45953079e-01, 1.02394425e-01, 1.53309637e-02,\n",
       "        5.66424795e-02, 1.29195354e-02, 3.63687506e-02, 4.31798634e-02,\n",
       "        5.01222612e-02, 2.81117019e-02, 7.39146324e-02, 2.36289793e-02,\n",
       "        2.89822195e-02, 4.82511507e-02, 9.38133096e-02, 2.09817658e-02,\n",
       "        4.64880509e-02, 6.47235073e-02, 8.06835877e-02, 6.06467130e-02,\n",
       "        6.11046475e-02, 7.85169346e-02, 2.58993184e-02, 7.74965121e-02,\n",
       "        3.58605455e-02, 4.65962389e-02, 3.34808834e-02, 5.14915557e-02,\n",
       "        5.81938774e-02, 1.84338748e-01, 1.06689440e-01, 3.64138458e-02,\n",
       "        9.19713301e-02, 1.39744492e-01, 2.74709682e-02, 1.75722987e-02,\n",
       "        4.22458781e-02, 7.45500233e-02, 2.78646475e-02, 9.79578440e-02,\n",
       "        8.34351577e-02, 3.11560965e-02, 5.37600758e-02, 1.73332435e-01,\n",
       "        1.20167018e-01, 6.99275521e-02, 3.07688394e-02, 3.91688280e-02,\n",
       "        5.74251923e-02, 4.62243534e-02, 6.32426079e-02, 9.50648713e-02,\n",
       "        4.61973294e-02, 1.30227268e-02, 2.47950115e-02, 3.38042037e-02,\n",
       "        6.37868950e-02, 5.76943396e-02, 2.03396175e-02, 2.80851747e-02,\n",
       "        2.01366886e-02, 1.58942077e-02, 2.33934565e-02, 7.47521152e-03,\n",
       "        8.90378091e-02, 8.25780896e-03, 7.26170027e-02, 2.50377347e-03,\n",
       "        2.48593330e-03, 1.24999478e-02, 2.67745689e-02, 5.52721152e-02,\n",
       "        4.73594731e-02, 3.52293792e-02, 4.71502003e-02, 1.11072895e-01,\n",
       "        5.03379518e-02, 3.83284197e-02, 4.03340519e-02, 5.68485297e-02,\n",
       "        4.96070533e-02, 5.59321321e-02, 1.73268892e-02, 4.15193640e-02,\n",
       "        6.89833438e-02, 1.08253378e-01, 7.16736304e-02, 1.51338940e-01,\n",
       "        2.11497677e-02, 3.43197346e-02, 4.42582199e-02, 1.08566110e-01,\n",
       "        3.86584685e-02, 4.18425060e-02, 3.82118282e-02, 3.67475140e-02,\n",
       "        3.96715995e-02, 6.66997803e-02, 7.67328549e-02, 3.70193642e-02,\n",
       "        3.49594933e-02, 5.75927625e-02, 4.33067151e-02, 2.84438527e-02,\n",
       "        8.05016598e-02, 6.27579988e-02, 2.00688191e-02, 2.45539927e-02,\n",
       "        1.01785488e-01, 7.53082141e-02, 8.65644234e-02, 5.99453656e-02,\n",
       "        2.28389156e-02, 7.82504881e-02, 4.31742168e-03, 5.43979692e-03,\n",
       "        3.30231446e-03, 3.35497212e-02, 9.39639870e-02, 2.90634796e-02,\n",
       "        1.82676887e-02, 4.57785220e-02, 7.57222198e-02, 4.32381164e-02,\n",
       "        3.23754587e-02, 1.21021147e-01, 1.00698800e-01, 4.37614246e-02,\n",
       "        6.47844087e-03, 7.35881423e-02, 8.47827971e-02, 6.16249075e-02,\n",
       "        6.93075991e-02, 1.94886480e-01, 4.52119159e-02, 3.25667985e-02,\n",
       "        1.08104592e-02, 9.27383047e-02, 2.42946501e-01, 2.28334838e-01,\n",
       "        4.18130337e-02, 4.20650051e-02, 2.49257006e-02, 4.40698289e-02,\n",
       "        2.25295271e-02, 2.37922769e-02, 3.68075927e-02, 5.31005359e-02,\n",
       "        6.89751553e-02, 9.91567857e-03, 8.05047883e-02, 1.10936092e-01,\n",
       "        4.17321562e-02, 5.53660858e-02, 1.73559156e-02, 9.13725058e-02,\n",
       "        4.67174301e-02, 1.12593775e-01, 4.04778096e-02, 1.07532167e-01,\n",
       "        4.19094769e-02, 5.15685866e-02, 2.66537826e-02, 8.07932830e-02,\n",
       "        9.53405589e-02, 3.63226637e-02, 3.76435850e-02, 2.53326568e-02]),\n",
       " 'mean_score_time': array([0.01666609, 0.01666903, 0.01666657, 0.01733343, 0.01734082,\n",
       "        0.02299794, 0.01799464, 0.01665513, 0.01666204, 0.01766864,\n",
       "        0.01699789, 0.01732135, 0.01933002, 0.01733398, 0.02366988,\n",
       "        0.02232869, 0.01800148, 0.02099299, 0.0203325 , 0.02400041,\n",
       "        0.03000641, 0.03455869, 0.01799846, 0.02199388, 0.0316662 ,\n",
       "        0.01832843, 0.02868311, 0.02100102, 0.02199451, 0.02899814,\n",
       "        0.02133369, 0.01866849, 0.02066763, 0.01966254, 0.02566989,\n",
       "        0.02166661, 0.01833073, 0.01799536, 0.02449449, 0.01732055,\n",
       "        0.01933583, 0.02033655, 0.01666538, 0.01733462, 0.01732866,\n",
       "        0.04032787, 0.01698295, 0.01665799, 0.01866078, 0.01833185,\n",
       "        0.0179979 , 0.01865911, 0.02299937, 0.01933352, 0.03266676,\n",
       "        0.02566751, 0.01766109, 0.01633088, 0.02032757, 0.01700886,\n",
       "        0.01666665, 0.02233108, 0.02200182, 0.01632357, 0.01932621,\n",
       "        0.01700481, 0.01700203, 0.01700608, 0.01766777, 0.0166657 ,\n",
       "        0.02099609, 0.02266137, 0.02032685, 0.02166518, 0.01766364,\n",
       "        0.01699646, 0.02133473, 0.01967541, 0.01666768, 0.01698645,\n",
       "        0.01799981, 0.01765577, 0.01766769, 0.02466647, 0.02366718,\n",
       "        0.01933972, 0.01899306, 0.0200007 , 0.02933367, 0.0189991 ,\n",
       "        0.01866913, 0.01899902, 0.01733128, 0.01832716, 0.0213275 ,\n",
       "        0.01699177, 0.01766404, 0.01798773, 0.03097868, 0.03399698,\n",
       "        0.01866651, 0.04265817, 0.02499962, 0.02399524, 0.01766245,\n",
       "        0.01799933, 0.02699916, 0.02066557, 0.02900195, 0.03700145,\n",
       "        0.0213325 , 0.02499859, 0.03733484, 0.01933352, 0.01932963,\n",
       "        0.01900037, 0.02099951, 0.02033448, 0.04133479, 0.01800132,\n",
       "        0.0163281 , 0.01799544, 0.02132638, 0.01731976, 0.01899242,\n",
       "        0.01966755, 0.0173219 , 0.01700815, 0.0173312 , 0.01966143,\n",
       "        0.02133687, 0.02299682, 0.02432744, 0.02099983, 0.01899981,\n",
       "        0.02199984, 0.02533277, 0.01800211, 0.02066533, 0.02283835,\n",
       "        0.0284218 , 0.01832946, 0.02800107, 0.01832914, 0.0199968 ,\n",
       "        0.01900291, 0.02466027, 0.01766205, 0.02133179, 0.01799631,\n",
       "        0.02766657, 0.02022139, 0.01766777, 0.01799885, 0.01953252,\n",
       "        0.02233529, 0.01866762, 0.01833113, 0.01765442, 0.0216736 ,\n",
       "        0.01732198, 0.01766086, 0.01732945, 0.02400064, 0.01832644,\n",
       "        0.02432775, 0.01766769, 0.0183328 , 0.01933471, 0.01832652,\n",
       "        0.01799909, 0.01766729, 0.01866388, 0.02099593, 0.02100714,\n",
       "        0.01898718, 0.01932844, 0.01833256, 0.02100062, 0.01899282,\n",
       "        0.01700083, 0.02399913, 0.01833375, 0.0199937 , 0.01801308,\n",
       "        0.02866793, 0.01932708, 0.02433467, 0.06300171, 0.05866647,\n",
       "        0.04450059, 0.02766315, 0.01834098, 0.01966405, 0.0199941 ,\n",
       "        0.01734304, 0.01800179, 0.01933336, 0.01867453, 0.02066541,\n",
       "        0.04366827, 0.02200246, 0.01800132, 0.01966723, 0.02166732,\n",
       "        0.02399945, 0.01966619, 0.02000777, 0.02133505, 0.01867604,\n",
       "        0.01700338, 0.02166176, 0.01832692, 0.02451976, 0.02000046,\n",
       "        0.02200087, 0.02167177, 0.02156138, 0.02399834, 0.02600233,\n",
       "        0.01800156, 0.02066342, 0.01766682, 0.01800378, 0.0183363 ,\n",
       "        0.01765537, 0.01900609, 0.01833113, 0.02066588, 0.01933646,\n",
       "        0.01767111, 0.01734424, 0.01933408, 0.02166891, 0.02166732,\n",
       "        0.01966675, 0.01933424, 0.02166843, 0.02033432, 0.02366718,\n",
       "        0.01933511, 0.02766935, 0.01766523, 0.01833447, 0.01900681,\n",
       "        0.02300151, 0.01632778, 0.01800013, 0.01966707, 0.02366686,\n",
       "        0.0203348 , 0.01600003, 0.02266486, 0.0176665 , 0.01900601,\n",
       "        0.01799989, 0.01966588, 0.01799901, 0.01899171, 0.01900411,\n",
       "        0.02166661, 0.02266208, 0.01966492, 0.02133671, 0.0236659 ,\n",
       "        0.01866905, 0.01866468, 0.01700377, 0.0220054 , 0.01766014,\n",
       "        0.02099967, 0.01766594, 0.02099848, 0.01667031, 0.02299921,\n",
       "        0.01798669, 0.02099498, 0.01699487, 0.01966461, 0.01899997,\n",
       "        0.02633397, 0.02499747, 0.01799854, 0.01932788, 0.01867421,\n",
       "        0.01732445, 0.01966723, 0.01800378, 0.01866142, 0.02233156,\n",
       "        0.02333371, 0.01899974, 0.02233315, 0.01766888, 0.0259997 ,\n",
       "        0.02000268, 0.03399976, 0.01700147, 0.01900236, 0.01666665,\n",
       "        0.01766729, 0.02167249, 0.01932891, 0.0210019 , 0.02300104,\n",
       "        0.0193336 , 0.02166843, 0.01833908, 0.02333593, 0.02466861,\n",
       "        0.01733208, 0.02633468, 0.02133377, 0.01966643, 0.01832875,\n",
       "        0.0206658 , 0.01799329, 0.01700036, 0.01732763, 0.01800831,\n",
       "        0.01798161, 0.01999966, 0.02033226, 0.01900029, 0.02466567,\n",
       "        0.01933249, 0.01699122, 0.01633167, 0.0186611 , 0.01733836,\n",
       "        0.01833407, 0.01832334, 0.02332902, 0.01867175, 0.01799973,\n",
       "        0.02066104, 0.02166661, 0.02099935, 0.01799552, 0.02300143,\n",
       "        0.02090597, 0.02000316, 0.02366384, 0.01766634, 0.01766555,\n",
       "        0.0203379 , 0.02199944, 0.02133385, 0.02366424, 0.01800791,\n",
       "        0.0180037 , 0.0240802 , 0.0216674 , 0.02033456, 0.01733327,\n",
       "        0.02100261, 0.01766801, 0.01766268, 0.01767127, 0.0193363 ,\n",
       "        0.02166351, 0.01666681, 0.01866603, 0.01832898, 0.0173347 ,\n",
       "        0.0259997 , 0.02066755, 0.03133241, 0.02600312, 0.02133425,\n",
       "        0.02599923, 0.0176665 , 0.03033527, 0.01766046, 0.01766777,\n",
       "        0.01966564, 0.01732548, 0.01766292, 0.01766594, 0.02100086,\n",
       "        0.04033415, 0.01799599, 0.02366749, 0.01833757, 0.01766769,\n",
       "        0.01833526, 0.01766515, 0.02067208, 0.01799583, 0.01766817,\n",
       "        0.02003344, 0.02066684, 0.01766912, 0.03399396, 0.02633357,\n",
       "        0.0203321 , 0.01766682, 0.02099999, 0.03000164, 0.02333943,\n",
       "        0.02133425, 0.0516665 , 0.02033377, 0.01633445, 0.02000491,\n",
       "        0.02100086, 0.0193332 , 0.01999942, 0.02166772, 0.01699789,\n",
       "        0.01766872, 0.02166573, 0.01766602, 0.02166677, 0.02733326,\n",
       "        0.01999911, 0.02633754, 0.01866523, 0.01766904, 0.01700258,\n",
       "        0.01900236, 0.01899735, 0.02199864, 0.01799544, 0.0186677 ,\n",
       "        0.02000229, 0.01732874, 0.01867477, 0.01800156, 0.01900148,\n",
       "        0.01800028, 0.01732667, 0.01932836, 0.02034116, 0.01966691,\n",
       "        0.03299999, 0.02200143, 0.01783125, 0.02500407, 0.01966429,\n",
       "        0.01832803, 0.02000173, 0.01800521, 0.02233346, 0.01766539,\n",
       "        0.01933416, 0.01733772, 0.01665926, 0.01933352, 0.02100054,\n",
       "        0.0169944 , 0.01733009, 0.01700163, 0.01833248, 0.02000125,\n",
       "        0.0176661 , 0.0209957 , 0.01733462, 0.01866849, 0.0183355 ,\n",
       "        0.02066271, 0.01799981, 0.01666601, 0.02266399, 0.01899878,\n",
       "        0.0193433 , 0.01965976, 0.02099959, 0.01833161, 0.01799933,\n",
       "        0.01833749, 0.01932979, 0.0183301 , 0.01866778, 0.01833669,\n",
       "        0.01899966, 0.02566449, 0.01833359, 0.0193398 , 0.02066771,\n",
       "        0.02050169, 0.01933336, 0.01899831, 0.01900005, 0.02166875,\n",
       "        0.01900458, 0.01732826, 0.01700314, 0.02166239, 0.01833328,\n",
       "        0.01867032, 0.01933861, 0.02133576, 0.0173262 , 0.02433244,\n",
       "        0.01699464, 0.02633413, 0.01799925, 0.01932963, 0.02833343,\n",
       "        0.02066676, 0.02433467, 0.02299539, 0.02066636, 0.02033401,\n",
       "        0.018339  , 0.0173339 , 0.01633684, 0.01733192, 0.01766706,\n",
       "        0.01766992, 0.01800084, 0.01899902, 0.02184423, 0.02100118,\n",
       "        0.01866047, 0.01700584, 0.02166828, 0.02285012, 0.01955263,\n",
       "        0.01966723, 0.02166843, 0.02333458, 0.02233291, 0.01899997,\n",
       "        0.0206689 , 0.01799464, 0.01666745, 0.01833622, 0.01834257,\n",
       "        0.02183501, 0.01933336, 0.03099942, 0.02200119, 0.01866198,\n",
       "        0.02666688, 0.01732278, 0.01766006, 0.01833399, 0.0193394 ,\n",
       "        0.01800187, 0.01933996, 0.02033448, 0.02066739, 0.02166748,\n",
       "        0.02200365, 0.01833344, 0.01933328, 0.01767683, 0.01932279,\n",
       "        0.01766141, 0.01766038, 0.01800187, 0.02433451, 0.01900101,\n",
       "        0.0226663 , 0.01866746, 0.02033488, 0.01832867, 0.0199976 ]),\n",
       " 'std_score_time': array([4.70303127e-04, 4.72383844e-04, 4.71819960e-04, 4.73450089e-04,\n",
       "        1.88234823e-03, 2.94268172e-03, 1.42070785e-03, 4.65092721e-04,\n",
       "        4.67475601e-04, 1.24621624e-03, 8.20234422e-04, 4.78626827e-04,\n",
       "        4.70869028e-04, 1.24700130e-03, 3.85530468e-03, 6.13113362e-03,\n",
       "        1.41180720e-03, 2.15306388e-03, 4.71274894e-03, 5.88727895e-03,\n",
       "        1.48946488e-02, 2.93724656e-03, 1.54512899e-06, 3.27412174e-03,\n",
       "        6.23566512e-03, 4.74599475e-04, 9.60309461e-03, 2.83232455e-03,\n",
       "        3.56122741e-03, 1.41669150e-02, 2.86595901e-03, 1.70045399e-03,\n",
       "        3.09248273e-03, 9.49237603e-04, 6.79812202e-03, 5.90530285e-03,\n",
       "        4.70583975e-04, 8.24246465e-04, 9.92784571e-03, 1.24589840e-03,\n",
       "        2.05298860e-03, 2.05053444e-03, 4.59233891e-04, 4.75141703e-04,\n",
       "        4.78729995e-04, 2.82939337e-02, 2.51063808e-06, 4.70375399e-04,\n",
       "        9.34480336e-04, 1.88542552e-03, 8.15273492e-04, 1.24039494e-03,\n",
       "        7.78801048e-03, 9.40157333e-04, 6.94359687e-03, 1.69858366e-03,\n",
       "        9.48506260e-04, 4.71599155e-04, 2.36494409e-03, 5.82162430e-06,\n",
       "        9.43077902e-04, 4.11466233e-03, 2.94389592e-03, 4.67376800e-04,\n",
       "        1.70735912e-03, 8.21403282e-04, 1.36730278e-06, 7.73136553e-06,\n",
       "        1.70113975e-03, 4.70193154e-04, 4.32747483e-03, 6.02413960e-03,\n",
       "        2.87350342e-03, 4.64142124e-03, 4.68533752e-04, 8.08310115e-04,\n",
       "        5.43592785e-03, 3.08406206e-03, 4.70415116e-04, 9.06060311e-06,\n",
       "        8.18384575e-04, 4.77632231e-04, 4.71651343e-04, 5.90778300e-03,\n",
       "        9.46383033e-03, 4.80330085e-04, 1.63135167e-03, 8.14979502e-04,\n",
       "        7.84664197e-03, 2.15983285e-03, 2.35870712e-03, 8.16050860e-04,\n",
       "        4.74124238e-04, 4.75708195e-04, 4.79377271e-03, 8.10467325e-06,\n",
       "        4.67812910e-04, 8.25698604e-04, 1.83719570e-02, 7.48171058e-03,\n",
       "        2.35685206e-03, 1.82729774e-02, 5.35462915e-03, 8.52900350e-03,\n",
       "        4.79575296e-04, 8.16145448e-04, 9.93381399e-03, 3.29852500e-03,\n",
       "        7.12023831e-03, 2.12144758e-02, 3.40525208e-03, 9.90035129e-03,\n",
       "        1.27611230e-02, 1.24919090e-03, 2.05917073e-03, 8.20818125e-04,\n",
       "        1.41366451e-03, 3.29959257e-03, 1.73064251e-02, 8.14300522e-04,\n",
       "        4.62435478e-04, 1.42905962e-03, 3.10138584e-03, 4.65503523e-04,\n",
       "        3.55095265e-03, 4.49880748e-03, 4.67185300e-04, 8.09438914e-04,\n",
       "        4.60435654e-04, 4.66195368e-04, 4.02667343e-03, 3.26750165e-03,\n",
       "        6.18774308e-03, 5.71680035e-03, 2.16141503e-03, 1.63423748e-03,\n",
       "        7.13696852e-03, 8.17411677e-04, 2.86883389e-03, 3.47276472e-03,\n",
       "        8.60797818e-03, 4.78643585e-04, 1.13150802e-02, 1.24765685e-03,\n",
       "        1.41152671e-03, 8.17703595e-04, 6.55260124e-03, 1.22954966e-03,\n",
       "        4.19139537e-03, 8.21409064e-04, 5.90785483e-03, 1.92032127e-03,\n",
       "        9.42572165e-04, 8.07667053e-04, 1.91828484e-03, 2.35887485e-03,\n",
       "        4.71145611e-04, 9.41280341e-04, 4.61592285e-04, 6.64668684e-03,\n",
       "        9.47954876e-04, 9.48003019e-04, 4.63447574e-04, 7.12055127e-03,\n",
       "        1.23918900e-03, 4.65392955e-03, 1.24698072e-03, 4.71497253e-04,\n",
       "        1.70138965e-03, 4.73949550e-04, 8.15756066e-04, 4.70023630e-04,\n",
       "        1.70241285e-03, 4.32824528e-03, 3.56669559e-03, 1.62509232e-03,\n",
       "        4.76273376e-04, 4.69122885e-04, 8.18482266e-04, 9.79226898e-06,\n",
       "        1.91065713e-06, 3.74096166e-03, 2.05278713e-03, 4.97093926e-03,\n",
       "        8.30960324e-04, 4.78486685e-03, 2.06333426e-03, 3.68154273e-03,\n",
       "        5.80336240e-02, 1.66604753e-02, 1.56085963e-02, 7.32140616e-03,\n",
       "        4.67780830e-04, 1.24515381e-03, 2.94707376e-03, 4.69728410e-04,\n",
       "        8.19948358e-04, 1.88514569e-03, 2.48746097e-03, 4.50015649e-03,\n",
       "        3.42013899e-02, 3.74221495e-03, 8.18679989e-04, 2.49270731e-03,\n",
       "        3.08883156e-03, 3.26574961e-03, 3.08877138e-03, 1.41334686e-03,\n",
       "        4.02757442e-03, 2.50674850e-03, 3.94332766e-06, 5.91114251e-03,\n",
       "        9.52462625e-04, 6.27692961e-03, 1.63326445e-03, 2.15887640e-03,\n",
       "        5.24502741e-03, 3.55829152e-03, 3.26497094e-03, 1.00320360e-02,\n",
       "        8.20233860e-04, 1.25628322e-03, 9.43585095e-04, 1.41552054e-03,\n",
       "        1.69987780e-03, 1.24901352e-03, 4.23857308e-03, 1.70144339e-03,\n",
       "        4.69685125e-04, 1.70039181e-03, 1.69922268e-03, 4.70366725e-04,\n",
       "        2.62269311e-03, 3.85911698e-03, 1.24816973e-03, 2.49410943e-03,\n",
       "        2.62297548e-03, 3.09183078e-03, 2.62446908e-03, 6.79751415e-03,\n",
       "        3.30021067e-03, 9.97940981e-03, 1.24702353e-03, 9.40608168e-04,\n",
       "        8.26769593e-04, 8.48477877e-03, 4.65020239e-04, 8.16729421e-04,\n",
       "        3.09259324e-03, 3.29925532e-03, 4.71516463e-03, 1.21570099e-06,\n",
       "        4.11007212e-03, 4.70808436e-04, 2.15981190e-03, 1.41309955e-03,\n",
       "        3.77068191e-03, 8.16534784e-04, 2.82805635e-03, 1.63337213e-03,\n",
       "        4.18825304e-03, 2.87451546e-03, 2.35758236e-03, 2.49532044e-03,\n",
       "        3.77180577e-03, 1.24487760e-03, 1.70045484e-03, 5.22711552e-06,\n",
       "        3.55602677e-03, 1.24127687e-03, 5.65492720e-03, 4.66067134e-04,\n",
       "        4.96496293e-03, 4.77712873e-04, 7.11811702e-03, 8.07691803e-04,\n",
       "        2.15730808e-03, 7.36229298e-06, 1.24626279e-03, 2.16152526e-03,\n",
       "        6.84863281e-03, 7.12571419e-03, 8.19750486e-04, 1.25090594e-03,\n",
       "        4.73491868e-04, 4.79150090e-04, 1.87240783e-03, 1.41037021e-03,\n",
       "        1.24656476e-03, 7.58709504e-03, 4.18736156e-03, 1.41383049e-03,\n",
       "        3.85925993e-03, 4.71323816e-04, 2.16303369e-03, 3.56015266e-03,\n",
       "        2.26417556e-02, 2.97360213e-07, 2.16049509e-03, 4.71713313e-04,\n",
       "        4.71876608e-04, 3.76641164e-03, 1.24659530e-03, 2.45330313e-03,\n",
       "        4.54473465e-03, 2.05527487e-03, 3.39741669e-03, 1.24594312e-03,\n",
       "        4.71943561e-03, 2.05680892e-03, 9.30448129e-04, 8.49820194e-03,\n",
       "        1.69859933e-03, 1.24630157e-03, 1.24955676e-03, 4.10882166e-03,\n",
       "        8.09833112e-04, 8.18578780e-04, 1.24124728e-03, 8.14532045e-04,\n",
       "        8.17606715e-04, 4.24441252e-03, 1.24734121e-03, 1.41512344e-03,\n",
       "        7.40783783e-03, 2.62177461e-03, 8.08854378e-04, 4.72551277e-04,\n",
       "        1.25512104e-03, 9.38586175e-04, 4.71093005e-04, 1.25422746e-03,\n",
       "        5.56410037e-03, 1.23674595e-03, 2.46494014e-06, 3.77625728e-03,\n",
       "        3.77073813e-03, 1.63297216e-03, 8.22085846e-04, 3.56169337e-03,\n",
       "        2.77781664e-03, 3.56004115e-03, 5.43874451e-03, 9.42067987e-04,\n",
       "        4.57528518e-04, 2.48637775e-03, 5.88711710e-03, 5.43418412e-03,\n",
       "        6.60238817e-03, 8.73261727e-06, 8.16145417e-04, 1.63517678e-03,\n",
       "        6.59856689e-03, 3.29953628e-03, 4.72045065e-04, 6.37604446e-03,\n",
       "        9.44933191e-04, 4.80589658e-04, 4.74695496e-04, 2.05236096e-03,\n",
       "        4.49676927e-03, 4.72157255e-04, 2.49438491e-03, 1.25407125e-03,\n",
       "        4.72719414e-04, 9.89967659e-03, 3.09275615e-03, 1.19516795e-02,\n",
       "        8.52231061e-03, 5.43800376e-03, 1.20257441e-02, 1.24959362e-03,\n",
       "        1.74381181e-02, 4.66906507e-04, 4.72552721e-04, 4.49613888e-03,\n",
       "        9.50891733e-04, 4.64613740e-04, 4.69407951e-04, 3.26730695e-03,\n",
       "        3.02138112e-02, 8.24056132e-04, 8.73184659e-03, 1.87869516e-03,\n",
       "        9.41955254e-04, 1.24555880e-03, 1.24859436e-03, 5.19063730e-03,\n",
       "        8.16256383e-04, 1.24723493e-03, 3.60729530e-03, 4.49504906e-03,\n",
       "        4.77972956e-04, 1.90989229e-02, 9.67104624e-03, 3.29841300e-03,\n",
       "        9.43078204e-04, 4.24193995e-03, 1.69678155e-02, 8.26744039e-03,\n",
       "        3.30481072e-03, 4.83319660e-02, 9.41560842e-04, 4.70921793e-04,\n",
       "        2.44610019e-03, 2.94278972e-03, 1.24749010e-03, 2.94454393e-03,\n",
       "        2.49311085e-03, 8.16535063e-04, 9.42070300e-04, 6.01828732e-03,\n",
       "        1.24787280e-03, 3.29891882e-03, 1.39130216e-02, 3.73696872e-03,\n",
       "        8.50119457e-03, 1.69733690e-03, 9.41673113e-04, 2.36022352e-06,\n",
       "        2.16067917e-03, 1.63396869e-03, 3.55838854e-03, 8.88746806e-06,\n",
       "        4.71539755e-04, 4.24053514e-03, 1.23955570e-03, 1.69458729e-03,\n",
       "        8.16438028e-04, 2.94492172e-03, 2.25624554e-06, 4.64064941e-04,\n",
       "        1.87738947e-03, 2.49967367e-03, 2.35482885e-03, 1.63909768e-02,\n",
       "        4.96766715e-03, 6.35463992e-04, 6.48163217e-03, 1.88767348e-03,\n",
       "        1.24074150e-03, 2.94106381e-03, 1.41170407e-03, 3.08845420e-03,\n",
       "        4.71371801e-04, 2.62419684e-03, 1.25097333e-03, 4.65855383e-04,\n",
       "        2.35561547e-03, 3.26584695e-03, 1.10710001e-05, 4.71428248e-04,\n",
       "        8.48537942e-07, 4.71204028e-04, 2.16064220e-03, 1.69908265e-03,\n",
       "        5.65773830e-03, 4.73450089e-04, 1.70040722e-03, 1.89719037e-03,\n",
       "        4.49810274e-03, 8.18189606e-04, 4.70921793e-04, 4.79042618e-03,\n",
       "        8.16441146e-04, 9.36957399e-04, 1.70494146e-03, 4.32076935e-03,\n",
       "        9.51733309e-04, 1.41585370e-03, 1.88531705e-03, 3.29436634e-03,\n",
       "        4.77150973e-04, 1.70017354e-03, 1.88115567e-03, 1.61837207e-03,\n",
       "        5.79200347e-03, 2.05416653e-03, 2.63020189e-03, 2.49446986e-03,\n",
       "        1.46934485e-03, 1.88430263e-03, 1.63366517e-03, 3.56412909e-03,\n",
       "        4.49954408e-03, 2.82367610e-03, 9.39052447e-04, 8.19466180e-04,\n",
       "        4.50070820e-03, 9.45832323e-04, 1.69955520e-03, 4.03208623e-03,\n",
       "        2.62412624e-03, 4.74709865e-04, 5.43478272e-03, 8.23746055e-04,\n",
       "        1.04044347e-02, 2.15869261e-03, 4.03005007e-03, 1.26583053e-02,\n",
       "        5.18563588e-03, 1.69838127e-03, 2.94949554e-03, 3.77163731e-03,\n",
       "        1.70006487e-03, 1.88038030e-03, 1.24721369e-03, 4.76991880e-04,\n",
       "        4.72327377e-04, 4.73225626e-04, 4.72060759e-04, 1.46971083e-06,\n",
       "        1.63355614e-03, 4.90185934e-03, 4.96718721e-03, 1.24540388e-03,\n",
       "        8.13365867e-04, 6.60250052e-03, 3.78431062e-03, 2.85970812e-03,\n",
       "        1.24683180e-03, 1.69758657e-03, 4.02726516e-03, 3.29829205e-03,\n",
       "        2.16123087e-03, 1.24742652e-03, 1.41867975e-03, 9.44201979e-04,\n",
       "        1.24632563e-03, 1.89351874e-03, 8.48544425e-04, 9.43752252e-04,\n",
       "        7.78839821e-03, 3.55687009e-03, 2.35989675e-03, 1.29721134e-02,\n",
       "        4.67368408e-04, 9.35379914e-04, 2.05479759e-03, 9.33693798e-04,\n",
       "        8.17897645e-04, 3.29645338e-03, 2.62550855e-03, 3.29996177e-03,\n",
       "        4.71376142e-04, 4.54098102e-03, 1.70062541e-03, 4.71409693e-03,\n",
       "        4.67389124e-04, 9.47077912e-04, 4.68475717e-04, 4.66509843e-04,\n",
       "        8.18678724e-04, 6.84791660e-03, 1.64127077e-03, 5.18316337e-03,\n",
       "        4.71541201e-04, 4.71224255e-03, 1.24624346e-03, 2.83059253e-03]),\n",
       " 'param_colsample_bytree': masked_array(data=[0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6,\n",
       "                    0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
       "                    0.7, 0.7, 0.7, 0.7, 0.7, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
       "                    0.8, 0.8, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9,\n",
       "                    0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.4,\n",
       "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.4, 0.4, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "                    0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,\n",
       "                    0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3,\n",
       "                    0.3, 0.3, 0.3, 0.3, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4,\n",
       "                    0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_reg_alpha': masked_array(data=[0, 0, 0, 0, 0.001, 0.001, 0.001, 0.001, 0.005, 0.005,\n",
       "                    0.005, 0.005, 0.01, 0.01, 0.01, 0.01, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.005, 0.005, 0.005, 0.005,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.05, 0.05, 0.05, 0.05, 0.1,\n",
       "                    0.1, 0.1, 0.1, 1, 1, 1, 1, 0, 0, 0, 0, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.005, 0.005, 0.005, 0.005, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1,\n",
       "                    1, 1, 1, 1, 0, 0, 0, 0, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.005, 0.005, 0.005, 0.005, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1,\n",
       "                    0, 0, 0, 0, 0.001, 0.001, 0.001, 0.001, 0.005, 0.005,\n",
       "                    0.005, 0.005, 0.01, 0.01, 0.01, 0.01, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.005, 0.005, 0.005, 0.005,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.05, 0.05, 0.05, 0.05, 0.1,\n",
       "                    0.1, 0.1, 0.1, 1, 1, 1, 1, 0, 0, 0, 0, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.005, 0.005, 0.005, 0.005, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1,\n",
       "                    1, 1, 1, 1, 0, 0, 0, 0, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.005, 0.005, 0.005, 0.005, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1,\n",
       "                    0, 0, 0, 0, 0.001, 0.001, 0.001, 0.001, 0.005, 0.005,\n",
       "                    0.005, 0.005, 0.01, 0.01, 0.01, 0.01, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.005, 0.005, 0.005, 0.005,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.05, 0.05, 0.05, 0.05, 0.1,\n",
       "                    0.1, 0.1, 0.1, 1, 1, 1, 1, 0, 0, 0, 0, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.005, 0.005, 0.005, 0.005, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1,\n",
       "                    1, 1, 1, 1, 0, 0, 0, 0, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.005, 0.005, 0.005, 0.005, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1,\n",
       "                    0, 0, 0, 0, 0.001, 0.001, 0.001, 0.001, 0.005, 0.005,\n",
       "                    0.005, 0.005, 0.01, 0.01, 0.01, 0.01, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.005, 0.005, 0.005, 0.005,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.05, 0.05, 0.05, 0.05, 0.1,\n",
       "                    0.1, 0.1, 0.1, 1, 1, 1, 1, 0, 0, 0, 0, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.005, 0.005, 0.005, 0.005, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1,\n",
       "                    1, 1, 1, 1, 0, 0, 0, 0, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.005, 0.005, 0.005, 0.005, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1,\n",
       "                    0, 0, 0, 0, 0.001, 0.001, 0.001, 0.001, 0.005, 0.005,\n",
       "                    0.005, 0.005, 0.01, 0.01, 0.01, 0.01, 0.05, 0.05, 0.05,\n",
       "                    0.05, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.005, 0.005, 0.005, 0.005,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.05, 0.05, 0.05, 0.05, 0.1,\n",
       "                    0.1, 0.1, 0.1, 1, 1, 1, 1, 0, 0, 0, 0, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.005, 0.005, 0.005, 0.005, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1,\n",
       "                    1, 1, 1, 1, 0, 0, 0, 0, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.005, 0.005, 0.005, 0.005, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1, 1, 1, 1, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_subsample': masked_array(data=[0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                    0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7,\n",
       "                    0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6,\n",
       "                    0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9,\n",
       "                    0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                    0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7,\n",
       "                    0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6,\n",
       "                    0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9,\n",
       "                    0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                    0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7,\n",
       "                    0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6,\n",
       "                    0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9,\n",
       "                    0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                    0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7,\n",
       "                    0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6,\n",
       "                    0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9,\n",
       "                    0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                    0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7,\n",
       "                    0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6,\n",
       "                    0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9,\n",
       "                    0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                    0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7,\n",
       "                    0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6,\n",
       "                    0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9,\n",
       "                    0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                    0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7,\n",
       "                    0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6,\n",
       "                    0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9,\n",
       "                    0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                    0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7,\n",
       "                    0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6,\n",
       "                    0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9,\n",
       "                    0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                    0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7,\n",
       "                    0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6,\n",
       "                    0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9,\n",
       "                    0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                    0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7,\n",
       "                    0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6,\n",
       "                    0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9,\n",
       "                    0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                    0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7,\n",
       "                    0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6,\n",
       "                    0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9,\n",
       "                    0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                    0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7,\n",
       "                    0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6,\n",
       "                    0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9,\n",
       "                    0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8,\n",
       "                    0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7,\n",
       "                    0.8, 0.9, 0.6, 0.7, 0.8, 0.9, 0.6, 0.7, 0.8, 0.9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'colsample_bytree': 0.6,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.0, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.1, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.2, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.3, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.6, 'gamma': 0.4, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.0, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.1, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.2, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.3, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.7, 'gamma': 0.4, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.0, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.1, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.2, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.3, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.8, 'gamma': 0.4, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.0,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.0, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.1,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.1, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.2,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.2, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.3,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.3, 'reg_alpha': 1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 0, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 0, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 0, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 0, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.001,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9,\n",
       "   'gamma': 0.4,\n",
       "   'reg_alpha': 0.005,\n",
       "   'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 0.01, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 0.01, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 0.01, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 0.01, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 0.05, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 0.05, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 0.05, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 0.05, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 0.1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 0.1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 0.1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 0.1, 'subsample': 0.9},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 1, 'subsample': 0.6},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 1, 'subsample': 0.7},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 1, 'subsample': 0.8},\n",
       "  {'colsample_bytree': 0.9, 'gamma': 0.4, 'reg_alpha': 1, 'subsample': 0.9}],\n",
       " 'split0_test_AUC': array([0.82281181, 0.8240581 , 0.82750935, 0.82794075, 0.82252421,\n",
       "        0.82432173, 0.82818042, 0.82794075, 0.82319528, 0.82518455,\n",
       "        0.82842009, 0.8267424 , 0.82333909, 0.82492091, 0.82741348,\n",
       "        0.82765315, 0.82458537, 0.82580769, 0.82774902, 0.82669447,\n",
       "        0.82415396, 0.82657463, 0.82774902, 0.82650273, 0.82770108,\n",
       "        0.82947464, 0.82803662, 0.82990605, 0.82290768, 0.82504074,\n",
       "        0.82731761, 0.8264548 , 0.82381843, 0.82542422, 0.82803662,\n",
       "        0.82760522, 0.82333909, 0.82506471, 0.82822836, 0.82664653,\n",
       "        0.82300355, 0.82544818, 0.82707794, 0.82755728, 0.82319528,\n",
       "        0.82561595, 0.82722174, 0.82650273, 0.82319528, 0.82528041,\n",
       "        0.82774902, 0.82683827, 0.82774902, 0.82875563, 0.82868373,\n",
       "        0.83012175, 0.82319528, 0.82561595, 0.82789282, 0.82669447,\n",
       "        0.82309942, 0.82561595, 0.82789282, 0.82635893, 0.82300355,\n",
       "        0.82532835, 0.82755728, 0.82722174, 0.82290768, 0.82542422,\n",
       "        0.82822836, 0.8265986 , 0.82319528, 0.82513661, 0.82731761,\n",
       "        0.82765315, 0.82324322, 0.82599942, 0.82717381, 0.82621513,\n",
       "        0.82750935, 0.82904324, 0.82921101, 0.83016969, 0.82252421,\n",
       "        0.82477711, 0.82736555, 0.82703001, 0.82271594, 0.82453744,\n",
       "        0.82679034, 0.82563992, 0.82372256, 0.82451347, 0.82813249,\n",
       "        0.82640686, 0.82276388, 0.82460934, 0.82650273, 0.82655067,\n",
       "        0.82333909, 0.82528041, 0.8287077 , 0.82607133, 0.82372256,\n",
       "        0.82571182, 0.82822836, 0.8266705 , 0.82837216, 0.8289953 ,\n",
       "        0.82959448, 0.83040936, 0.82199693, 0.82465727, 0.8268862 ,\n",
       "        0.82595149, 0.82199693, 0.82460934, 0.82669447, 0.82604736,\n",
       "        0.82190106, 0.82561595, 0.82693414, 0.82647877, 0.82314735,\n",
       "        0.82489694, 0.82640686, 0.82762918, 0.82305148, 0.82552008,\n",
       "        0.82717381, 0.8263829 , 0.82343495, 0.82619116, 0.82626306,\n",
       "        0.82628703, 0.82909117, 0.83019365, 0.82997795, 0.83146391,\n",
       "        0.82262007, 0.82324322, 0.82803662, 0.82813249, 0.82257214,\n",
       "        0.82319528, 0.82746141, 0.82808456, 0.82218867, 0.82367462,\n",
       "        0.8285639 , 0.82971431, 0.82305148, 0.82377049, 0.82726968,\n",
       "        0.82755728, 0.82290768, 0.82338702, 0.82746141, 0.82813249,\n",
       "        0.82257214, 0.82343495, 0.82822836, 0.82798869, 0.82842009,\n",
       "        0.82861183, 0.8289953 , 0.82868373, 0.8218052 , 0.82300355,\n",
       "        0.82813249, 0.82851596, 0.82247627, 0.82333909, 0.8289953 ,\n",
       "        0.82865976, 0.82271594, 0.82314735, 0.82832423, 0.82813249,\n",
       "        0.82257214, 0.82319528, 0.82770108, 0.82779695, 0.82305148,\n",
       "        0.82338702, 0.82861183, 0.82770108, 0.82290768, 0.82309942,\n",
       "        0.82846803, 0.82765315, 0.82889943, 0.82851596, 0.82882753,\n",
       "        0.82901927, 0.82300355, 0.82324322, 0.82846803, 0.82779695,\n",
       "        0.82338702, 0.82319528, 0.8289953 , 0.82818042, 0.82285974,\n",
       "        0.82338702, 0.82813249, 0.82861183, 0.82161346, 0.82295561,\n",
       "        0.82707794, 0.82822836, 0.82214073, 0.82343495, 0.82683827,\n",
       "        0.82755728, 0.82228454, 0.8240581 , 0.82832423, 0.82750935,\n",
       "        0.82846803, 0.82875563, 0.82830026, 0.82925894, 0.82285974,\n",
       "        0.82329115, 0.82779695, 0.82765315, 0.82228454, 0.82391429,\n",
       "        0.82779695, 0.82827629, 0.82285974, 0.82391429, 0.82784489,\n",
       "        0.82822836, 0.82242834, 0.82329115, 0.82746141, 0.82827629,\n",
       "        0.82329115, 0.82333909, 0.82717381, 0.82770108, 0.82381843,\n",
       "        0.82341099, 0.82794075, 0.8289234 , 0.82818042, 0.82957051,\n",
       "        0.82801265, 0.83040936, 0.82281181, 0.82362669, 0.82731761,\n",
       "        0.828492  , 0.82271594, 0.82324322, 0.82808456, 0.82796472,\n",
       "        0.821949  , 0.82333909, 0.82789282, 0.82825232, 0.82281181,\n",
       "        0.82305148, 0.82722174, 0.82738951, 0.8223804 , 0.82381843,\n",
       "        0.82731761, 0.82796472, 0.82281181, 0.82415396, 0.82765315,\n",
       "        0.82719778, 0.82837216, 0.82889943, 0.8289953 , 0.8307449 ,\n",
       "        0.82439363, 0.82492091, 0.82693414, 0.82966638, 0.8243457 ,\n",
       "        0.82396223, 0.82726968, 0.82952258, 0.82386636, 0.82314735,\n",
       "        0.82712587, 0.82889943, 0.82415396, 0.82429777, 0.82755728,\n",
       "        0.83014572, 0.82424983, 0.82477711, 0.82741348, 0.82933084,\n",
       "        0.82372256, 0.8246333 , 0.82683827, 0.82880357, 0.82698207,\n",
       "        0.82813249, 0.82971431, 0.8285639 , 0.82338702, 0.82396223,\n",
       "        0.82621513, 0.82861183, 0.8242019 , 0.82424983, 0.82616719,\n",
       "        0.82947464, 0.82424983, 0.82266801, 0.82693414, 0.82904324,\n",
       "        0.82377049, 0.82540025, 0.82741348, 0.8285639 , 0.82401016,\n",
       "        0.82559199, 0.82693414, 0.8287077 , 0.8240581 , 0.82487297,\n",
       "        0.8268862 , 0.82894737, 0.82726968, 0.82844406, 0.83009779,\n",
       "        0.82882753, 0.82487297, 0.8244895 , 0.82731761, 0.82880357,\n",
       "        0.82496884, 0.8246333 , 0.82655067, 0.82865976, 0.82386636,\n",
       "        0.82381843, 0.82650273, 0.82909117, 0.8242019 , 0.82372256,\n",
       "        0.82650273, 0.82851596, 0.82415396, 0.82578372, 0.82717381,\n",
       "        0.82861183, 0.82516058, 0.82468124, 0.82722174, 0.82842009,\n",
       "        0.82731761, 0.82873167, 0.82981018, 0.82858786, 0.8246333 ,\n",
       "        0.82525645, 0.82731761, 0.82851596, 0.82482504, 0.8242019 ,\n",
       "        0.82746141, 0.82875563, 0.82415396, 0.82386636, 0.82722174,\n",
       "        0.82865976, 0.82492091, 0.82391429, 0.82726968, 0.82851596,\n",
       "        0.82391429, 0.82453744, 0.8264548 , 0.82909117, 0.8244895 ,\n",
       "        0.82549612, 0.82722174, 0.82880357, 0.82746141, 0.82791679,\n",
       "        0.82942671, 0.82911514, 0.82477711, 0.82516058, 0.82707794,\n",
       "        0.8288515 , 0.82401016, 0.82410603, 0.82722174, 0.82928291,\n",
       "        0.82453744, 0.82468124, 0.82655067, 0.82861183, 0.8246333 ,\n",
       "        0.82401016, 0.82707794, 0.82904324, 0.82424983, 0.8244895 ,\n",
       "        0.8264548 , 0.82889943, 0.82501678, 0.82525645, 0.82655067,\n",
       "        0.82952258, 0.82676637, 0.8289234 , 0.83091266, 0.83007382,\n",
       "        0.82563992, 0.82573579, 0.8265986 , 0.82928291, 0.82549612,\n",
       "        0.82544818, 0.82712587, 0.82933084, 0.82563992, 0.82568785,\n",
       "        0.82736555, 0.82957051, 0.826311  , 0.82487297, 0.82717381,\n",
       "        0.82918704, 0.82535232, 0.82487297, 0.82746141, 0.82942671,\n",
       "        0.82592752, 0.82516058, 0.82679034, 0.8291391 , 0.83076886,\n",
       "        0.83028952, 0.8287077 , 0.82755728, 0.82611926, 0.82544818,\n",
       "        0.82746141, 0.82875563, 0.82611926, 0.82544818, 0.82731761,\n",
       "        0.82882753, 0.82559199, 0.82520851, 0.82703001, 0.82949861,\n",
       "        0.82559199, 0.82468124, 0.8265986 , 0.8286358 , 0.82573579,\n",
       "        0.82415396, 0.82722174, 0.82861183, 0.82573579, 0.82602339,\n",
       "        0.82679034, 0.82909117, 0.82981018, 0.82940274, 0.82865976,\n",
       "        0.82813249, 0.82655067, 0.82525645, 0.82664653, 0.82837216,\n",
       "        0.82587959, 0.82492091, 0.82703001, 0.82846803, 0.82506471,\n",
       "        0.82568785, 0.82626306, 0.82830026, 0.82568785, 0.82587959,\n",
       "        0.82683827, 0.82966638, 0.82587959, 0.82559199, 0.82703001,\n",
       "        0.82861183, 0.82650273, 0.82530438, 0.82535232, 0.82846803,\n",
       "        0.82966638, 0.82904324, 0.82827629, 0.82813249, 0.82679034,\n",
       "        0.82492091, 0.82698207, 0.82923497, 0.82607133, 0.82573579,\n",
       "        0.82698207, 0.8285639 , 0.82587959, 0.82549612, 0.82722174,\n",
       "        0.82904324, 0.82492091, 0.82583166, 0.82640686, 0.82909117,\n",
       "        0.82544818, 0.82343495, 0.82640686, 0.82875563, 0.82520851,\n",
       "        0.82477711, 0.82683827, 0.82961845, 0.82954654, 0.82983415,\n",
       "        0.8287077 , 0.82818042, 0.82621513, 0.82492091, 0.82760522,\n",
       "        0.82909117, 0.826311  , 0.82444157, 0.82760522, 0.82961845,\n",
       "        0.82650273, 0.8244895 , 0.8268862 , 0.82875563, 0.82621513,\n",
       "        0.82549612, 0.8267424 , 0.82942671, 0.82621513, 0.82487297,\n",
       "        0.82683827, 0.82961845, 0.82573579, 0.8240581 , 0.82731761,\n",
       "        0.82942671, 0.82930687, 0.82997795, 0.82961845, 0.82818042]),\n",
       " 'split1_test_AUC': array([0.86794171, 0.86310037, 0.86034417, 0.85646151, 0.86813345,\n",
       "        0.86314831, 0.86135078, 0.85626977, 0.86813345, 0.86334004,\n",
       "        0.86005656, 0.85626977, 0.86798965, 0.86314831, 0.86091937,\n",
       "        0.85650944, 0.86746237, 0.86420286, 0.86125491, 0.85718052,\n",
       "        0.86842105, 0.86329211, 0.86183012, 0.85742019, 0.87220784,\n",
       "        0.86885246, 0.86839709, 0.86671939, 0.86832518, 0.86276484,\n",
       "        0.86125491, 0.85660531, 0.86880452, 0.86329211, 0.86125491,\n",
       "        0.85598217, 0.86808551, 0.86247723, 0.86135078, 0.85583837,\n",
       "        0.86746237, 0.86300451, 0.86139872, 0.85698878, 0.86832518,\n",
       "        0.8625731 , 0.86139872, 0.85598217, 0.86717477, 0.86305244,\n",
       "        0.86211773, 0.8579954 , 0.87182437, 0.87019461, 0.86858882,\n",
       "        0.86739047, 0.86861279, 0.86214169, 0.86120698, 0.85593423,\n",
       "        0.86861279, 0.86233343, 0.86106318, 0.85555076, 0.86808551,\n",
       "        0.86348385, 0.86044003, 0.85583837, 0.86832518, 0.86300451,\n",
       "        0.86096731, 0.85631771, 0.86760617, 0.86252517, 0.86063177,\n",
       "        0.85670118, 0.86813345, 0.8628607 , 0.86192599, 0.85852267,\n",
       "        0.8717285 , 0.86952354, 0.86887643, 0.86739047, 0.86808551,\n",
       "        0.86185409, 0.86072764, 0.85694085, 0.86727064, 0.86180615,\n",
       "        0.86115905, 0.85593423, 0.86875659, 0.86310037, 0.86020036,\n",
       "        0.85550283, 0.86870866, 0.86276484, 0.86048797, 0.8558863 ,\n",
       "        0.86827725, 0.86329211, 0.86101524, 0.85665325, 0.86789378,\n",
       "        0.86353178, 0.86120698, 0.85904995, 0.87206404, 0.87033841,\n",
       "        0.86801361, 0.86772601, 0.869188  , 0.86252517, 0.86096731,\n",
       "        0.85641357, 0.8690442 , 0.86233343, 0.86096731, 0.85622184,\n",
       "        0.86866072, 0.8627169 , 0.86139872, 0.85655738, 0.86794171,\n",
       "        0.86305244, 0.86072764, 0.85665325, 0.86832518, 0.86310037,\n",
       "        0.8623574 , 0.85631771, 0.86818138, 0.86314831, 0.86163839,\n",
       "        0.85809127, 0.8715847 , 0.87038635, 0.86892436, 0.86834915,\n",
       "        0.86592848, 0.86175822, 0.86187806, 0.85789953, 0.86549708,\n",
       "        0.86166235, 0.86144665, 0.85737226, 0.86492187, 0.86161442,\n",
       "        0.86149458, 0.85761193, 0.86477807, 0.86058384, 0.86149458,\n",
       "        0.85718052, 0.86631195, 0.86161442, 0.86125491, 0.85665325,\n",
       "        0.86597642, 0.86233343, 0.862645  , 0.85852267, 0.87283098,\n",
       "        0.86846899, 0.86763014, 0.86691113, 0.86559294, 0.86233343,\n",
       "        0.86130285, 0.85727639, 0.86564088, 0.86194996, 0.86139872,\n",
       "        0.85751606, 0.86429872, 0.8627169 , 0.8606797 , 0.85691688,\n",
       "        0.8651136 , 0.8624293 , 0.86135078, 0.85691688, 0.86655162,\n",
       "        0.86233343, 0.86226153, 0.85708465, 0.86731857, 0.86314831,\n",
       "        0.86230946, 0.8581392 , 0.87302272, 0.86880452, 0.86834915,\n",
       "        0.86772601, 0.86592848, 0.8625731 , 0.86159045, 0.85727639,\n",
       "        0.86549708, 0.86357971, 0.86130285, 0.85742019, 0.86487393,\n",
       "        0.86127888, 0.86111111, 0.85694085, 0.86516154, 0.86185409,\n",
       "        0.86159045, 0.85722845, 0.86631195, 0.8625731 , 0.86206979,\n",
       "        0.85670118, 0.8670789 , 0.86190202, 0.8627888 , 0.85775573,\n",
       "        0.87292685, 0.869188  , 0.86719873, 0.86758221, 0.86530534,\n",
       "        0.86142268, 0.86274087, 0.85686895, 0.86520947, 0.86233343,\n",
       "        0.86274087, 0.85701275, 0.86525741, 0.86238136, 0.86206979,\n",
       "        0.85710862, 0.86487393, 0.86166235, 0.86206979, 0.85737226,\n",
       "        0.86731857, 0.86190202, 0.86211773, 0.85694085, 0.86669543,\n",
       "        0.86180615, 0.86326814, 0.8579954 , 0.87268718, 0.86846899,\n",
       "        0.86854089, 0.86767807, 0.86655162, 0.86118301, 0.86226153,\n",
       "        0.85684498, 0.86659956, 0.86118301, 0.86211773, 0.85698878,\n",
       "        0.8670789 , 0.86137475, 0.86111111, 0.85701275, 0.86755824,\n",
       "        0.86113508, 0.86183012, 0.85665325, 0.86573675, 0.86175822,\n",
       "        0.86091937, 0.85761193, 0.86688716, 0.86166235, 0.86259707,\n",
       "        0.85742019, 0.87292685, 0.86952354, 0.86887643, 0.86763014,\n",
       "        0.86381938, 0.86108714, 0.86000863, 0.85686895, 0.86329211,\n",
       "        0.86103921, 0.85847474, 0.85732432, 0.86334004, 0.86123095,\n",
       "        0.85967309, 0.85708465, 0.86381938, 0.85979292, 0.85996069,\n",
       "        0.85746812, 0.86535327, 0.8603202 , 0.8601045 , 0.85722845,\n",
       "        0.864826  , 0.86214169, 0.85991276, 0.85895408, 0.87062602,\n",
       "        0.86779791, 0.86695906, 0.86868469, 0.86415492, 0.86022433,\n",
       "        0.85876234, 0.85703672, 0.86420286, 0.86084747, 0.85948135,\n",
       "        0.85742019, 0.86415492, 0.85984086, 0.85823507, 0.85789953,\n",
       "        0.86449046, 0.86151855, 0.85962516, 0.85809127, 0.86458633,\n",
       "        0.86137475, 0.85962516, 0.85871441, 0.86520947, 0.86142268,\n",
       "        0.8601045 , 0.8584268 , 0.87235164, 0.86861279, 0.8671508 ,\n",
       "        0.86858882, 0.86338798, 0.8603202 , 0.85861854, 0.85718052,\n",
       "        0.86343591, 0.86065574, 0.85933755, 0.85770779, 0.86425079,\n",
       "        0.86070367, 0.858283  , 0.85847474, 0.86362765, 0.86194996,\n",
       "        0.8602483 , 0.85674911, 0.86405905, 0.86108714, 0.85962516,\n",
       "        0.85809127, 0.86444253, 0.86113508, 0.86044003, 0.8584268 ,\n",
       "        0.87235164, 0.86842105, 0.86834915, 0.86791775, 0.86492187,\n",
       "        0.86180615, 0.858283  , 0.85861854, 0.86405905, 0.86223756,\n",
       "        0.86077557, 0.8579954 , 0.86520947, 0.86055987, 0.85928962,\n",
       "        0.85742019, 0.86420286, 0.86147062, 0.86005656, 0.85770779,\n",
       "        0.86434666, 0.86156648, 0.85919375, 0.85833094, 0.86401112,\n",
       "        0.86108714, 0.86082351, 0.85847474, 0.87163263, 0.86885246,\n",
       "        0.86734254, 0.8672946 , 0.86444253, 0.86204582, 0.85919375,\n",
       "        0.85737226, 0.8628607 , 0.86108714, 0.85928962, 0.85737226,\n",
       "        0.8645384 , 0.86127888, 0.8606797 , 0.85694085, 0.86396319,\n",
       "        0.86065574, 0.85933755, 0.85794746, 0.86377145, 0.86223756,\n",
       "        0.85952929, 0.85823507, 0.86487393, 0.86161442, 0.86034417,\n",
       "        0.85933755, 0.87177644, 0.86880452, 0.86772601, 0.86801361,\n",
       "        0.8627169 , 0.85830697, 0.85749209, 0.85732432, 0.86199789,\n",
       "        0.85825904, 0.85849871, 0.85626977, 0.86108714, 0.8600326 ,\n",
       "        0.85754002, 0.85655738, 0.86252517, 0.85955325, 0.85869044,\n",
       "        0.85761193, 0.86319624, 0.85912185, 0.85768383, 0.85756399,\n",
       "        0.86429872, 0.86012846, 0.85964912, 0.8601045 , 0.87000288,\n",
       "        0.86798965, 0.86640782, 0.86657559, 0.86266897, 0.85897805,\n",
       "        0.85725242, 0.85713259, 0.86334004, 0.85974499, 0.85916978,\n",
       "        0.85742019, 0.86209376, 0.85931358, 0.86027227, 0.8578516 ,\n",
       "        0.86305244, 0.85979292, 0.85897805, 0.85761193, 0.86357971,\n",
       "        0.85916978, 0.85921772, 0.85718052, 0.86405905, 0.86094334,\n",
       "        0.85974499, 0.85871441, 0.87009874, 0.86808551, 0.86592848,\n",
       "        0.86705493, 0.86137475, 0.85869044, 0.85878631, 0.85818713,\n",
       "        0.86137475, 0.85840284, 0.85902598, 0.85698878, 0.8624293 ,\n",
       "        0.85883424, 0.8601764 , 0.85775573, 0.8625731 , 0.85864251,\n",
       "        0.85921772, 0.85703672, 0.86444253, 0.85864251, 0.86041607,\n",
       "        0.85727639, 0.86381938, 0.8603202 , 0.8601764 , 0.85924168,\n",
       "        0.87033841, 0.86846899, 0.86650369, 0.86734254, 0.86290864,\n",
       "        0.85897805, 0.85979292, 0.85823507, 0.86266897, 0.85854664,\n",
       "        0.85979292, 0.85742019, 0.86266897, 0.85988879, 0.85916978,\n",
       "        0.85876234, 0.8627169 , 0.85998466, 0.85916978, 0.858283  ,\n",
       "        0.86348385, 0.860464  , 0.85907391, 0.85761193, 0.86362765,\n",
       "        0.8600326 , 0.85888218, 0.86029623, 0.87076982, 0.86870866,\n",
       "        0.8670789 , 0.86763014, 0.86295657, 0.86008053, 0.85969706,\n",
       "        0.85794746, 0.86290864, 0.86008053, 0.85998466, 0.85770779,\n",
       "        0.86300451, 0.85854664, 0.85969706, 0.85881028, 0.86319624,\n",
       "        0.86065574, 0.85993673, 0.8579954 , 0.86238136, 0.86027227,\n",
       "        0.85936152, 0.85972102, 0.86425079, 0.86204582, 0.85998466,\n",
       "        0.85919375, 0.87053015, 0.86837312, 0.86760617, 0.8694037 ]),\n",
       " 'split2_test_AUC': array([0.89392196, 0.89617486, 0.89473684, 0.89905091, 0.89344262,\n",
       "        0.89627073, 0.89516825, 0.89924264, 0.8944013 , 0.89569552,\n",
       "        0.89502445, 0.89885917, 0.8939699 , 0.89631867, 0.89483271,\n",
       "        0.89900297, 0.89464097, 0.89598313, 0.89459304, 0.89905091,\n",
       "        0.89497651, 0.89555172, 0.89497651, 0.89857157, 0.89353849,\n",
       "        0.8938261 , 0.89392196, 0.89416163, 0.89401783, 0.89545585,\n",
       "        0.89521618, 0.89919471, 0.89401783, 0.89535998, 0.89535998,\n",
       "        0.8989071 , 0.89459304, 0.89531205, 0.89526412, 0.89881124,\n",
       "        0.8941137 , 0.89583933, 0.89516825, 0.89981785, 0.89507238,\n",
       "        0.89646247, 0.89468891, 0.89924264, 0.89349056, 0.89641453,\n",
       "        0.89516825, 0.89972198, 0.89373023, 0.89310708, 0.89420957,\n",
       "        0.89454511, 0.89406577, 0.89722941, 0.89593519, 0.89885917,\n",
       "        0.89416163, 0.89612693, 0.89492858, 0.89914677, 0.89339469,\n",
       "        0.89603106, 0.89545585, 0.89986578, 0.89344262, 0.89574346,\n",
       "        0.89444924, 0.89919471, 0.89459304, 0.89627073, 0.89516825,\n",
       "        0.89953025, 0.89478478, 0.89526412, 0.89516825, 0.89933851,\n",
       "        0.89368229, 0.89329882, 0.89444924, 0.89512031, 0.89358643,\n",
       "        0.89675007, 0.89603106, 0.89943438, 0.89468891, 0.89660627,\n",
       "        0.89488064, 0.89948231, 0.8942575 , 0.8962228 , 0.89478478,\n",
       "        0.89957818, 0.8941137 , 0.89627073, 0.89492858, 0.89938644,\n",
       "        0.89420957, 0.89603106, 0.896079  , 0.89885917, 0.89526412,\n",
       "        0.89583933, 0.89507238, 0.89842776, 0.89363436, 0.89377816,\n",
       "        0.89540792, 0.89579139, 0.89488064, 0.89612693, 0.89526412,\n",
       "        0.89991372, 0.89473684, 0.89574346, 0.89516825, 0.90005752,\n",
       "        0.8942575 , 0.89555172, 0.89550379, 0.90005752, 0.89420957,\n",
       "        0.89574346, 0.89593519, 0.89996165, 0.89420957, 0.89655834,\n",
       "        0.89540792, 0.89909884, 0.89444924, 0.89703768, 0.89545585,\n",
       "        0.89885917, 0.89349056, 0.89454511, 0.89631867, 0.89603106,\n",
       "        0.89627073, 0.89655834, 0.89722941, 0.89938644, 0.89732528,\n",
       "        0.89742115, 0.89655834, 0.89972198, 0.89631867, 0.896079  ,\n",
       "        0.89559965, 0.89943438, 0.89655834, 0.8962228 , 0.89569552,\n",
       "        0.89986578, 0.89646247, 0.8966542 , 0.89526412, 0.8989071 ,\n",
       "        0.89526412, 0.89583933, 0.89449717, 0.89837983, 0.89574346,\n",
       "        0.89248394, 0.8944013 , 0.89478478, 0.89655834, 0.89631867,\n",
       "        0.89488064, 0.89972198, 0.89569552, 0.89574346, 0.89488064,\n",
       "        0.89972198, 0.896079  , 0.89684594, 0.89550379, 0.89957818,\n",
       "        0.89516825, 0.89641453, 0.89679801, 0.89914677, 0.89545585,\n",
       "        0.89694181, 0.89579139, 0.89895504, 0.89497651, 0.89588726,\n",
       "        0.89550379, 0.89814016, 0.89569552, 0.89301122, 0.8944013 ,\n",
       "        0.89473684, 0.89559965, 0.89698974, 0.89598313, 0.89938644,\n",
       "        0.89545585, 0.89660627, 0.89617486, 0.89938644, 0.8962228 ,\n",
       "        0.89746908, 0.8965104 , 0.89900297, 0.89713354, 0.89713354,\n",
       "        0.89679801, 0.89885917, 0.89598313, 0.89603106, 0.89627073,\n",
       "        0.89924264, 0.89478478, 0.89555172, 0.89502445, 0.89857157,\n",
       "        0.89507238, 0.89301122, 0.89430544, 0.89435337, 0.89555172,\n",
       "        0.89785255, 0.89631867, 0.89909884, 0.89617486, 0.89780462,\n",
       "        0.8966542 , 0.89866743, 0.89646247, 0.89742115, 0.89660627,\n",
       "        0.89948231, 0.89612693, 0.8962228 , 0.8965104 , 0.89996165,\n",
       "        0.89583933, 0.89694181, 0.89675007, 0.89871537, 0.89535998,\n",
       "        0.89574346, 0.89512031, 0.89866743, 0.89564759, 0.89349056,\n",
       "        0.89492858, 0.8965104 , 0.89579139, 0.8965104 , 0.89593519,\n",
       "        0.89929058, 0.89603106, 0.8966542 , 0.89627073, 0.89991372,\n",
       "        0.89631867, 0.89689387, 0.89742115, 0.89871537, 0.8966542 ,\n",
       "        0.89727735, 0.89718148, 0.89924264, 0.89550379, 0.89694181,\n",
       "        0.89694181, 0.89909884, 0.89550379, 0.89631867, 0.89670214,\n",
       "        0.8989071 , 0.89507238, 0.89272361, 0.89507238, 0.89593519,\n",
       "        0.89550379, 0.89512031, 0.89646247, 0.89885917, 0.89478478,\n",
       "        0.89521618, 0.89583933, 0.89914677, 0.89583933, 0.89454511,\n",
       "        0.89694181, 0.89905091, 0.89430544, 0.89627073, 0.89473684,\n",
       "        0.89957818, 0.89507238, 0.89612693, 0.89531205, 0.90015339,\n",
       "        0.89574346, 0.89555172, 0.89535998, 0.89866743, 0.89516825,\n",
       "        0.89210047, 0.89329882, 0.8941137 , 0.89627073, 0.89449717,\n",
       "        0.8965104 , 0.8986195 , 0.89579139, 0.89550379, 0.89569552,\n",
       "        0.89943438, 0.89569552, 0.89483271, 0.89535998, 0.89986578,\n",
       "        0.8942575 , 0.89675007, 0.89564759, 0.89981785, 0.89512031,\n",
       "        0.89660627, 0.89478478, 0.89814016, 0.89468891, 0.89502445,\n",
       "        0.89559965, 0.8983319 , 0.89531205, 0.89267568, 0.89406577,\n",
       "        0.89377816, 0.89526412, 0.89603106, 0.89579139, 0.89857157,\n",
       "        0.89598313, 0.89569552, 0.89583933, 0.89900297, 0.89627073,\n",
       "        0.89497651, 0.89603106, 0.8984757 , 0.89444924, 0.8966542 ,\n",
       "        0.89516825, 0.89790049, 0.89449717, 0.8941137 , 0.89535998,\n",
       "        0.89842776, 0.89416163, 0.89574346, 0.89497651, 0.89698974,\n",
       "        0.89507238, 0.89334675, 0.89358643, 0.8944013 , 0.89574346,\n",
       "        0.89655834, 0.89588726, 0.8986195 , 0.89598313, 0.89631867,\n",
       "        0.89593519, 0.89852363, 0.89550379, 0.89569552, 0.89540792,\n",
       "        0.89895504, 0.89344262, 0.89564759, 0.89545585, 0.8989071 ,\n",
       "        0.8939699 , 0.89569552, 0.89540792, 0.89905091, 0.89473684,\n",
       "        0.89555172, 0.89588726, 0.89905091, 0.89435337, 0.89392196,\n",
       "        0.8942575 , 0.89502445, 0.89660627, 0.89679801, 0.89646247,\n",
       "        0.89881124, 0.89660627, 0.8966542 , 0.89694181, 0.90048893,\n",
       "        0.8963666 , 0.89670214, 0.89612693, 0.89953025, 0.896079  ,\n",
       "        0.89579139, 0.89598313, 0.89828396, 0.89416163, 0.8963666 ,\n",
       "        0.896079  , 0.90010545, 0.8939699 , 0.89545585, 0.89569552,\n",
       "        0.89962611, 0.8962228 , 0.89334675, 0.89478478, 0.89574346,\n",
       "        0.89540792, 0.89569552, 0.89569552, 0.89852363, 0.89627073,\n",
       "        0.89718148, 0.89627073, 0.8987633 , 0.89598313, 0.8965104 ,\n",
       "        0.89569552, 0.89866743, 0.896079  , 0.89689387, 0.89555172,\n",
       "        0.89818809, 0.89526412, 0.89794842, 0.89703768, 0.8987633 ,\n",
       "        0.89593519, 0.89655834, 0.89574346, 0.89756495, 0.89550379,\n",
       "        0.89401783, 0.89507238, 0.89373023, 0.89708561, 0.89732528,\n",
       "        0.89627073, 0.89914677, 0.89454511, 0.89593519, 0.89655834,\n",
       "        0.89866743, 0.89631867, 0.89684594, 0.89588726, 0.8989071 ,\n",
       "        0.89588726, 0.89694181, 0.8963666 , 0.89809223, 0.89555172,\n",
       "        0.89708561, 0.89559965, 0.89775669, 0.89569552, 0.89670214,\n",
       "        0.89502445, 0.89718148, 0.89569552, 0.89512031, 0.89401783,\n",
       "        0.89329882, 0.89488064, 0.8965104 , 0.89559965, 0.89770875,\n",
       "        0.89698974, 0.89670214, 0.89593519, 0.89823603, 0.89559965,\n",
       "        0.89675007, 0.89521618, 0.89766082, 0.8965104 , 0.89617486,\n",
       "        0.89550379, 0.89809223, 0.8962228 , 0.89660627, 0.89598313,\n",
       "        0.89775669, 0.89488064, 0.89722941, 0.89540792, 0.89713354,\n",
       "        0.89521618, 0.89420957, 0.8938261 , 0.89473684, 0.89569552,\n",
       "        0.89679801, 0.8962228 , 0.89842776, 0.89617486, 0.89675007,\n",
       "        0.89641453, 0.89837983, 0.89545585, 0.89689387, 0.89603106,\n",
       "        0.89804429, 0.89516825, 0.89679801, 0.8966542 , 0.89766082,\n",
       "        0.89516825, 0.89555172, 0.8966542 , 0.89737321, 0.89540792,\n",
       "        0.89698974, 0.89559965, 0.89828396, 0.89535998, 0.8944013 ,\n",
       "        0.89497651, 0.8938261 , 0.89598313, 0.89646247, 0.89569552,\n",
       "        0.89919471, 0.89497651, 0.89675007, 0.89598313, 0.89804429,\n",
       "        0.89559965, 0.89703768, 0.89703768, 0.89799636, 0.89526412,\n",
       "        0.8966542 , 0.89555172, 0.89871537, 0.89535998, 0.89737321,\n",
       "        0.89617486, 0.89766082, 0.89459304, 0.89550379, 0.89483271,\n",
       "        0.8962228 , 0.89444924, 0.89329882, 0.89593519, 0.89655834]),\n",
       " 'mean_test_AUC': array([0.8615585 , 0.86111111, 0.86086345, 0.86115106, 0.86136676,\n",
       "        0.86124692, 0.86156648, 0.86115106, 0.86191001, 0.8614067 ,\n",
       "        0.86116703, 0.86062378, 0.86176621, 0.86146263, 0.86105519,\n",
       "        0.86105519, 0.86222957, 0.86199789, 0.86119899, 0.8609753 ,\n",
       "        0.86251718, 0.86180615, 0.86151855, 0.8608315 , 0.86448247,\n",
       "        0.86405107, 0.86345189, 0.86359569, 0.86175023, 0.86108714,\n",
       "        0.8612629 , 0.86075161, 0.86221359, 0.86135877, 0.86155051,\n",
       "        0.8608315 , 0.86200588, 0.86095133, 0.86161442, 0.86043205,\n",
       "        0.86152654, 0.86143067, 0.86121497, 0.86145464, 0.86219762,\n",
       "        0.86155051, 0.86110312, 0.86057585, 0.86128687, 0.86158246,\n",
       "        0.86167833, 0.86151855, 0.86443454, 0.86401911, 0.86382737,\n",
       "        0.86401911, 0.86195795, 0.86166235, 0.86167833, 0.86049596,\n",
       "        0.86195795, 0.86135877, 0.86129486, 0.86035216, 0.86149458,\n",
       "        0.86161442, 0.86115106, 0.8609753 , 0.8615585 , 0.86139073,\n",
       "        0.86121497, 0.86070367, 0.86179817, 0.86131084, 0.86103921,\n",
       "        0.86129486, 0.86205381, 0.86137475, 0.86142268, 0.86135877,\n",
       "        0.86430671, 0.8639552 , 0.86417889, 0.86422682, 0.86139872,\n",
       "        0.86112709, 0.86137475, 0.86113508, 0.8615585 , 0.86098329,\n",
       "        0.86094334, 0.86035216, 0.86224555, 0.86127888, 0.86103921,\n",
       "        0.86049596, 0.86186208, 0.86121497, 0.86063976, 0.8606078 ,\n",
       "        0.86194197, 0.86153453, 0.86193398, 0.86052791, 0.86229348,\n",
       "        0.86169431, 0.86150257, 0.86138274, 0.86469019, 0.86437063,\n",
       "        0.86433867, 0.86464225, 0.86202186, 0.86110312, 0.86103921,\n",
       "        0.86075959, 0.86192599, 0.86089541, 0.86094334, 0.86077557,\n",
       "        0.86160643, 0.86129486, 0.86127888, 0.86103122, 0.86176621,\n",
       "        0.86123095, 0.86102323, 0.86141469, 0.86186208, 0.86172626,\n",
       "        0.86164637, 0.86059981, 0.86202186, 0.86212572, 0.8611191 ,\n",
       "        0.86107916, 0.86472214, 0.8650417 , 0.86507366, 0.86528137,\n",
       "        0.86160643, 0.86051992, 0.86238136, 0.86180615, 0.86179817,\n",
       "        0.86075959, 0.86182213, 0.86172626, 0.86114307, 0.86045601,\n",
       "        0.86188604, 0.86225354, 0.86146263, 0.86019238, 0.86148659,\n",
       "        0.86153453, 0.86189403, 0.86055188, 0.86132681, 0.86123095,\n",
       "        0.86127089, 0.8605359 , 0.86179018, 0.8616304 , 0.86566485,\n",
       "        0.86318825, 0.86367558, 0.86345988, 0.86131883, 0.86055188,\n",
       "        0.86143866, 0.86183811, 0.86127089, 0.86034417, 0.86175822,\n",
       "        0.86196593, 0.86103122, 0.8609034 , 0.86150257, 0.86154252,\n",
       "        0.86095133, 0.8606797 , 0.86194996, 0.86128687, 0.86168632,\n",
       "        0.86088742, 0.86222158, 0.86124692, 0.86173425, 0.86071166,\n",
       "        0.86209376, 0.86131084, 0.86587256, 0.8634439 , 0.86385933,\n",
       "        0.86382737, 0.86151056, 0.86093535, 0.86201387, 0.86148659,\n",
       "        0.86144665, 0.86112709, 0.86215767, 0.86166235, 0.86131883,\n",
       "        0.86071166, 0.861918  , 0.86151855, 0.86130285, 0.86064775,\n",
       "        0.86182213, 0.86143866, 0.86147861, 0.8606797 , 0.86172626,\n",
       "        0.86116703, 0.86138274, 0.86050395, 0.86204582, 0.86127888,\n",
       "        0.86548909, 0.86365162, 0.86326814, 0.86373151, 0.86123894,\n",
       "        0.86085546, 0.8622855 , 0.86120698, 0.86122296, 0.86135078,\n",
       "        0.86239734, 0.86131883, 0.86152654, 0.86123894, 0.86217365,\n",
       "        0.86160643, 0.86114307, 0.8603921 , 0.86201387, 0.86187007,\n",
       "        0.86214968, 0.86072764, 0.86201387, 0.8611191 , 0.86195795,\n",
       "        0.8603202 , 0.86210974, 0.86186208, 0.86550507, 0.86384335,\n",
       "        0.86382737, 0.86486594, 0.86171828, 0.86044003, 0.86183811,\n",
       "        0.86154252, 0.86178219, 0.86036014, 0.86215767, 0.86162241,\n",
       "        0.86178219, 0.8605359 , 0.86214169, 0.86132681, 0.86234142,\n",
       "        0.86048797, 0.86207778, 0.86109513, 0.86120698, 0.86083948,\n",
       "        0.86172626, 0.8615585 , 0.86173425, 0.86071166, 0.86231745,\n",
       "        0.86117502, 0.86545713, 0.86371553, 0.8643147 , 0.86477008,\n",
       "        0.86123894, 0.86037612, 0.86113508, 0.86179817, 0.86080753,\n",
       "        0.86007254, 0.86052791, 0.86199789, 0.86101524, 0.85964113,\n",
       "        0.86124692, 0.86167833, 0.86075959, 0.86012047, 0.86075161,\n",
       "        0.86239734, 0.8615585 , 0.86040808, 0.86094334, 0.86223756,\n",
       "        0.86143067, 0.86077557, 0.86070367, 0.86214169, 0.86425878,\n",
       "        0.86267696, 0.86332407, 0.86378743, 0.86127089, 0.85956124,\n",
       "        0.86049596, 0.86142268, 0.86139872, 0.86020036, 0.86044802,\n",
       "        0.86210974, 0.86136676, 0.85911386, 0.8601764 , 0.86226952,\n",
       "        0.86083948, 0.86122296, 0.86089541, 0.86215767, 0.86123894,\n",
       "        0.861191  , 0.86044802, 0.86185409, 0.86131883, 0.86044003,\n",
       "        0.86086345, 0.86190202, 0.86497779, 0.86324418, 0.86377145,\n",
       "        0.86373151, 0.86117502, 0.86028025, 0.86057585, 0.86151855,\n",
       "        0.86146263, 0.86032819, 0.86057585, 0.86179018, 0.86146263,\n",
       "        0.85983287, 0.86027227, 0.86201387, 0.86075959, 0.86077557,\n",
       "        0.86063976, 0.86105519, 0.8609034 , 0.86032819, 0.86071965,\n",
       "        0.86171029, 0.86125491, 0.86051992, 0.86087943, 0.86127888,\n",
       "        0.86491388, 0.86349982, 0.86391525, 0.86363564, 0.86176621,\n",
       "        0.86120698, 0.86049596, 0.861918  , 0.86162241, 0.86091937,\n",
       "        0.86139073, 0.86175822, 0.86162241, 0.86004058, 0.86063976,\n",
       "        0.86167833, 0.86085546, 0.86034417, 0.86092736, 0.86171029,\n",
       "        0.86074362, 0.86059981, 0.86035216, 0.86215767, 0.86107916,\n",
       "        0.86071166, 0.86131084, 0.86210974, 0.86448247, 0.86356374,\n",
       "        0.86367558, 0.8638114 , 0.86194197, 0.8613348 , 0.86091139,\n",
       "        0.86167833, 0.86115905, 0.86061579, 0.86115106, 0.86238136,\n",
       "        0.86181414, 0.86088742, 0.8611191 , 0.86169431, 0.8615585 ,\n",
       "        0.86015243, 0.86079954, 0.86175822, 0.86072764, 0.86103122,\n",
       "        0.86068769, 0.86241332, 0.86128687, 0.86077557, 0.86086345,\n",
       "        0.86282875, 0.86492187, 0.86369156, 0.86447448, 0.8646103 ,\n",
       "        0.86125491, 0.85991276, 0.85992874, 0.86171029, 0.86125491,\n",
       "        0.86029623, 0.86063177, 0.86145464, 0.8609034 , 0.86074362,\n",
       "        0.86020036, 0.86159844, 0.86163839, 0.86044003, 0.86047199,\n",
       "        0.86166235, 0.86127089, 0.86064775, 0.86072764, 0.861918  ,\n",
       "        0.86205381, 0.86061579, 0.86072764, 0.86226952, 0.86542517,\n",
       "        0.864099  , 0.86339597, 0.86262103, 0.86195795, 0.86058384,\n",
       "        0.86032819, 0.86167833, 0.8613348 , 0.86037612, 0.86101524,\n",
       "        0.86163839, 0.8613348 , 0.86045601, 0.86106318, 0.86208577,\n",
       "        0.86151056, 0.86047199, 0.86064775, 0.86144665, 0.86162241,\n",
       "        0.86013645, 0.8606797 , 0.86118301, 0.86183012, 0.86122296,\n",
       "        0.86051992, 0.86166235, 0.86520148, 0.86420286, 0.86286869,\n",
       "        0.86282875, 0.86093535, 0.86015243, 0.86034417, 0.86142268,\n",
       "        0.86141469, 0.86000863, 0.86066373, 0.86123095, 0.86103122,\n",
       "        0.86042406, 0.86055188, 0.86123894, 0.86159045, 0.86023232,\n",
       "        0.86051992, 0.86159844, 0.86218164, 0.86028025, 0.86114307,\n",
       "        0.86121497, 0.86173425, 0.86095133, 0.86031221, 0.86161442,\n",
       "        0.86507366, 0.86390726, 0.86286869, 0.86340396, 0.86179817,\n",
       "        0.86023232, 0.86099927, 0.86196593, 0.86163839, 0.86034417,\n",
       "        0.86106318, 0.86145464, 0.8613348 , 0.86075959, 0.86080753,\n",
       "        0.86194996, 0.86093535, 0.86087144, 0.86074362, 0.86167833,\n",
       "        0.86136676, 0.85981689, 0.86071166, 0.86124692, 0.86141469,\n",
       "        0.86059981, 0.86044003, 0.86273288, 0.86522545, 0.8643147 ,\n",
       "        0.8635877 , 0.86321222, 0.86171828, 0.86048797, 0.86099927,\n",
       "        0.86207778, 0.86139872, 0.86042406, 0.861191  , 0.86179018,\n",
       "        0.8617023 , 0.86002461, 0.86120698, 0.86185409, 0.8615585 ,\n",
       "        0.86093535, 0.86074362, 0.86204582, 0.86131883, 0.86083948,\n",
       "        0.86079155, 0.86233343, 0.86152654, 0.8605359 , 0.86071166,\n",
       "        0.86161442, 0.86476209, 0.8638833 , 0.8643866 , 0.86471415]),\n",
       " 'std_test_AUC': array([0.02937939, 0.02947513, 0.02744797, 0.02921937, 0.02934503,\n",
       "        0.02940381, 0.02734809, 0.0293128 , 0.02940094, 0.02881843,\n",
       "        0.02720245, 0.02960208, 0.02916878, 0.02917237, 0.02752395,\n",
       "        0.02930526, 0.02883844, 0.0286914 , 0.02728899, 0.02966102,\n",
       "        0.02921301, 0.02817937, 0.02744639, 0.02952069, 0.02742751,\n",
       "        0.02648984, 0.02712392, 0.02632506, 0.02940052, 0.02877132,\n",
       "        0.02771948, 0.02984032, 0.02903526, 0.02858387, 0.02748544,\n",
       "        0.02931014, 0.02940525, 0.02869865, 0.02736787, 0.02963964,\n",
       "        0.02933245, 0.0287586 , 0.02779806, 0.02966879, 0.02966187,\n",
       "        0.02893201, 0.02754415, 0.02987307, 0.02899835, 0.02905898,\n",
       "        0.02752554, 0.02985876, 0.02743887, 0.02663181, 0.02696185,\n",
       "        0.02640854, 0.02931293, 0.02923804, 0.02778018, 0.02963717,\n",
       "        0.02939019, 0.02879423, 0.02736772, 0.02990883, 0.02911252,\n",
       "        0.02889451, 0.02772403, 0.02987842, 0.02919059, 0.02873038,\n",
       "        0.02703513, 0.02979906, 0.02943591, 0.02905307, 0.0277014 ,\n",
       "        0.02952294, 0.02952141, 0.02829671, 0.0277609 , 0.02991978,\n",
       "        0.02752002, 0.02652609, 0.02683973, 0.02661018, 0.02939382,\n",
       "        0.02938734, 0.02803631, 0.02970737, 0.02965916, 0.02942773,\n",
       "        0.02779817, 0.03030746, 0.0291615 , 0.02930353, 0.02721715,\n",
       "        0.03007999, 0.02952802, 0.02927616, 0.02793494, 0.02992192,\n",
       "        0.0292775 , 0.02891056, 0.02751189, 0.02984155, 0.02947396,\n",
       "        0.0286589 , 0.02728976, 0.02934118, 0.02714859, 0.02678203,\n",
       "        0.02699359, 0.02678102, 0.03018304, 0.02919469, 0.02791521,\n",
       "        0.03035093, 0.03011949, 0.02905818, 0.02795431, 0.03038561,\n",
       "        0.02995759, 0.02856886, 0.02799357, 0.03020452, 0.02933783,\n",
       "        0.02895163, 0.02838559, 0.02972093, 0.02940745, 0.02901752,\n",
       "        0.027861  , 0.02984018, 0.0293168 , 0.02893201, 0.02825022,\n",
       "        0.02970269, 0.02673501, 0.02654181, 0.02722001, 0.02644854,\n",
       "        0.03022267, 0.02994358, 0.02825008, 0.02922017, 0.03062972,\n",
       "        0.03030931, 0.02820995, 0.02940746, 0.03038117, 0.02957031,\n",
       "        0.02736863, 0.02865171, 0.03010048, 0.02957983, 0.02793474,\n",
       "        0.02967994, 0.03019067, 0.02992064, 0.02768038, 0.02907436,\n",
       "        0.02986232, 0.02958628, 0.02706088, 0.02882096, 0.02794786,\n",
       "        0.02634168, 0.02684791, 0.02709576, 0.03066713, 0.02995727,\n",
       "        0.02724999, 0.02924815, 0.03005093, 0.02958076, 0.02689878,\n",
       "        0.02918117, 0.03003933, 0.03011464, 0.02743211, 0.0293504 ,\n",
       "        0.02978302, 0.02991722, 0.02821188, 0.02929189, 0.02975849,\n",
       "        0.03004602, 0.02742596, 0.02923782, 0.02968577, 0.02976542,\n",
       "        0.02736766, 0.02886346, 0.02773413, 0.02660152, 0.02695798,\n",
       "        0.02697035, 0.02980142, 0.03012916, 0.02756455, 0.02937752,\n",
       "        0.02956105, 0.03002005, 0.0274326 , 0.02922409, 0.03005565,\n",
       "        0.03024654, 0.027921  , 0.02891879, 0.03095144, 0.03029503,\n",
       "        0.02846357, 0.02898818, 0.03033915, 0.02966746, 0.02834672,\n",
       "        0.0294353 , 0.0298709 , 0.02920389, 0.02723532, 0.0291178 ,\n",
       "        0.02769507, 0.02652274, 0.02708946, 0.02671382, 0.02981535,\n",
       "        0.03044221, 0.02797573, 0.02932843, 0.03029702, 0.0301736 ,\n",
       "        0.02811191, 0.02889792, 0.03016377, 0.03001992, 0.02807181,\n",
       "        0.02926265, 0.03020276, 0.02978776, 0.02818916, 0.02943774,\n",
       "        0.02984233, 0.03005966, 0.02840449, 0.02914161, 0.0293982 ,\n",
       "        0.0295483 , 0.02743817, 0.02860386, 0.02800764, 0.02629944,\n",
       "        0.02752088, 0.0270588 , 0.02998917, 0.02975929, 0.02801461,\n",
       "        0.02909364, 0.03012399, 0.02997556, 0.0278369 , 0.02955523,\n",
       "        0.03059143, 0.03003447, 0.02839417, 0.02892771, 0.03037089,\n",
       "        0.03030604, 0.02856148, 0.02950159, 0.03002384, 0.02985956,\n",
       "        0.02842969, 0.02917416, 0.02989922, 0.02946878, 0.02818982,\n",
       "        0.02939536, 0.02773779, 0.02637778, 0.02716802, 0.02669056,\n",
       "        0.02908788, 0.0286632 , 0.028396  , 0.02846206, 0.02881025,\n",
       "        0.02909733, 0.02803106, 0.02861543, 0.02942879, 0.02916968,\n",
       "        0.02852395, 0.02882283, 0.02872083, 0.02938375, 0.02743164,\n",
       "        0.02855917, 0.02903743, 0.02912851, 0.02772582, 0.02912933,\n",
       "        0.02950027, 0.02896843, 0.02797946, 0.02861073, 0.02819864,\n",
       "        0.02636467, 0.02608521, 0.02698372, 0.02982445, 0.02879959,\n",
       "        0.02872409, 0.02874829, 0.02929347, 0.0290929 , 0.02839305,\n",
       "        0.0287528 , 0.02923414, 0.0294656 , 0.02796844, 0.02907784,\n",
       "        0.02889177, 0.02912919, 0.02787094, 0.02923107, 0.02912693,\n",
       "        0.02899175, 0.02770602, 0.02843249, 0.02896585, 0.02864765,\n",
       "        0.02805728, 0.0284325 , 0.0282633 , 0.02649581, 0.02622392,\n",
       "        0.0267375 , 0.02877964, 0.02920673, 0.02798854, 0.02864737,\n",
       "        0.02902502, 0.02901195, 0.02830053, 0.02886221, 0.02962464,\n",
       "        0.02905669, 0.02841965, 0.02843645, 0.02874997, 0.0297858 ,\n",
       "        0.02803395, 0.02848929, 0.02880405, 0.02790076, 0.02784765,\n",
       "        0.02861688, 0.02825959, 0.02901429, 0.02766251, 0.02806599,\n",
       "        0.02815632, 0.02660753, 0.02622463, 0.0270383 , 0.02911623,\n",
       "        0.02911196, 0.02803714, 0.02871459, 0.02910122, 0.0294563 ,\n",
       "        0.02795769, 0.02860667, 0.02923867, 0.02932643, 0.02785326,\n",
       "        0.02885545, 0.02807383, 0.02929583, 0.0278437 , 0.02887609,\n",
       "        0.02871333, 0.02905821, 0.02816191, 0.02868884, 0.0287532 ,\n",
       "        0.02860131, 0.0280347 , 0.02879331, 0.02777261, 0.02720476,\n",
       "        0.02659377, 0.02701985, 0.02937739, 0.02925018, 0.02835214,\n",
       "        0.02872279, 0.02966165, 0.02961954, 0.02849351, 0.02928473,\n",
       "        0.02938734, 0.02940371, 0.02840609, 0.02914678, 0.0292171 ,\n",
       "        0.02930673, 0.02814941, 0.02839555, 0.02862241, 0.0293561 ,\n",
       "        0.02843576, 0.02921949, 0.02826403, 0.02866492, 0.02823066,\n",
       "        0.02872592, 0.02876674, 0.02654806, 0.02617685, 0.02691731,\n",
       "        0.02850142, 0.0285835 , 0.02826127, 0.02843703, 0.02889839,\n",
       "        0.0293204 , 0.02826854, 0.0285818 , 0.02871779, 0.02891756,\n",
       "        0.02795895, 0.02843303, 0.02848957, 0.02940909, 0.02794358,\n",
       "        0.02831479, 0.02857383, 0.02985243, 0.02848582, 0.02847348,\n",
       "        0.02862456, 0.02915005, 0.02816032, 0.02797665, 0.02662542,\n",
       "        0.02616202, 0.02717684, 0.02715933, 0.02897625, 0.02936566,\n",
       "        0.02817535, 0.02891627, 0.0279707 , 0.02877966, 0.02829751,\n",
       "        0.02866761, 0.02887903, 0.02925701, 0.02811642, 0.02849364,\n",
       "        0.02871863, 0.02950416, 0.02850713, 0.02848482, 0.02853582,\n",
       "        0.02978206, 0.0279343 , 0.02836979, 0.0286044 , 0.02885515,\n",
       "        0.02786185, 0.0278758 , 0.02711957, 0.02696919, 0.0267699 ,\n",
       "        0.02677135, 0.02789733, 0.02910767, 0.02817154, 0.02839885,\n",
       "        0.02903061, 0.02932655, 0.02815425, 0.02864019, 0.02881273,\n",
       "        0.0290328 , 0.02815125, 0.02842325, 0.02892153, 0.02871994,\n",
       "        0.0280477 , 0.02812035, 0.02876196, 0.02901458, 0.02815469,\n",
       "        0.02836532, 0.02795408, 0.02936666, 0.02860024, 0.02808274,\n",
       "        0.0270183 , 0.02679888, 0.02688375, 0.02733336, 0.02814138,\n",
       "        0.0293571 , 0.02828028, 0.02837076, 0.02862893, 0.02901931,\n",
       "        0.02835991, 0.02864465, 0.02842005, 0.02915452, 0.02811515,\n",
       "        0.02825959, 0.02870601, 0.02897868, 0.02869994, 0.02809621,\n",
       "        0.02850244, 0.0294451 , 0.02870173, 0.02813068, 0.02870148,\n",
       "        0.02948341, 0.02809332, 0.02808548, 0.02715274, 0.02654191,\n",
       "        0.02716653, 0.02698119, 0.02849612, 0.02920814, 0.027813  ,\n",
       "        0.02876828, 0.0280529 , 0.02952082, 0.0279282 , 0.02808349,\n",
       "        0.02822373, 0.0296361 , 0.02865911, 0.02834923, 0.02821291,\n",
       "        0.02905084, 0.02809708, 0.0284316 , 0.02823827, 0.02960082,\n",
       "        0.0283246 , 0.02783954, 0.02817678, 0.02918712, 0.02756772,\n",
       "        0.02732306, 0.0269052 , 0.02604486, 0.02716925, 0.02811143]),\n",
       " 'rank_test_AUC': array([231, 373, 424, 359, 288, 330, 229, 359, 148, 277, 356, 476, 175,\n",
       "        258, 382, 383,  99, 131, 350, 398,  83, 164, 246, 430,  25,  39,\n",
       "         67,  62, 181, 377, 323, 445, 101, 290, 237, 430, 130, 400, 219,\n",
       "        516, 243, 269, 342, 263, 102, 238, 374, 484, 312, 228, 198, 249,\n",
       "         27,  40,  50,  40, 136, 205, 202, 500, 136, 291, 309, 524, 254,\n",
       "        218, 359, 399, 231, 281, 342, 463, 167, 305, 386, 309, 120, 285,\n",
       "        273, 292,  33,  42,  37,  35, 279, 368, 285, 366, 231, 397, 403,\n",
       "        524,  97, 315, 386, 500, 153, 342, 472, 479, 142, 241, 143, 493,\n",
       "         92, 195, 252, 283,  21,  29,  30,  22, 124, 374, 385, 440, 144,\n",
       "        416, 403, 439, 224, 309, 316, 389, 175, 336, 392, 275, 153, 186,\n",
       "        209, 480, 124, 112, 371, 378,  19,  12,  10,   7, 222, 495,  88,\n",
       "        165, 167, 440, 162, 186, 363, 508, 151,  96, 258, 544, 255, 242,\n",
       "        150, 487, 298, 336, 321, 491, 170, 213,   2,  75,  59,  66, 300,\n",
       "        488, 268, 158, 319, 527, 178, 133, 389, 413, 252, 239, 400, 465,\n",
       "        139, 312, 197, 418, 100, 327, 182, 459, 116, 307,   1,  68,  46,\n",
       "         48, 251, 408, 127, 255, 265, 369, 105, 205, 300, 459, 145, 246,\n",
       "        308, 469, 161, 267, 257, 465, 188, 356, 283, 499, 122, 316,   4,\n",
       "         60,  72,  54, 332, 425,  93, 349, 339, 293,  85, 300, 245, 332,\n",
       "        104, 222, 364, 520, 127, 152, 109, 451, 126, 371, 135, 534, 114,\n",
       "        153,   3,  47,  48,  16, 189, 515, 159, 239, 173, 523, 105, 214,\n",
       "        174, 491, 111, 298,  89, 504, 118, 376, 346, 427, 185, 230, 182,\n",
       "        456,  91, 354,   5,  56,  31,  17, 331, 521, 366, 166, 432, 550,\n",
       "        493, 132, 393, 558, 327, 198, 440, 549, 445,  86, 231, 519, 403,\n",
       "         98, 269, 436, 462, 110,  34,  81,  71,  52, 321, 559, 503, 271,\n",
       "        278, 542, 510, 113, 288, 560, 545,  94, 427, 340, 417, 105, 332,\n",
       "        351, 510, 156, 300, 512, 422, 149,  13,  73,  53,  55, 354, 537,\n",
       "        486, 246, 258, 531, 484, 170, 261, 556, 539, 127, 440, 436, 472,\n",
       "        383, 413, 531, 455, 192, 324, 495, 420, 316,  15,  65,  43,  61,\n",
       "        175, 346, 500, 145, 214, 411, 282, 178, 214, 551, 474, 202, 426,\n",
       "        527, 410, 192, 448, 480, 524, 105, 378, 456, 305, 114,  24,  64,\n",
       "         58,  51, 141, 297, 412, 198, 358, 478, 359,  87, 163, 418, 370,\n",
       "        196, 231, 547, 434, 178, 452, 389, 464,  84, 312, 436, 422,  78,\n",
       "         14,  57,  26,  23, 324, 555, 554, 191, 326, 536, 475, 262, 413,\n",
       "        448, 542, 225, 211, 512, 506, 205, 319, 469, 452, 145, 120, 477,\n",
       "        452,  94,   6,  38,  70,  82, 136, 483, 531, 202, 294, 522, 393,\n",
       "        212, 294, 508, 380, 117, 250, 506, 471, 265, 214, 548, 467, 353,\n",
       "        160, 340, 495, 208,   9,  36,  76,  78, 408, 546, 527, 271, 274,\n",
       "        553, 468, 336, 388, 517, 488, 335, 227, 540, 498, 226, 103, 538,\n",
       "        364, 342, 182, 402, 535, 219,  10,  44,  76,  69, 167, 540, 396,\n",
       "        133, 210, 527, 380, 263, 294, 440, 433, 139, 406, 421, 448, 198,\n",
       "        287, 557, 456, 327, 275, 480, 512,  80,   8,  31,  63,  74, 189,\n",
       "        504, 395, 118, 279, 517, 351, 170, 194, 552, 346, 156, 231, 406,\n",
       "        447, 122, 300, 427, 435,  90, 243, 490, 459, 219,  18,  45,  28,\n",
       "         20]),\n",
       " 'split0_train_AUC': array([0.96567323, 0.96726704, 0.96709328, 0.96674576, 0.96551745,\n",
       "        0.96731497, 0.96735692, 0.96674576, 0.96536166, 0.96744679,\n",
       "        0.96730898, 0.96699741, 0.96527778, 0.96737489, 0.96690154,\n",
       "        0.96670382, 0.96501414, 0.96663191, 0.96661394, 0.96658997,\n",
       "        0.96443893, 0.96639224, 0.96632633, 0.96615257, 0.95521163,\n",
       "        0.95588271, 0.9570511 , 0.95682341, 0.96531373, 0.96751869,\n",
       "        0.96690154, 0.96658997, 0.96521786, 0.96719514, 0.96742882,\n",
       "        0.96692551, 0.96531373, 0.96721911, 0.96709328, 0.96660795,\n",
       "        0.96521786, 0.96736291, 0.96705733, 0.96669782, 0.96481042,\n",
       "        0.96675175, 0.96674576, 0.96636229, 0.96441497, 0.96593687,\n",
       "        0.96608666, 0.96576311, 0.95458849, 0.95546328, 0.95636804,\n",
       "        0.95633209, 0.96516993, 0.96712324, 0.96704535, 0.96672778,\n",
       "        0.96534968, 0.96711125, 0.96703336, 0.96695547, 0.96545753,\n",
       "        0.96717117, 0.9670813 , 0.96666787, 0.96515794, 0.96713522,\n",
       "        0.96716518, 0.96684762, 0.9647505 , 0.96628439, 0.96618253,\n",
       "        0.96654204, 0.96416331, 0.96592489, 0.96602675, 0.96569121,\n",
       "        0.95329427, 0.9546484 , 0.95554118, 0.95529551, 0.96534968,\n",
       "        0.9668596 , 0.96657799, 0.96672179, 0.96531373, 0.96697944,\n",
       "        0.96668584, 0.96645216, 0.96489431, 0.96695547, 0.96699741,\n",
       "        0.96653605, 0.96490629, 0.96667985, 0.96639824, 0.96658398,\n",
       "        0.96466662, 0.96645216, 0.96657799, 0.96602076, 0.96383976,\n",
       "        0.96573315, 0.96585898, 0.96557137, 0.95222174, 0.95391142,\n",
       "        0.95448663, 0.95377361, 0.96490629, 0.96672778, 0.96650609,\n",
       "        0.96617055, 0.96491827, 0.96667985, 0.96644617, 0.96634431,\n",
       "        0.96476249, 0.96667985, 0.9664222 , 0.96614658, 0.9646067 ,\n",
       "        0.9666439 , 0.96662592, 0.9661346 , 0.96407943, 0.9659848 ,\n",
       "        0.96636229, 0.96595485, 0.96349223, 0.96532571, 0.96534369,\n",
       "        0.96491228, 0.95101141, 0.95210191, 0.95277298, 0.95226968,\n",
       "        0.96727902, 0.96865713, 0.96835754, 0.9674408 , 0.96727902,\n",
       "        0.96874101, 0.96832159, 0.96742882, 0.96726704, 0.96863316,\n",
       "        0.96810589, 0.96762055, 0.9668596 , 0.96854928, 0.96814184,\n",
       "        0.96723109, 0.96663191, 0.96806994, 0.96806994, 0.96696745,\n",
       "        0.96626043, 0.9678782 , 0.96749473, 0.96669183, 0.95681742,\n",
       "        0.95758436, 0.95834532, 0.95835131, 0.96730299, 0.96866911,\n",
       "        0.96811787, 0.96778832, 0.96703935, 0.96868109, 0.96799803,\n",
       "        0.96766849, 0.96718316, 0.96862118, 0.96827366, 0.9676625 ,\n",
       "        0.96688357, 0.96853729, 0.9682377 , 0.96782427, 0.9667158 ,\n",
       "        0.96832159, 0.96790217, 0.96759659, 0.96644018, 0.96737489,\n",
       "        0.96736291, 0.96638026, 0.95601452, 0.95721887, 0.95714697,\n",
       "        0.957848  , 0.96753068, 0.96840547, 0.96833357, 0.96735692,\n",
       "        0.96699142, 0.96847738, 0.96803399, 0.96741683, 0.96705134,\n",
       "        0.96838151, 0.9680939 , 0.96783027, 0.96706332, 0.96844142,\n",
       "        0.9679501 , 0.96793213, 0.96654803, 0.96783027, 0.96745878,\n",
       "        0.96702138, 0.96590092, 0.96755464, 0.96737489, 0.96650609,\n",
       "        0.95494799, 0.95631411, 0.95634407, 0.95689531, 0.96718316,\n",
       "        0.96796208, 0.96745878, 0.96719514, 0.96690754, 0.96830961,\n",
       "        0.96744679, 0.96726105, 0.96694349, 0.9680939 , 0.96767448,\n",
       "        0.96733894, 0.96687158, 0.9680939 , 0.96774638, 0.96738688,\n",
       "        0.96597282, 0.96789018, 0.96747076, 0.96714121, 0.96572117,\n",
       "        0.9670034 , 0.96731497, 0.96618253, 0.95430687, 0.95561308,\n",
       "        0.95524159, 0.95586473, 0.96659596, 0.96830961, 0.96769845,\n",
       "        0.9670094 , 0.96654803, 0.96822572, 0.96748274, 0.96703336,\n",
       "        0.96620051, 0.96791415, 0.96767448, 0.96714721, 0.96617654,\n",
       "        0.96777035, 0.96772241, 0.96699142, 0.96564927, 0.96730299,\n",
       "        0.96703935, 0.96667985, 0.96542158, 0.96684762, 0.9667877 ,\n",
       "        0.96590691, 0.9528329 , 0.95394737, 0.95377361, 0.953486  ,\n",
       "        0.96777035, 0.96950796, 0.96930424, 0.96928027, 0.96777035,\n",
       "        0.96977159, 0.96934019, 0.96943606, 0.96790217, 0.96953192,\n",
       "        0.9693282 , 0.96934019, 0.96763853, 0.96930424, 0.96934019,\n",
       "        0.96924432, 0.96735093, 0.9689687 , 0.96908254, 0.96931622,\n",
       "        0.96702737, 0.96860919, 0.96864514, 0.96805795, 0.95797982,\n",
       "        0.9592321 , 0.95925606, 0.9597354 , 0.96777035, 0.96949597,\n",
       "        0.96948399, 0.96928027, 0.9678782 , 0.96949597, 0.96946002,\n",
       "        0.96877696, 0.96753068, 0.96940011, 0.96962779, 0.9694061 ,\n",
       "        0.96768646, 0.96907056, 0.9690406 , 0.96900465, 0.96713522,\n",
       "        0.9689687 , 0.96914246, 0.96884886, 0.96691952, 0.96852531,\n",
       "        0.96866911, 0.96836952, 0.95741659, 0.95876474, 0.95866887,\n",
       "        0.95919615, 0.96760258, 0.9691844 , 0.96905258, 0.96905258,\n",
       "        0.9677344 , 0.9693282 , 0.96929225, 0.96856725, 0.96768646,\n",
       "        0.96934019, 0.96956787, 0.96876498, 0.96744679, 0.96940011,\n",
       "        0.96913647, 0.96877097, 0.9670753 , 0.96863316, 0.96883089,\n",
       "        0.96884287, 0.966572  , 0.96815382, 0.96872304, 0.96808192,\n",
       "        0.9563201 , 0.95805172, 0.95793788, 0.95815358, 0.96733894,\n",
       "        0.96920837, 0.96913647, 0.9686751 , 0.96738688, 0.96917242,\n",
       "        0.96910052, 0.96845341, 0.96724307, 0.9688968 , 0.96900465,\n",
       "        0.96841147, 0.96718316, 0.96941209, 0.96886085, 0.96844142,\n",
       "        0.9669315 , 0.96863316, 0.96881291, 0.96854928, 0.96647613,\n",
       "        0.96841746, 0.96840547, 0.96789018, 0.95534944, 0.9569792 ,\n",
       "        0.95720688, 0.95676349, 0.96727902, 0.96910052, 0.96908853,\n",
       "        0.968747  , 0.96712324, 0.96895672, 0.96913647, 0.96864514,\n",
       "        0.96690754, 0.96908853, 0.96913647, 0.96827366, 0.96721911,\n",
       "        0.96908853, 0.9690406 , 0.9680939 , 0.96697944, 0.96844142,\n",
       "        0.96860919, 0.96826167, 0.96597282, 0.96827366, 0.9681658 ,\n",
       "        0.96730898, 0.95382753, 0.95546927, 0.95570295, 0.95460047,\n",
       "        0.96890878, 0.97029288, 0.97023895, 0.97001726, 0.96895672,\n",
       "        0.97028089, 0.97033482, 0.97001726, 0.96890878, 0.97022697,\n",
       "        0.97010713, 0.97013709, 0.96883688, 0.97033482, 0.97039474,\n",
       "        0.96996932, 0.96856126, 0.96996333, 0.97001126, 0.96994536,\n",
       "        0.96850134, 0.96954391, 0.96995135, 0.96943606, 0.95896247,\n",
       "        0.9603226 , 0.96071805, 0.96147301, 0.96869308, 0.97008317,\n",
       "        0.97015507, 0.97028089, 0.96869308, 0.9700592 , 0.97022697,\n",
       "        0.97017304, 0.96871705, 0.96999928, 0.97009515, 0.9697656 ,\n",
       "        0.96893275, 0.97010713, 0.97008317, 0.96978957, 0.96844142,\n",
       "        0.96980754, 0.96974763, 0.96974164, 0.96821374, 0.96951994,\n",
       "        0.96977159, 0.96920238, 0.95873478, 0.96009491, 0.9604664 ,\n",
       "        0.96070607, 0.96862118, 0.97015507, 0.9701311 , 0.96996932,\n",
       "        0.96860919, 0.97007118, 0.96997531, 0.97011312, 0.9688968 ,\n",
       "        0.96981953, 0.97008317, 0.96993337, 0.96895672, 0.96965176,\n",
       "        0.96996333, 0.97005321, 0.96834556, 0.96931622, 0.96990341,\n",
       "        0.96974164, 0.96811787, 0.96871705, 0.96947201, 0.96960982,\n",
       "        0.95765626, 0.95900441, 0.95922011, 0.95995111, 0.96876498,\n",
       "        0.96986746, 0.97025093, 0.97011312, 0.96868109, 0.96987945,\n",
       "        0.96995135, 0.97029288, 0.96859721, 0.96963978, 0.9699873 ,\n",
       "        0.97017304, 0.96874101, 0.96969969, 0.97021498, 0.97026891,\n",
       "        0.96824969, 0.96961581, 0.96972366, 0.96952593, 0.96803399,\n",
       "        0.96880093, 0.96962779, 0.968747  , 0.95656577, 0.95790193,\n",
       "        0.95845916, 0.95894449, 0.96847738, 0.96941209, 0.97021498,\n",
       "        0.96980155, 0.96828564, 0.96959184, 0.97008317, 0.96952593,\n",
       "        0.96830961, 0.96955589, 0.96990341, 0.96966973, 0.96871705,\n",
       "        0.96981953, 0.97010713, 0.96944804, 0.96786622, 0.9691844 ,\n",
       "        0.96942407, 0.9696218 , 0.96749473, 0.96870506, 0.96887283,\n",
       "        0.96839349, 0.95539138, 0.95636804, 0.95703911, 0.95702713]),\n",
       " 'split1_train_AUC': array([0.95703312, 0.95928602, 0.95992115, 0.95866887, 0.95706907,\n",
       "        0.95927404, 0.96012487, 0.95871681, 0.95696122, 0.95927404,\n",
       "        0.9598852 , 0.9583573 , 0.95687734, 0.95919015, 0.95983726,\n",
       "        0.95817156, 0.95663767, 0.95867486, 0.95992115, 0.95798581,\n",
       "        0.95643395, 0.95818354, 0.95914222, 0.95792589, 0.94469011,\n",
       "        0.94720664, 0.94775789, 0.94773991, 0.95681742, 0.95934594,\n",
       "        0.96012487, 0.95853705, 0.95678147, 0.95930999, 0.96011288,\n",
       "        0.95808168, 0.95669758, 0.95909429, 0.95984925, 0.95809366,\n",
       "        0.95705709, 0.95883065, 0.96032859, 0.958573  , 0.9566137 ,\n",
       "        0.95838726, 0.95951371, 0.95779408, 0.9563261 , 0.95820751,\n",
       "        0.9589385 , 0.95722486, 0.94430663, 0.94648763, 0.94730251,\n",
       "        0.94686511, 0.95691329, 0.95905834, 0.95968148, 0.9582854 ,\n",
       "        0.95691329, 0.95883065, 0.95969346, 0.95802176, 0.95642196,\n",
       "        0.95910627, 0.9598133 , 0.95790193, 0.95680544, 0.95887858,\n",
       "        0.95976536, 0.95782403, 0.95648188, 0.95833933, 0.95935792,\n",
       "        0.95751845, 0.95609841, 0.95795585, 0.95877073, 0.95734469,\n",
       "        0.94313225, 0.94550499, 0.94630788, 0.94557089, 0.95650585,\n",
       "        0.95905834, 0.95968148, 0.95812961, 0.95662568, 0.95877073,\n",
       "        0.9597414 , 0.95760234, 0.95681742, 0.95880668, 0.95978933,\n",
       "        0.95751246, 0.95684139, 0.95868685, 0.95929801, 0.95732073,\n",
       "        0.95618229, 0.95814759, 0.95911825, 0.95723684, 0.95565502,\n",
       "        0.95768023, 0.95848313, 0.95704511, 0.94202977, 0.94431862,\n",
       "        0.94446242, 0.94352171, 0.95637403, 0.95868685, 0.95929801,\n",
       "        0.95724883, 0.956398  , 0.95847114, 0.95929801, 0.95706308,\n",
       "        0.95652981, 0.9586509 , 0.95910627, 0.95723085, 0.95630213,\n",
       "        0.95874676, 0.95895048, 0.95708705, 0.95611039, 0.95817156,\n",
       "        0.95887858, 0.95685936, 0.95546328, 0.95720089, 0.95826742,\n",
       "        0.95667362, 0.94089133, 0.94217357, 0.94264093, 0.94137667,\n",
       "        0.95978933, 0.96110752, 0.96143107, 0.95993313, 0.95998107,\n",
       "        0.96103561, 0.96121537, 0.95996908, 0.95994512, 0.96084388,\n",
       "        0.96146702, 0.95989718, 0.95980131, 0.9610476 , 0.96165876,\n",
       "        0.9599571 , 0.95903437, 0.96040049, 0.96156289, 0.95939387,\n",
       "        0.95843519, 0.95996908, 0.96072404, 0.95929801, 0.94719466,\n",
       "        0.94914797, 0.9497112 , 0.94923785, 0.95968148, 0.96108355,\n",
       "        0.96173066, 0.960029  , 0.95966949, 0.9609757 , 0.96170669,\n",
       "        0.95983726, 0.95962156, 0.96096371, 0.96132322, 0.95940586,\n",
       "        0.95952569, 0.96081991, 0.96109553, 0.95940586, 0.95911825,\n",
       "        0.96049636, 0.96096371, 0.95893251, 0.95850709, 0.95947776,\n",
       "        0.96058024, 0.95900441, 0.9467273 , 0.94844095, 0.94884838,\n",
       "        0.94862669, 0.95916619, 0.96091578, 0.96149099, 0.9597414 ,\n",
       "        0.95921412, 0.96073603, 0.96152694, 0.95984925, 0.95917817,\n",
       "        0.96103561, 0.961479  , 0.95932197, 0.95923809, 0.96067611,\n",
       "        0.9611195 , 0.95972941, 0.95881867, 0.96030462, 0.96065214,\n",
       "        0.95921412, 0.95826742, 0.95960958, 0.96023272, 0.95878271,\n",
       "        0.94587647, 0.94778185, 0.94799756, 0.94668536, 0.95880668,\n",
       "        0.96062818, 0.96121537, 0.95927404, 0.95913024, 0.9603166 ,\n",
       "        0.96121537, 0.95954367, 0.9590823 , 0.96074801, 0.96131124,\n",
       "        0.959304  , 0.95910627, 0.96077198, 0.96109553, 0.95952569,\n",
       "        0.95873478, 0.960029  , 0.96073603, 0.95914821, 0.95831536,\n",
       "        0.95926206, 0.9599571 , 0.95855503, 0.94486986, 0.94691904,\n",
       "        0.94687111, 0.94510953, 0.95899842, 0.96056826, 0.9609038 ,\n",
       "        0.95873478, 0.95899842, 0.96053231, 0.96096371, 0.95878271,\n",
       "        0.95874676, 0.96042446, 0.96062818, 0.95902239, 0.95921412,\n",
       "        0.96052032, 0.96078396, 0.95922011, 0.9587228 , 0.95976536,\n",
       "        0.96025669, 0.95865689, 0.9579918 , 0.95898643, 0.95989718,\n",
       "        0.95819552, 0.9431682 , 0.94467812, 0.94504362, 0.94366552,\n",
       "        0.9611195 , 0.96162281, 0.96155091, 0.96077198, 0.9611195 ,\n",
       "        0.9613352 , 0.96212611, 0.96064016, 0.96125132, 0.96159884,\n",
       "        0.96176661, 0.96095173, 0.96114347, 0.96200628, 0.96219802,\n",
       "        0.96047838, 0.96065214, 0.96146702, 0.96179058, 0.96069408,\n",
       "        0.95986123, 0.96139512, 0.96109553, 0.95993313, 0.94913599,\n",
       "        0.95002277, 0.95045418, 0.95041223, 0.96109553, 0.96176661,\n",
       "        0.96183851, 0.96055627, 0.96105958, 0.96156289, 0.96205421,\n",
       "        0.9602447 , 0.96113148, 0.96165876, 0.96182653, 0.96075999,\n",
       "        0.96084388, 0.96153892, 0.96175463, 0.96057425, 0.96078396,\n",
       "        0.96151496, 0.96125132, 0.9601728 , 0.96004098, 0.96123933,\n",
       "        0.96103561, 0.96011288, 0.94822524, 0.94945954, 0.95011864,\n",
       "        0.95011265, 0.96132322, 0.96187446, 0.961479  , 0.96055627,\n",
       "        0.96137115, 0.96127529, 0.961479  , 0.96055627, 0.96098768,\n",
       "        0.96144305, 0.96139512, 0.96054429, 0.96089181, 0.96138314,\n",
       "        0.96161082, 0.96033458, 0.96036454, 0.96125132, 0.96117942,\n",
       "        0.96008892, 0.95964553, 0.96064016, 0.9608319 , 0.95966949,\n",
       "        0.94775789, 0.94835706, 0.94914797, 0.94873454, 0.96086785,\n",
       "        0.96135917, 0.96128727, 0.96065214, 0.96059223, 0.96150297,\n",
       "        0.96139512, 0.96013086, 0.96081991, 0.96138314, 0.96145504,\n",
       "        0.96026867, 0.9608319 , 0.96120338, 0.96114347, 0.9601728 ,\n",
       "        0.96013685, 0.96085586, 0.96099966, 0.96008293, 0.95986123,\n",
       "        0.9608319 , 0.9609757 , 0.95931598, 0.94641573, 0.94761408,\n",
       "        0.94743433, 0.94681718, 0.96049636, 0.96120338, 0.96086785,\n",
       "        0.96016082, 0.9603166 , 0.9609757 , 0.96075999, 0.96011288,\n",
       "        0.96042446, 0.96093975, 0.96101165, 0.9601728 , 0.96030462,\n",
       "        0.96092776, 0.96110752, 0.96011288, 0.95993313, 0.96073603,\n",
       "        0.96079594, 0.95944181, 0.95944181, 0.95980131, 0.96019677,\n",
       "        0.95891453, 0.94532523, 0.94587647, 0.94584652, 0.94467213,\n",
       "        0.9624257 , 0.96300091, 0.96234182, 0.96152095, 0.9622819 ,\n",
       "        0.96298893, 0.96232983, 0.96173665, 0.96218603, 0.96302488,\n",
       "        0.96210215, 0.96112549, 0.96215008, 0.96290504, 0.96248562,\n",
       "        0.96168872, 0.96207818, 0.96244967, 0.96207818, 0.96101764,\n",
       "        0.96149099, 0.96218603, 0.96189843, 0.96089181, 0.95070583,\n",
       "        0.95128104, 0.95192815, 0.95103538, 0.96207818, 0.96294099,\n",
       "        0.96198231, 0.96129326, 0.96244967, 0.96284513, 0.96224595,\n",
       "        0.96146103, 0.96221   , 0.96301289, 0.96247364, 0.96126929,\n",
       "        0.96231785, 0.96302488, 0.96243769, 0.96123933, 0.96146702,\n",
       "        0.96285711, 0.96180256, 0.96131124, 0.9614071 , 0.96218603,\n",
       "        0.96167074, 0.9608319 , 0.95023847, 0.95077773, 0.95095748,\n",
       "        0.95086761, 0.96179058, 0.96283314, 0.96216206, 0.96128128,\n",
       "        0.96177859, 0.96301289, 0.96226992, 0.96152095, 0.96186248,\n",
       "        0.96303686, 0.96230587, 0.961485  , 0.96197033, 0.96255752,\n",
       "        0.9621381 , 0.961485  , 0.96175463, 0.96278521, 0.96175463,\n",
       "        0.96116144, 0.96162281, 0.96195835, 0.96141909, 0.96057425,\n",
       "        0.94960335, 0.95005872, 0.95037029, 0.94988496, 0.96181454,\n",
       "        0.96286909, 0.96215008, 0.96108954, 0.96215008, 0.96259347,\n",
       "        0.96215008, 0.96158086, 0.9620662 , 0.96262942, 0.96177859,\n",
       "        0.96134119, 0.96168272, 0.96273727, 0.96217405, 0.96125731,\n",
       "        0.96152694, 0.96223397, 0.96170669, 0.96095772, 0.96099966,\n",
       "        0.96158686, 0.96131124, 0.9603945 , 0.94824921, 0.94901615,\n",
       "        0.94877648, 0.94806346, 0.96222198, 0.96300091, 0.96145504,\n",
       "        0.96114946, 0.9620662 , 0.96221   , 0.96159884, 0.96135318,\n",
       "        0.96188644, 0.96270132, 0.96091578, 0.96100566, 0.96188644,\n",
       "        0.9624976 , 0.96141909, 0.96107157, 0.96135917, 0.96197033,\n",
       "        0.96113148, 0.960754  , 0.96073603, 0.96143107, 0.96098768,\n",
       "        0.96041846, 0.94676325, 0.94762607, 0.94697297, 0.94617007]),\n",
       " 'split2_train_AUC': array([0.94513949, 0.94670933, 0.94769198, 0.94777586, 0.94489982,\n",
       "        0.9468052 , 0.94787173, 0.94800355, 0.944768  , 0.94666139,\n",
       "        0.94800355, 0.94775189, 0.944768  , 0.94645767, 0.94791966,\n",
       "        0.94727255, 0.94452833, 0.9460742 , 0.94758412, 0.94729652,\n",
       "        0.94401304, 0.94543908, 0.94732049, 0.94675726, 0.93082518,\n",
       "        0.93327581, 0.93440226, 0.93487561, 0.94493577, 0.94675726,\n",
       "        0.94801553, 0.94775189, 0.94493577, 0.94662544, 0.94809942,\n",
       "        0.94801553, 0.9449837 , 0.94640974, 0.9481833 , 0.94782379,\n",
       "        0.9451275 , 0.94636181, 0.94805148, 0.94748826, 0.94403701,\n",
       "        0.94603825, 0.94746429, 0.9468771 , 0.9436775 , 0.94504362,\n",
       "        0.9470209 , 0.94639776, 0.93007022, 0.93259275, 0.93346156,\n",
       "        0.93392292, 0.94463618, 0.94661945, 0.94767999, 0.94740437,\n",
       "        0.94473205, 0.94655354, 0.94775189, 0.94733247, 0.94495974,\n",
       "        0.94643371, 0.94758412, 0.94762007, 0.94472007, 0.94654156,\n",
       "        0.9480395 , 0.94734445, 0.94448039, 0.94611015, 0.94727854,\n",
       "        0.94685313, 0.94330601, 0.94516346, 0.9468052 , 0.94660148,\n",
       "        0.92906361, 0.93156217, 0.93240701, 0.93206548, 0.94457626,\n",
       "        0.94666739, 0.9473085 , 0.94736842, 0.94470808, 0.94642772,\n",
       "        0.9477459 , 0.94727255, 0.94451635, 0.94613412, 0.94748226,\n",
       "        0.9470928 , 0.94440849, 0.94628991, 0.94742235, 0.94710478,\n",
       "        0.94416882, 0.94553494, 0.94690106, 0.94708082, 0.94317419,\n",
       "        0.9448399 , 0.94592441, 0.94570271, 0.92798509, 0.92987849,\n",
       "        0.9307413 , 0.92998035, 0.94427668, 0.9460023 , 0.94730251,\n",
       "        0.94666139, 0.94434858, 0.94608619, 0.94715871, 0.94670933,\n",
       "        0.94444444, 0.9460023 , 0.94736243, 0.94652958, 0.94425271,\n",
       "        0.94597833, 0.94696697, 0.94642172, 0.94342585, 0.94540313,\n",
       "        0.94625995, 0.94611015, 0.94282667, 0.9446242 , 0.94589445,\n",
       "        0.94593639, 0.9254326 , 0.92778137, 0.92873406, 0.92773344,\n",
       "        0.94688908, 0.9478178 , 0.9497112 , 0.94922587, 0.9472366 ,\n",
       "        0.94794363, 0.94949549, 0.94914198, 0.94693701, 0.94770396,\n",
       "        0.94907008, 0.94877049, 0.94700892, 0.94756016, 0.94908805,\n",
       "        0.94868661, 0.94684115, 0.94746429, 0.94819528, 0.94849487,\n",
       "        0.94642172, 0.94675127, 0.94814136, 0.94766801, 0.93387499,\n",
       "        0.93510929, 0.93573243, 0.93692479, 0.94722462, 0.94790768,\n",
       "        0.9490581 , 0.94895024, 0.94717668, 0.94776388, 0.94903413,\n",
       "        0.94891429, 0.94717668, 0.94747627, 0.94932173, 0.94913   ,\n",
       "        0.94724859, 0.94764404, 0.94924384, 0.94897421, 0.94669734,\n",
       "        0.94726656, 0.94859673, 0.94836305, 0.94630189, 0.94709879,\n",
       "        0.94801553, 0.94824322, 0.93337168, 0.93443821, 0.9350314 ,\n",
       "        0.93624772, 0.94699693, 0.94746429, 0.94907607, 0.94849487,\n",
       "        0.94686511, 0.94750024, 0.94896822, 0.94844694, 0.94705685,\n",
       "        0.94748226, 0.94882442, 0.94836305, 0.94682916, 0.94748826,\n",
       "        0.94899219, 0.94869859, 0.94645767, 0.94708681, 0.94875252,\n",
       "        0.9479676 , 0.94588247, 0.94666739, 0.94778784, 0.9481114 ,\n",
       "        0.93253283, 0.93358738, 0.93413263, 0.93446218, 0.94660148,\n",
       "        0.94761408, 0.94878248, 0.94850685, 0.94696098, 0.94761408,\n",
       "        0.94869859, 0.94833909, 0.94704487, 0.94712875, 0.94908206,\n",
       "        0.94871057, 0.94670933, 0.94725458, 0.94880045, 0.94856677,\n",
       "        0.94626594, 0.94711078, 0.94797359, 0.94790768, 0.94581056,\n",
       "        0.94623598, 0.94753619, 0.94756016, 0.93081919, 0.93210742,\n",
       "        0.93242498, 0.93264069, 0.94645767, 0.94727854, 0.94863867,\n",
       "        0.94778784, 0.94662544, 0.94711677, 0.94867462, 0.94833909,\n",
       "        0.94654156, 0.94704487, 0.9484709 , 0.94785974, 0.9461461 ,\n",
       "        0.94712875, 0.948399  , 0.94783578, 0.94605023, 0.94674528,\n",
       "        0.94775789, 0.94778784, 0.94487585, 0.94599631, 0.94661346,\n",
       "        0.94699693, 0.92865018, 0.92978262, 0.93077126, 0.92962084,\n",
       "        0.94899818, 0.94909405, 0.94984901, 0.94909405, 0.94924983,\n",
       "        0.94835107, 0.94975913, 0.94922587, 0.94873454, 0.94874652,\n",
       "        0.94975314, 0.94933372, 0.94922587, 0.94898619, 0.94961533,\n",
       "        0.94940562, 0.94853082, 0.94869859, 0.94942958, 0.94908206,\n",
       "        0.94777586, 0.94794363, 0.94869859, 0.94877049, 0.93607995,\n",
       "        0.93653533, 0.93739215, 0.93789546, 0.94845892, 0.94904611,\n",
       "        0.94974715, 0.94896223, 0.94857876, 0.94890231, 0.94961533,\n",
       "        0.94923785, 0.94874652, 0.94907008, 0.94989095, 0.94917793,\n",
       "        0.94889033, 0.94873454, 0.94966926, 0.94909405, 0.94817132,\n",
       "        0.9481833 , 0.94901016, 0.94923785, 0.94754817, 0.94783578,\n",
       "        0.94851884, 0.94820727, 0.93539689, 0.93610392, 0.93665516,\n",
       "        0.93784752, 0.94902215, 0.94842297, 0.94951347, 0.94909405,\n",
       "        0.94896223, 0.94855479, 0.94947752, 0.94898619, 0.94872256,\n",
       "        0.94851884, 0.94947153, 0.948399  , 0.94918991, 0.94874053,\n",
       "        0.94947752, 0.94928578, 0.94819528, 0.94835107, 0.94928578,\n",
       "        0.94863867, 0.94734445, 0.94751222, 0.94850685, 0.94878248,\n",
       "        0.93409069, 0.93494152, 0.93573243, 0.93587024, 0.94879446,\n",
       "        0.94845892, 0.94969322, 0.94836305, 0.94880644, 0.94824322,\n",
       "        0.9496333 , 0.94859074, 0.94877049, 0.94861471, 0.94913   ,\n",
       "        0.94833909, 0.94853082, 0.94802751, 0.94936967, 0.94895024,\n",
       "        0.94791966, 0.94772793, 0.94877049, 0.94843495, 0.94742834,\n",
       "        0.9471647 , 0.94830913, 0.9480395 , 0.9324849 , 0.93389896,\n",
       "        0.93457003, 0.93397086, 0.94841099, 0.94795561, 0.94867462,\n",
       "        0.94842297, 0.94841099, 0.9480395 , 0.94881843, 0.94836305,\n",
       "        0.94849487, 0.94805148, 0.9486926 , 0.94821925, 0.94872256,\n",
       "        0.94812338, 0.94897421, 0.94896223, 0.94781181, 0.9473085 ,\n",
       "        0.94827917, 0.94776388, 0.94666139, 0.94668536, 0.9479676 ,\n",
       "        0.94773991, 0.93096899, 0.93186775, 0.9316101 , 0.93040576,\n",
       "        0.95049612, 0.94981306, 0.95091554, 0.95081967, 0.95024446,\n",
       "        0.94992091, 0.95069984, 0.95078372, 0.95079571, 0.95016058,\n",
       "        0.95058   , 0.95011265, 0.95019653, 0.94980107, 0.9503643 ,\n",
       "        0.95040025, 0.95013661, 0.94953744, 0.9504362 , 0.95013062,\n",
       "        0.95000479, 0.94904611, 0.94965727, 0.94953744, 0.93780558,\n",
       "        0.9381531 , 0.93916571, 0.93900992, 0.9503643 , 0.94989694,\n",
       "        0.95075975, 0.95060397, 0.95049612, 0.94986099, 0.95084364,\n",
       "        0.95044818, 0.95013661, 0.94975314, 0.95063992, 0.95020851,\n",
       "        0.95049612, 0.94957938, 0.95069984, 0.95038227, 0.94975314,\n",
       "        0.94975314, 0.95010665, 0.95006471, 0.9492019 , 0.94898619,\n",
       "        0.94953744, 0.94932173, 0.93726632, 0.93770971, 0.93838079,\n",
       "        0.93763182, 0.95056802, 0.94984901, 0.95067587, 0.95025645,\n",
       "        0.95031636, 0.94978909, 0.95058   , 0.95024446, 0.95054405,\n",
       "        0.94938165, 0.95045418, 0.95049013, 0.95034033, 0.94945355,\n",
       "        0.95066389, 0.9502924 , 0.94971719, 0.9492019 , 0.95010665,\n",
       "        0.94968124, 0.94884239, 0.94886636, 0.94988496, 0.94957339,\n",
       "        0.93572045, 0.93641549, 0.93703863, 0.93667314, 0.94982504,\n",
       "        0.94970521, 0.95065789, 0.95002876, 0.95017256, 0.94970521,\n",
       "        0.95041822, 0.94968124, 0.94964529, 0.94981306, 0.95066988,\n",
       "        0.95049612, 0.94996884, 0.94923785, 0.95052008, 0.95032835,\n",
       "        0.94945355, 0.94891429, 0.95016058, 0.94968124, 0.94891429,\n",
       "        0.94826718, 0.94954942, 0.94910603, 0.93422251, 0.93491156,\n",
       "        0.9358283 , 0.93436032, 0.94972917, 0.94910603, 0.95041223,\n",
       "        0.94993888, 0.94992091, 0.94907008, 0.95037628, 0.94989095,\n",
       "        0.94918991, 0.94904611, 0.95020851, 0.94983103, 0.94916595,\n",
       "        0.94910603, 0.95041223, 0.94995087, 0.94936967, 0.94859074,\n",
       "        0.94977111, 0.94987297, 0.94817132, 0.94829115, 0.94904611,\n",
       "        0.94926182, 0.93296424, 0.93318594, 0.93369524, 0.93207746]),\n",
       " 'mean_train_AUC': array([0.95594861, 0.95775413, 0.95823547, 0.95773016, 0.95582878,\n",
       "        0.95779807, 0.95845117, 0.95782204, 0.95569696, 0.95779408,\n",
       "        0.95839924, 0.9577022 , 0.95564104, 0.95767424, 0.95821949,\n",
       "        0.95738264, 0.95539338, 0.95712699, 0.95803974, 0.95729077,\n",
       "        0.95496197, 0.95667162, 0.95759635, 0.95694524, 0.94357564,\n",
       "        0.94545505, 0.94640375, 0.94647964, 0.95568897, 0.95787397,\n",
       "        0.95834731, 0.95762631, 0.95564503, 0.95771019, 0.95854704,\n",
       "        0.95767424, 0.955665  , 0.95757438, 0.95837528, 0.95750847,\n",
       "        0.95580082, 0.95751845, 0.95847913, 0.95758636, 0.95515371,\n",
       "        0.95705909, 0.95790792, 0.95701115, 0.95480619, 0.956396  ,\n",
       "        0.95734869, 0.95646191, 0.94298845, 0.94484789, 0.9457107 ,\n",
       "        0.94570671, 0.95557313, 0.95760034, 0.95813561, 0.95747252,\n",
       "        0.955665  , 0.95749848, 0.95815957, 0.95743657, 0.95561308,\n",
       "        0.95757038, 0.95815957, 0.95739662, 0.95556115, 0.95751845,\n",
       "        0.95832335, 0.9573387 , 0.95523759, 0.95691129, 0.95760633,\n",
       "        0.95697121, 0.95452258, 0.95634807, 0.95720089, 0.95654579,\n",
       "        0.94183004, 0.94390519, 0.94475202, 0.94431063, 0.95547726,\n",
       "        0.95752844, 0.95785599, 0.95740661, 0.95554916, 0.95739263,\n",
       "        0.95805771, 0.95710902, 0.95540936, 0.95729876, 0.95808967,\n",
       "        0.9570471 , 0.95538539, 0.95721887, 0.9577062 , 0.95700316,\n",
       "        0.95500591, 0.95671156, 0.95753244, 0.95677947, 0.95422299,\n",
       "        0.95608443, 0.9567555 , 0.9561064 , 0.94074553, 0.94270284,\n",
       "        0.94323012, 0.94242522, 0.95518566, 0.95713898, 0.9577022 ,\n",
       "        0.95669359, 0.95522162, 0.95707906, 0.9576343 , 0.95670557,\n",
       "        0.95524558, 0.95711102, 0.9576303 , 0.95663567, 0.95505385,\n",
       "        0.957123  , 0.95751446, 0.95654779, 0.95453855, 0.95651983,\n",
       "        0.95716694, 0.95630812, 0.9539274 , 0.95571693, 0.95650185,\n",
       "        0.95584076, 0.93911178, 0.94068562, 0.94138266, 0.94045993,\n",
       "        0.95798581, 0.95919415, 0.95983327, 0.9588666 , 0.95816556,\n",
       "        0.95924009, 0.95967748, 0.95884663, 0.95804972, 0.95906033,\n",
       "        0.95954766, 0.95876274, 0.95788994, 0.95905234, 0.95962955,\n",
       "        0.95862493, 0.95750248, 0.9586449 , 0.95927604, 0.9582854 ,\n",
       "        0.95703911, 0.95819952, 0.95878671, 0.95788595, 0.94596236,\n",
       "        0.94728054, 0.94792965, 0.94817132, 0.9580697 , 0.95922011,\n",
       "        0.95963554, 0.95892252, 0.95796184, 0.95914022, 0.95957962,\n",
       "        0.95880668, 0.9579938 , 0.95902039, 0.95963954, 0.95873278,\n",
       "        0.95788595, 0.95900042, 0.95952569, 0.95873478, 0.95751047,\n",
       "        0.95869484, 0.9591542 , 0.95829738, 0.95708305, 0.95798381,\n",
       "        0.95865289, 0.95787596, 0.94537117, 0.94669934, 0.94700892,\n",
       "        0.94757414, 0.95789793, 0.95892851, 0.95963354, 0.95853106,\n",
       "        0.95769022, 0.95890455, 0.95950971, 0.95857101, 0.95776212,\n",
       "        0.95896646, 0.95946578, 0.9585051 , 0.95771019, 0.9588686 ,\n",
       "        0.95935393, 0.95878671, 0.95727479, 0.95840723, 0.95895448,\n",
       "        0.9580677 , 0.9566836 , 0.95794387, 0.95846515, 0.95780007,\n",
       "        0.94445243, 0.94589445, 0.94615809, 0.94601428, 0.95753044,\n",
       "        0.95873478, 0.95915221, 0.95832534, 0.95766625, 0.95874676,\n",
       "        0.95912025, 0.95838127, 0.95769022, 0.95865689, 0.95935593,\n",
       "        0.95845117, 0.95756239, 0.95870682, 0.95921412, 0.95849311,\n",
       "        0.95699118, 0.95834332, 0.95872679, 0.9580657 , 0.9566157 ,\n",
       "        0.95750048, 0.95826942, 0.95743257, 0.94333198, 0.94487985,\n",
       "        0.94484589, 0.94453832, 0.95735069, 0.9587188 , 0.95908031,\n",
       "        0.95784401, 0.95739063, 0.95862493, 0.95904036, 0.95805172,\n",
       "        0.95716294, 0.95846116, 0.95892452, 0.95800978, 0.95717892,\n",
       "        0.95847314, 0.95896846, 0.95801577, 0.95680743, 0.95793788,\n",
       "        0.95835131, 0.95770819, 0.95609641, 0.95727679, 0.95776611,\n",
       "        0.95703312, 0.94155043, 0.9428027 , 0.94319616, 0.94225745,\n",
       "        0.95929601, 0.96007494, 0.96023472, 0.95971543, 0.95937989,\n",
       "        0.95981929, 0.96040848, 0.95976736, 0.95929601, 0.9599591 ,\n",
       "        0.96028265, 0.95987521, 0.95933595, 0.9600989 , 0.96038451,\n",
       "        0.95970944, 0.95884463, 0.95971144, 0.9601009 , 0.95969746,\n",
       "        0.95822149, 0.95931598, 0.95947976, 0.95892053, 0.94773192,\n",
       "        0.94859673, 0.94903413, 0.9493477 , 0.95910827, 0.9601029 ,\n",
       "        0.96035655, 0.95959959, 0.95917218, 0.95998706, 0.96037652,\n",
       "        0.95941984, 0.95913623, 0.96004298, 0.96044842, 0.95978134,\n",
       "        0.95914022, 0.95978134, 0.96015483, 0.95955765, 0.95869683,\n",
       "        0.95955565, 0.95980131, 0.95941984, 0.95816956, 0.95920014,\n",
       "        0.95940785, 0.95889656, 0.94701291, 0.9481094 , 0.94848089,\n",
       "        0.9490521 , 0.95931598, 0.95982728, 0.96001502, 0.95956763,\n",
       "        0.95935593, 0.95971943, 0.96008293, 0.95936991, 0.95913223,\n",
       "        0.95976736, 0.96014484, 0.95923609, 0.95917617, 0.95984126,\n",
       "        0.96007494, 0.95946378, 0.95854504, 0.95941185, 0.95976536,\n",
       "        0.95919015, 0.95785399, 0.95876873, 0.95935393, 0.95884463,\n",
       "        0.94605623, 0.94711677, 0.94760609, 0.94758612, 0.95900042,\n",
       "        0.95967549, 0.96003899, 0.9592301 , 0.95892851, 0.95963954,\n",
       "        0.96004298, 0.95905834, 0.95894449, 0.95963155, 0.95986323,\n",
       "        0.95900641, 0.95884862, 0.95954766, 0.95979133, 0.95918816,\n",
       "        0.95832934, 0.95907232, 0.95952769, 0.95902239, 0.9579219 ,\n",
       "        0.95880468, 0.9592301 , 0.95841522, 0.94475002, 0.94616408,\n",
       "        0.94640375, 0.94585051, 0.95872879, 0.95941984, 0.95954367,\n",
       "        0.95911026, 0.95861694, 0.95932397, 0.95957163, 0.95904036,\n",
       "        0.95860895, 0.95935992, 0.95961357, 0.95888857, 0.95874876,\n",
       "        0.95937989, 0.95970744, 0.95905634, 0.95824146, 0.95882865,\n",
       "        0.9592281 , 0.95848912, 0.95735867, 0.95825344, 0.95877672,\n",
       "        0.95798781, 0.94337392, 0.9444045 , 0.94438652, 0.94322612,\n",
       "        0.9606102 , 0.96103561, 0.96116544, 0.96078596, 0.96049436,\n",
       "        0.96106358, 0.9611215 , 0.96084588, 0.96063017, 0.96113747,\n",
       "        0.96092976, 0.96045841, 0.9603945 , 0.96101365, 0.96108155,\n",
       "        0.9606861 , 0.96025868, 0.96065015, 0.96084188, 0.96036454,\n",
       "        0.95999904, 0.96025868, 0.96050235, 0.9599551 , 0.94915796,\n",
       "        0.94991891, 0.95060397, 0.9505061 , 0.96037852, 0.9609737 ,\n",
       "        0.96096571, 0.96072604, 0.96054629, 0.96092177, 0.96110552,\n",
       "        0.96069408, 0.96035455, 0.96092177, 0.96106957, 0.96041447,\n",
       "        0.96058224, 0.9609038 , 0.96107356, 0.96047039, 0.9598872 ,\n",
       "        0.96080593, 0.96055228, 0.96037253, 0.95960758, 0.96023072,\n",
       "        0.96032659, 0.95978534, 0.94874652, 0.94952745, 0.94993489,\n",
       "        0.94973516, 0.96032659, 0.96094574, 0.96098968, 0.96050235,\n",
       "        0.96023472, 0.96095772, 0.96094174, 0.96062618, 0.96043444,\n",
       "        0.96074601, 0.96094774, 0.96063616, 0.96042246, 0.96055428,\n",
       "        0.96092177, 0.9606102 , 0.95993912, 0.96043444, 0.96058823,\n",
       "        0.96019477, 0.95952769, 0.95984725, 0.96025868, 0.95991915,\n",
       "        0.94766002, 0.94849287, 0.94887635, 0.9488364 , 0.96013485,\n",
       "        0.96081392, 0.96101964, 0.96041048, 0.96033458, 0.96072604,\n",
       "        0.96083988, 0.96051833, 0.9601029 , 0.96069408, 0.96081192,\n",
       "        0.96067012, 0.96013086, 0.96055827, 0.96096971, 0.96061819,\n",
       "        0.95974339, 0.96025469, 0.96053031, 0.96005496, 0.95931598,\n",
       "        0.95955166, 0.96016282, 0.95941584, 0.94634583, 0.94727655,\n",
       "        0.94768798, 0.94712276, 0.96014284, 0.96050634, 0.96069408,\n",
       "        0.96029663, 0.96009091, 0.96029064, 0.9606861 , 0.96025669,\n",
       "        0.95979532, 0.96043444, 0.96034257, 0.96016881, 0.95992315,\n",
       "        0.96047439, 0.96064615, 0.96015682, 0.95953168, 0.95991516,\n",
       "        0.96010889, 0.96008293, 0.95880069, 0.95947576, 0.95963554,\n",
       "        0.95935792, 0.94503963, 0.94572668, 0.94590244, 0.94509155]),\n",
       " 'std_train_AUC': array([0.00841787, 0.00846227, 0.00800974, 0.00777282, 0.00846268,\n",
       "        0.00843788, 0.00804235, 0.00767759, 0.00845472, 0.00854989,\n",
       "        0.00795114, 0.00787059, 0.00841859, 0.00860643, 0.0078333 ,\n",
       "        0.00795237, 0.00840945, 0.00846372, 0.00788197, 0.00789184,\n",
       "        0.00840354, 0.00862064, 0.00783572, 0.00794841, 0.00998686,\n",
       "        0.00931196, 0.00929579, 0.00900436, 0.00835745, 0.00853949,\n",
       "        0.00781196, 0.00771753, 0.00831903, 0.00847339, 0.00796849,\n",
       "        0.00772534, 0.00833175, 0.0085631 , 0.00779001, 0.00767975,\n",
       "        0.00824982, 0.00862373, 0.00786854, 0.00787324, 0.00854332,\n",
       "        0.00850824, 0.0079531 , 0.00797404, 0.00853398, 0.00862528,\n",
       "        0.00786433, 0.00792426, 0.01005284, 0.00940857, 0.00941903,\n",
       "        0.0091851 , 0.00843626, 0.00843389, 0.00798108, 0.00790966,\n",
       "        0.00846327, 0.00844535, 0.007946  , 0.00802174, 0.00838771,\n",
       "        0.00853541, 0.00804512, 0.00778443, 0.00838999, 0.00846216,\n",
       "        0.00787433, 0.00796953, 0.00832188, 0.00829777, 0.00781628,\n",
       "        0.00804727, 0.00858756, 0.00855173, 0.00792529, 0.0078138 ,\n",
       "        0.00993489, 0.00949256, 0.00950835, 0.0095254 , 0.00851184,\n",
       "        0.00831412, 0.00797193, 0.0079175 , 0.00844659, 0.0084466 ,\n",
       "        0.00782332, 0.00783781, 0.00837864, 0.00856689, 0.00805717,\n",
       "        0.00794449, 0.00843128, 0.00838863, 0.00782822, 0.00795552,\n",
       "        0.00840943, 0.00859958, 0.00811096, 0.00773896, 0.00849723,\n",
       "        0.00860395, 0.00822943, 0.00813846, 0.00993615, 0.0098777 ,\n",
       "        0.00973307, 0.00974445, 0.00846382, 0.00853164, 0.00792062,\n",
       "        0.00797425, 0.00843864, 0.00846476, 0.00796147, 0.00801993,\n",
       "        0.00834437, 0.00851151, 0.0078508 , 0.00801966, 0.00835623,\n",
       "        0.00851445, 0.00808971, 0.00805678, 0.00850473, 0.00848322,\n",
       "        0.00829551, 0.00811093, 0.0085063 , 0.00851625, 0.00803767,\n",
       "        0.00776923, 0.01051804, 0.00998441, 0.0098541 , 0.01003783,\n",
       "        0.00842128, 0.00861453, 0.00769572, 0.00747436, 0.00828238,\n",
       "        0.0085849 , 0.00776227, 0.00750764, 0.00840721, 0.00863688,\n",
       "        0.00788896, 0.0077372 , 0.00821594, 0.00868414, 0.00790991,\n",
       "        0.00762913, 0.00815184, 0.00850332, 0.00827336, 0.00758202,\n",
       "        0.00815906, 0.00871532, 0.00801886, 0.00783036, 0.00940665,\n",
       "        0.00926994, 0.00931723, 0.00877979, 0.00827581, 0.00857763,\n",
       "        0.0079209 , 0.00773031, 0.00819831, 0.00863749, 0.00788673,\n",
       "        0.00769097, 0.00824831, 0.00874106, 0.00782815, 0.00758082,\n",
       "        0.00809937, 0.00862612, 0.00783326, 0.00771012, 0.0082512 ,\n",
       "        0.00868956, 0.0079846 , 0.00786489, 0.00828286, 0.00834482,\n",
       "        0.00801525, 0.00744729, 0.00929351, 0.00938134, 0.00912185,\n",
       "        0.00884963, 0.0084307 , 0.00866392, 0.0079708 , 0.00774781,\n",
       "        0.00828689, 0.00866125, 0.00791319, 0.00779699, 0.0082239 ,\n",
       "        0.00865662, 0.0079945 , 0.00796842, 0.00833091, 0.00864905,\n",
       "        0.00783958, 0.0078803 , 0.00827419, 0.0085741 , 0.00773057,\n",
       "        0.0078208 , 0.00824888, 0.00860815, 0.00809347, 0.00754168,\n",
       "        0.00920618, 0.00937364, 0.00916059, 0.00917057, 0.00845076,\n",
       "        0.00841423, 0.00776288, 0.0076589 , 0.00820868, 0.00852152,\n",
       "        0.00779598, 0.00776846, 0.008183  , 0.00868577, 0.00771522,\n",
       "        0.00762887, 0.00830329, 0.00863203, 0.00784822, 0.00771789,\n",
       "        0.00813922, 0.00856649, 0.00808549, 0.00788928, 0.00821684,\n",
       "        0.00856928, 0.00816236, 0.00764387, 0.00965027, 0.00970387,\n",
       "        0.00942428, 0.00948978, 0.00830357, 0.00868492, 0.00788723,\n",
       "        0.0078724 , 0.00821243, 0.0087226 , 0.0077979 , 0.00764939,\n",
       "        0.00810349, 0.00863221, 0.00793184, 0.00790656, 0.00830306,\n",
       "        0.00855033, 0.00799252, 0.00786649, 0.00811509, 0.00849155,\n",
       "        0.0079861 , 0.00774175, 0.00849416, 0.00859792, 0.00837282,\n",
       "        0.0077636 , 0.00993861, 0.00995395, 0.0094811 , 0.00979365,\n",
       "        0.00777142, 0.00840551, 0.00799691, 0.00827479, 0.00766038,\n",
       "        0.00881034, 0.00808567, 0.00827383, 0.00794636, 0.00856445,\n",
       "        0.00806008, 0.008203  , 0.00762482, 0.00840374, 0.0081541 ,\n",
       "        0.00811735, 0.00778886, 0.00836783, 0.00811176, 0.00829057,\n",
       "        0.00794446, 0.00856382, 0.00822291, 0.00790656, 0.00899554,\n",
       "        0.00932062, 0.00898221, 0.00894784, 0.00800811, 0.0084311 ,\n",
       "        0.00812539, 0.00832235, 0.0079912 , 0.00848085, 0.00818796,\n",
       "        0.00799811, 0.0077973 , 0.00837797, 0.00811624, 0.00828706,\n",
       "        0.00776748, 0.00839465, 0.00798882, 0.00816019, 0.00788139,\n",
       "        0.00859796, 0.00828268, 0.00802385, 0.00801827, 0.00856866,\n",
       "        0.00830645, 0.00827602, 0.00903029, 0.00930037, 0.00906137,\n",
       "        0.00874774, 0.00771708, 0.00859855, 0.0080437 , 0.00817797,\n",
       "        0.00779506, 0.00855177, 0.00814934, 0.00803783, 0.00785236,\n",
       "        0.00858247, 0.0082518 , 0.00836568, 0.00755142, 0.00850441,\n",
       "        0.00809888, 0.00797859, 0.00781438, 0.00838167, 0.00804166,\n",
       "        0.00827278, 0.00795118, 0.00853016, 0.00831913, 0.00790052,\n",
       "        0.00915454, 0.00947537, 0.00913066, 0.00913331, 0.00768505,\n",
       "        0.00855418, 0.0079866 , 0.0083531 , 0.00767611, 0.00864531,\n",
       "        0.00800476, 0.00814429, 0.00765711, 0.00837225, 0.00819149,\n",
       "        0.00824298, 0.00774284, 0.00880837, 0.00801448, 0.00798764,\n",
       "        0.00786608, 0.0086272 , 0.00824822, 0.00824581, 0.00789622,\n",
       "        0.00879402, 0.00829663, 0.008129  , 0.00940843, 0.00947809,\n",
       "        0.00927014, 0.00933013, 0.00780359, 0.00872401, 0.00838638,\n",
       "        0.00833044, 0.00773321, 0.00861892, 0.00833726, 0.00831479,\n",
       "        0.00762577, 0.00866069, 0.00840452, 0.00823738, 0.00763091,\n",
       "        0.00862869, 0.00825167, 0.00784612, 0.00791605, 0.00873226,\n",
       "        0.00837341, 0.00839526, 0.00802028, 0.00888109, 0.0083068 ,\n",
       "        0.00801587, 0.00943342, 0.00969134, 0.00988989, 0.00993023,\n",
       "        0.00762577, 0.00847555, 0.00793248, 0.00785459, 0.00774311,\n",
       "        0.00842269, 0.00806136, 0.00787728, 0.00747602, 0.00830007,\n",
       "        0.00801491, 0.00818854, 0.00771048, 0.00848888, 0.00823744,\n",
       "        0.00802044, 0.00763107, 0.00843536, 0.00803916, 0.0081025 ,\n",
       "        0.00762452, 0.00847844, 0.00834363, 0.00815054, 0.00870634,\n",
       "        0.00910176, 0.00884839, 0.00917815, 0.0075786 , 0.00835757,\n",
       "        0.00795067, 0.00804308, 0.00754981, 0.00835729, 0.00795419,\n",
       "        0.00807088, 0.00769806, 0.00839667, 0.00800438, 0.008007  ,\n",
       "        0.00762612, 0.00851357, 0.00797178, 0.00794163, 0.00771081,\n",
       "        0.00831466, 0.00806698, 0.00806045, 0.00786516, 0.00849612,\n",
       "        0.00831506, 0.00814991, 0.00882773, 0.00918138, 0.00904536,\n",
       "        0.009454  , 0.00744252, 0.00839666, 0.00798571, 0.00806657,\n",
       "        0.00754739, 0.00840669, 0.0079736 , 0.00813599, 0.00756022,\n",
       "        0.00849952, 0.00807084, 0.00796033, 0.00767851, 0.00836667,\n",
       "        0.00792577, 0.008091  , 0.00771259, 0.00837819, 0.00812397,\n",
       "        0.0082181 , 0.00800742, 0.00824035, 0.00803837, 0.00819294,\n",
       "        0.00906007, 0.00928812, 0.00911696, 0.00953207, 0.00782289,\n",
       "        0.00835851, 0.00803867, 0.00821346, 0.00766435, 0.00834128,\n",
       "        0.008028  , 0.00844814, 0.00786065, 0.00820909, 0.00791587,\n",
       "        0.00804707, 0.00774187, 0.00849442, 0.00808538, 0.00815323,\n",
       "        0.00777644, 0.00856646, 0.0080298 , 0.00812667, 0.00789585,\n",
       "        0.0085055 , 0.00823709, 0.0080482 , 0.00922035, 0.00946604,\n",
       "        0.00927102, 0.01005846, 0.00779384, 0.0084755 , 0.00810233,\n",
       "        0.00813129, 0.00762636, 0.00848719, 0.00807115, 0.00805336,\n",
       "        0.0079444 , 0.00852513, 0.00805062, 0.0081207 , 0.00810153,\n",
       "        0.00857641, 0.00805896, 0.00798592, 0.00766096, 0.008532  ,\n",
       "        0.0080558 , 0.00807638, 0.00800657, 0.00844785, 0.0081505 ,\n",
       "        0.00784639, 0.00923661, 0.00955888, 0.00956011, 0.01021417]),\n",
       " 'split0_test_Accuracy': array([0.8013468 , 0.8047138 , 0.80808081, 0.8013468 , 0.8013468 ,\n",
       "        0.8047138 , 0.80808081, 0.8013468 , 0.8013468 , 0.8013468 ,\n",
       "        0.80808081, 0.8013468 , 0.7979798 , 0.8013468 , 0.80808081,\n",
       "        0.8013468 , 0.8013468 , 0.8013468 , 0.8047138 , 0.8047138 ,\n",
       "        0.7979798 , 0.8013468 , 0.80808081, 0.8013468 , 0.8047138 ,\n",
       "        0.80808081, 0.8013468 , 0.8047138 , 0.7979798 , 0.8047138 ,\n",
       "        0.8047138 , 0.8013468 , 0.7979798 , 0.8047138 , 0.80808081,\n",
       "        0.8013468 , 0.7979798 , 0.8047138 , 0.80808081, 0.8013468 ,\n",
       "        0.7979798 , 0.8047138 , 0.80808081, 0.8013468 , 0.7979798 ,\n",
       "        0.7979798 , 0.8047138 , 0.8013468 , 0.7979798 , 0.8013468 ,\n",
       "        0.8047138 , 0.8013468 , 0.8047138 , 0.8047138 , 0.8047138 ,\n",
       "        0.8047138 , 0.7979798 , 0.8047138 , 0.8047138 , 0.8013468 ,\n",
       "        0.7979798 , 0.8047138 , 0.8047138 , 0.8013468 , 0.8013468 ,\n",
       "        0.8047138 , 0.80808081, 0.8013468 , 0.7979798 , 0.8047138 ,\n",
       "        0.8047138 , 0.8013468 , 0.8013468 , 0.8047138 , 0.8013468 ,\n",
       "        0.8013468 , 0.7979798 , 0.8013468 , 0.8013468 , 0.8013468 ,\n",
       "        0.8047138 , 0.80808081, 0.7979798 , 0.8047138 , 0.8013468 ,\n",
       "        0.8013468 , 0.80808081, 0.8013468 , 0.8013468 , 0.8047138 ,\n",
       "        0.80808081, 0.8013468 , 0.7979798 , 0.8013468 , 0.8047138 ,\n",
       "        0.8013468 , 0.7979798 , 0.8047138 , 0.8047138 , 0.8013468 ,\n",
       "        0.7979798 , 0.8013468 , 0.80808081, 0.8013468 , 0.7979798 ,\n",
       "        0.8047138 , 0.8013468 , 0.8013468 , 0.80808081, 0.80808081,\n",
       "        0.8013468 , 0.8013468 , 0.8013468 , 0.8047138 , 0.8013468 ,\n",
       "        0.8013468 , 0.8013468 , 0.8047138 , 0.8013468 , 0.8013468 ,\n",
       "        0.8047138 , 0.8013468 , 0.8047138 , 0.8013468 , 0.8013468 ,\n",
       "        0.8047138 , 0.8013468 , 0.8013468 , 0.7979798 , 0.8013468 ,\n",
       "        0.8013468 , 0.8013468 , 0.8013468 , 0.8013468 , 0.8047138 ,\n",
       "        0.8013468 , 0.80808081, 0.81144781, 0.7979798 , 0.7979798 ,\n",
       "        0.8013468 , 0.7979798 , 0.7979798 , 0.8013468 , 0.8013468 ,\n",
       "        0.7979798 , 0.7979798 , 0.8013468 , 0.8047138 , 0.79461279,\n",
       "        0.7979798 , 0.8013468 , 0.8013468 , 0.8013468 , 0.7979798 ,\n",
       "        0.8013468 , 0.8047138 , 0.79461279, 0.79461279, 0.8013468 ,\n",
       "        0.8013468 , 0.79461279, 0.7979798 , 0.8013468 , 0.8047138 ,\n",
       "        0.8013468 , 0.8047138 , 0.7979798 , 0.8013468 , 0.79461279,\n",
       "        0.7979798 , 0.8013468 , 0.8047138 , 0.79461279, 0.79124579,\n",
       "        0.8013468 , 0.8047138 , 0.79461279, 0.7979798 , 0.8013468 ,\n",
       "        0.8047138 , 0.7979798 , 0.8013468 , 0.8013468 , 0.8047138 ,\n",
       "        0.79461279, 0.8013468 , 0.8013468 , 0.8047138 , 0.79461279,\n",
       "        0.8013468 , 0.8013468 , 0.8047138 , 0.8047138 , 0.8047138 ,\n",
       "        0.8013468 , 0.8047138 , 0.79461279, 0.79124579, 0.8013468 ,\n",
       "        0.8047138 , 0.79461279, 0.79461279, 0.8013468 , 0.80808081,\n",
       "        0.79461279, 0.8013468 , 0.8013468 , 0.8013468 , 0.7979798 ,\n",
       "        0.79461279, 0.8013468 , 0.8013468 , 0.7979798 , 0.7979798 ,\n",
       "        0.8013468 , 0.8013468 , 0.7979798 , 0.7979798 , 0.8013468 ,\n",
       "        0.8047138 , 0.8047138 , 0.8047138 , 0.7979798 , 0.8013468 ,\n",
       "        0.7979798 , 0.79124579, 0.8013468 , 0.7979798 , 0.8013468 ,\n",
       "        0.79124579, 0.8013468 , 0.8047138 , 0.79461279, 0.79461279,\n",
       "        0.8013468 , 0.8013468 , 0.79461279, 0.79124579, 0.8013468 ,\n",
       "        0.8013468 , 0.79461279, 0.7979798 , 0.8013468 , 0.8013468 ,\n",
       "        0.79461279, 0.8013468 , 0.8013468 , 0.8047138 , 0.8047138 ,\n",
       "        0.8047138 , 0.7979798 , 0.8047138 , 0.8013468 , 0.7979798 ,\n",
       "        0.8013468 , 0.8047138 , 0.8013468 , 0.79461279, 0.8013468 ,\n",
       "        0.8013468 , 0.7979798 , 0.79124579, 0.8013468 , 0.8013468 ,\n",
       "        0.79461279, 0.79461279, 0.8013468 , 0.8013468 , 0.7979798 ,\n",
       "        0.79461279, 0.7979798 , 0.8013468 , 0.79461279, 0.7979798 ,\n",
       "        0.8013468 , 0.8047138 , 0.8047138 , 0.8013468 , 0.7979798 ,\n",
       "        0.79461279, 0.7979798 , 0.80808081, 0.8047138 , 0.79461279,\n",
       "        0.7979798 , 0.80808081, 0.8013468 , 0.79461279, 0.8013468 ,\n",
       "        0.81144781, 0.8047138 , 0.7979798 , 0.8013468 , 0.80808081,\n",
       "        0.8047138 , 0.79461279, 0.7979798 , 0.8047138 , 0.8047138 ,\n",
       "        0.7979798 , 0.7979798 , 0.8047138 , 0.8047138 , 0.8013468 ,\n",
       "        0.7979798 , 0.8047138 , 0.8013468 , 0.79461279, 0.7979798 ,\n",
       "        0.8047138 , 0.8047138 , 0.79461279, 0.7979798 , 0.8047138 ,\n",
       "        0.8047138 , 0.7979798 , 0.7979798 , 0.81144781, 0.8047138 ,\n",
       "        0.79461279, 0.8013468 , 0.8047138 , 0.8047138 , 0.7979798 ,\n",
       "        0.8013468 , 0.80808081, 0.8047138 , 0.7979798 , 0.7979798 ,\n",
       "        0.80808081, 0.8047138 , 0.8013468 , 0.8013468 , 0.8047138 ,\n",
       "        0.8013468 , 0.79461279, 0.7979798 , 0.8047138 , 0.8047138 ,\n",
       "        0.79461279, 0.8013468 , 0.80808081, 0.8047138 , 0.79461279,\n",
       "        0.8013468 , 0.80808081, 0.8047138 , 0.79461279, 0.8013468 ,\n",
       "        0.80808081, 0.8047138 , 0.7979798 , 0.7979798 , 0.8047138 ,\n",
       "        0.8047138 , 0.8013468 , 0.79461279, 0.8047138 , 0.8013468 ,\n",
       "        0.8047138 , 0.7979798 , 0.8047138 , 0.8013468 , 0.8013468 ,\n",
       "        0.8013468 , 0.81144781, 0.8047138 , 0.79461279, 0.8013468 ,\n",
       "        0.8047138 , 0.8047138 , 0.7979798 , 0.8047138 , 0.8047138 ,\n",
       "        0.8047138 , 0.79461279, 0.8047138 , 0.80808081, 0.8047138 ,\n",
       "        0.7979798 , 0.7979798 , 0.80808081, 0.8013468 , 0.8013468 ,\n",
       "        0.7979798 , 0.8047138 , 0.8047138 , 0.80808081, 0.8013468 ,\n",
       "        0.8047138 , 0.8013468 , 0.7979798 , 0.7979798 , 0.8047138 ,\n",
       "        0.8047138 , 0.7979798 , 0.7979798 , 0.8047138 , 0.80808081,\n",
       "        0.7979798 , 0.7979798 , 0.8047138 , 0.8047138 , 0.79461279,\n",
       "        0.8013468 , 0.81144781, 0.8013468 , 0.7979798 , 0.7979798 ,\n",
       "        0.80808081, 0.8013468 , 0.7979798 , 0.7979798 , 0.8047138 ,\n",
       "        0.80808081, 0.80808081, 0.8013468 , 0.8013468 , 0.7979798 ,\n",
       "        0.7979798 , 0.7979798 , 0.80808081, 0.80808081, 0.7979798 ,\n",
       "        0.8047138 , 0.80808081, 0.80808081, 0.79461279, 0.8013468 ,\n",
       "        0.8047138 , 0.8047138 , 0.7979798 , 0.7979798 , 0.80808081,\n",
       "        0.7979798 , 0.7979798 , 0.7979798 , 0.80808081, 0.8013468 ,\n",
       "        0.7979798 , 0.7979798 , 0.8013468 , 0.8047138 , 0.8047138 ,\n",
       "        0.7979798 , 0.8047138 , 0.7979798 , 0.79461279, 0.8013468 ,\n",
       "        0.80808081, 0.80808081, 0.79461279, 0.8013468 , 0.8047138 ,\n",
       "        0.8013468 , 0.8013468 , 0.7979798 , 0.8047138 , 0.8047138 ,\n",
       "        0.79461279, 0.79461279, 0.8047138 , 0.7979798 , 0.7979798 ,\n",
       "        0.8013468 , 0.8013468 , 0.8013468 , 0.7979798 , 0.7979798 ,\n",
       "        0.8013468 , 0.80808081, 0.8047138 , 0.8013468 , 0.8047138 ,\n",
       "        0.8013468 , 0.8013468 , 0.8013468 , 0.8047138 , 0.8013468 ,\n",
       "        0.7979798 , 0.8013468 , 0.80808081, 0.8013468 , 0.79461279,\n",
       "        0.8013468 , 0.8047138 , 0.7979798 , 0.79461279, 0.8047138 ,\n",
       "        0.8047138 , 0.8013468 , 0.79461279, 0.8013468 , 0.8047138 ,\n",
       "        0.7979798 , 0.79461279, 0.7979798 , 0.7979798 , 0.8047138 ,\n",
       "        0.80808081, 0.8013468 , 0.8047138 , 0.8013468 , 0.79461279,\n",
       "        0.7979798 , 0.8047138 , 0.8013468 , 0.79461279, 0.79461279,\n",
       "        0.8047138 , 0.8013468 , 0.8013468 , 0.7979798 , 0.8047138 ,\n",
       "        0.8047138 , 0.79461279, 0.8013468 , 0.8013468 , 0.7979798 ,\n",
       "        0.79461279, 0.79461279, 0.7979798 , 0.8047138 , 0.79461279,\n",
       "        0.8013468 , 0.8013468 , 0.80808081, 0.80808081, 0.8013468 ,\n",
       "        0.8047138 , 0.8013468 , 0.7979798 , 0.7979798 , 0.8047138 ,\n",
       "        0.7979798 , 0.79461279, 0.7979798 , 0.8047138 , 0.8047138 ,\n",
       "        0.7979798 , 0.79461279, 0.8047138 , 0.8013468 , 0.79461279,\n",
       "        0.8013468 , 0.8047138 , 0.8013468 , 0.7979798 , 0.8013468 ,\n",
       "        0.8013468 , 0.8013468 , 0.79461279, 0.7979798 , 0.7979798 ,\n",
       "        0.8013468 , 0.80808081, 0.8013468 , 0.8047138 , 0.8013468 ]),\n",
       " 'split1_test_Accuracy': array([0.83501684, 0.85185185, 0.83501684, 0.83164983, 0.83501684,\n",
       "        0.84511785, 0.83501684, 0.83501684, 0.83838384, 0.84175084,\n",
       "        0.83501684, 0.83838384, 0.83164983, 0.84848485, 0.83501684,\n",
       "        0.83501684, 0.82491582, 0.83838384, 0.83501684, 0.83501684,\n",
       "        0.82828283, 0.84175084, 0.83838384, 0.83838384, 0.82491582,\n",
       "        0.82154882, 0.82491582, 0.83164983, 0.83838384, 0.85185185,\n",
       "        0.83501684, 0.83501684, 0.83501684, 0.85185185, 0.83501684,\n",
       "        0.83501684, 0.83164983, 0.84848485, 0.83501684, 0.83838384,\n",
       "        0.83164983, 0.84175084, 0.83501684, 0.83838384, 0.82828283,\n",
       "        0.83838384, 0.83838384, 0.83838384, 0.82828283, 0.84175084,\n",
       "        0.83838384, 0.83838384, 0.82491582, 0.82491582, 0.82154882,\n",
       "        0.82491582, 0.83501684, 0.84848485, 0.83501684, 0.83838384,\n",
       "        0.83501684, 0.84848485, 0.83501684, 0.84175084, 0.83838384,\n",
       "        0.84511785, 0.84175084, 0.84175084, 0.83838384, 0.84848485,\n",
       "        0.83501684, 0.83838384, 0.82828283, 0.85185185, 0.83838384,\n",
       "        0.83838384, 0.82828283, 0.84511785, 0.83501684, 0.84175084,\n",
       "        0.82491582, 0.82154882, 0.82491582, 0.83164983, 0.83838384,\n",
       "        0.84175084, 0.83838384, 0.83838384, 0.83838384, 0.84175084,\n",
       "        0.83838384, 0.83838384, 0.83501684, 0.84848485, 0.83838384,\n",
       "        0.83838384, 0.83838384, 0.84175084, 0.83838384, 0.83501684,\n",
       "        0.82828283, 0.84175084, 0.83501684, 0.83838384, 0.82828283,\n",
       "        0.84511785, 0.83501684, 0.83838384, 0.82491582, 0.82154882,\n",
       "        0.82154882, 0.82491582, 0.83501684, 0.84511785, 0.83838384,\n",
       "        0.83501684, 0.83501684, 0.84175084, 0.83838384, 0.83838384,\n",
       "        0.83164983, 0.84511785, 0.83838384, 0.83164983, 0.83501684,\n",
       "        0.84175084, 0.84175084, 0.83501684, 0.83164983, 0.84175084,\n",
       "        0.83838384, 0.83501684, 0.83164983, 0.83838384, 0.83164983,\n",
       "        0.83164983, 0.82154882, 0.82491582, 0.82491582, 0.83164983,\n",
       "        0.83501684, 0.84175084, 0.83838384, 0.84175084, 0.83501684,\n",
       "        0.84175084, 0.84511785, 0.84511785, 0.83164983, 0.84511785,\n",
       "        0.84175084, 0.84175084, 0.82828283, 0.84175084, 0.84511785,\n",
       "        0.84175084, 0.82828283, 0.84848485, 0.83838384, 0.83838384,\n",
       "        0.82828283, 0.84511785, 0.84175084, 0.84175084, 0.82154882,\n",
       "        0.82828283, 0.82491582, 0.83164983, 0.83164983, 0.84848485,\n",
       "        0.84175084, 0.83501684, 0.82828283, 0.84175084, 0.84175084,\n",
       "        0.83838384, 0.83164983, 0.84511785, 0.84511785, 0.83164983,\n",
       "        0.83164983, 0.84175084, 0.83838384, 0.84175084, 0.82828283,\n",
       "        0.84848485, 0.83838384, 0.83838384, 0.83164983, 0.85185185,\n",
       "        0.84175084, 0.83838384, 0.82154882, 0.82828283, 0.83164983,\n",
       "        0.82828283, 0.83501684, 0.84175084, 0.84175084, 0.84511785,\n",
       "        0.83501684, 0.84175084, 0.84175084, 0.84511785, 0.83501684,\n",
       "        0.84175084, 0.84511785, 0.84511785, 0.82491582, 0.84511785,\n",
       "        0.84175084, 0.84511785, 0.82828283, 0.84175084, 0.83838384,\n",
       "        0.84175084, 0.84175084, 0.84511785, 0.83838384, 0.83838384,\n",
       "        0.82491582, 0.82828283, 0.82828283, 0.82828283, 0.83838384,\n",
       "        0.84511785, 0.84511785, 0.84175084, 0.82828283, 0.84511785,\n",
       "        0.84511785, 0.84175084, 0.83164983, 0.84511785, 0.84848485,\n",
       "        0.84511785, 0.83164983, 0.84848485, 0.84511785, 0.84175084,\n",
       "        0.82828283, 0.84511785, 0.83838384, 0.84175084, 0.83501684,\n",
       "        0.84848485, 0.84175084, 0.83501684, 0.82491582, 0.82491582,\n",
       "        0.82828283, 0.82154882, 0.83501684, 0.84511785, 0.84848485,\n",
       "        0.83838384, 0.83501684, 0.84848485, 0.84848485, 0.84175084,\n",
       "        0.83164983, 0.84511785, 0.84175084, 0.83838384, 0.83164983,\n",
       "        0.84848485, 0.83838384, 0.84175084, 0.82828283, 0.84511785,\n",
       "        0.83838384, 0.84175084, 0.82154882, 0.84511785, 0.83838384,\n",
       "        0.84175084, 0.82491582, 0.82491582, 0.82491582, 0.82828283,\n",
       "        0.84511785, 0.85185185, 0.84848485, 0.83838384, 0.84511785,\n",
       "        0.85185185, 0.85185185, 0.83501684, 0.84511785, 0.84848485,\n",
       "        0.84511785, 0.83838384, 0.84175084, 0.84848485, 0.84848485,\n",
       "        0.83838384, 0.84511785, 0.84848485, 0.84511785, 0.83838384,\n",
       "        0.84848485, 0.84848485, 0.84175084, 0.83501684, 0.82491582,\n",
       "        0.83501684, 0.83501684, 0.82828283, 0.84848485, 0.84848485,\n",
       "        0.84511785, 0.83501684, 0.84848485, 0.84848485, 0.84511785,\n",
       "        0.83501684, 0.84848485, 0.84848485, 0.84511785, 0.83838384,\n",
       "        0.84848485, 0.85185185, 0.84511785, 0.83501684, 0.84175084,\n",
       "        0.85185185, 0.85185185, 0.83501684, 0.84511785, 0.85185185,\n",
       "        0.84511785, 0.83501684, 0.82491582, 0.83501684, 0.83164983,\n",
       "        0.82491582, 0.84511785, 0.85185185, 0.84511785, 0.83838384,\n",
       "        0.84511785, 0.84848485, 0.85185185, 0.83838384, 0.84511785,\n",
       "        0.85185185, 0.85521886, 0.83838384, 0.84175084, 0.84511785,\n",
       "        0.85185185, 0.83501684, 0.84848485, 0.85521886, 0.84848485,\n",
       "        0.83838384, 0.83838384, 0.84848485, 0.84175084, 0.83501684,\n",
       "        0.82828283, 0.83838384, 0.83501684, 0.83164983, 0.84511785,\n",
       "        0.85185185, 0.85185185, 0.83838384, 0.84511785, 0.85185185,\n",
       "        0.85185185, 0.83838384, 0.84511785, 0.84848485, 0.84848485,\n",
       "        0.83838384, 0.84511785, 0.84175084, 0.85185185, 0.83838384,\n",
       "        0.84175084, 0.84175084, 0.85185185, 0.83838384, 0.84175084,\n",
       "        0.85521886, 0.84848485, 0.83838384, 0.82491582, 0.83164983,\n",
       "        0.82828283, 0.82491582, 0.83838384, 0.84848485, 0.85521886,\n",
       "        0.83838384, 0.83501684, 0.85185185, 0.84848485, 0.83838384,\n",
       "        0.84175084, 0.84511785, 0.85185185, 0.83838384, 0.84175084,\n",
       "        0.85185185, 0.84511785, 0.83838384, 0.84175084, 0.84848485,\n",
       "        0.85521886, 0.83501684, 0.84511785, 0.84175084, 0.84511785,\n",
       "        0.83838384, 0.82491582, 0.83164983, 0.82828283, 0.82491582,\n",
       "        0.84511785, 0.84511785, 0.84175084, 0.83164983, 0.84848485,\n",
       "        0.84511785, 0.84175084, 0.83501684, 0.84175084, 0.84511785,\n",
       "        0.84175084, 0.83501684, 0.84511785, 0.84848485, 0.83838384,\n",
       "        0.83164983, 0.84848485, 0.84175084, 0.84511785, 0.83164983,\n",
       "        0.84848485, 0.84848485, 0.83838384, 0.83501684, 0.82828283,\n",
       "        0.83838384, 0.83164983, 0.82828283, 0.84848485, 0.84848485,\n",
       "        0.84511785, 0.83164983, 0.85185185, 0.84511785, 0.84511785,\n",
       "        0.83164983, 0.84175084, 0.84848485, 0.83838384, 0.83164983,\n",
       "        0.84511785, 0.84511785, 0.84175084, 0.83164983, 0.85185185,\n",
       "        0.84511785, 0.83838384, 0.83501684, 0.84511785, 0.84175084,\n",
       "        0.83501684, 0.83501684, 0.82828283, 0.83838384, 0.83501684,\n",
       "        0.82491582, 0.84511785, 0.83838384, 0.84175084, 0.82828283,\n",
       "        0.84511785, 0.84511785, 0.84175084, 0.83501684, 0.85185185,\n",
       "        0.84511785, 0.83838384, 0.83838384, 0.84848485, 0.84511785,\n",
       "        0.83838384, 0.83501684, 0.84511785, 0.84511785, 0.83838384,\n",
       "        0.83164983, 0.85185185, 0.84511785, 0.83838384, 0.84175084,\n",
       "        0.82828283, 0.84175084, 0.83501684, 0.83501684, 0.84848485,\n",
       "        0.83838384, 0.84175084, 0.83164983, 0.84848485, 0.84511785,\n",
       "        0.84175084, 0.83164983, 0.84848485, 0.84848485, 0.84175084,\n",
       "        0.83501684, 0.84848485, 0.84175084, 0.84175084, 0.84175084,\n",
       "        0.84848485, 0.84511785, 0.84511785, 0.84175084, 0.84175084,\n",
       "        0.84511785, 0.84511785, 0.83838384, 0.82491582, 0.83838384,\n",
       "        0.82491582, 0.82491582, 0.84511785, 0.84848485, 0.84511785,\n",
       "        0.83501684, 0.84848485, 0.84848485, 0.84511785, 0.83838384,\n",
       "        0.84511785, 0.84511785, 0.83838384, 0.83838384, 0.84175084,\n",
       "        0.84511785, 0.83838384, 0.83164983, 0.84175084, 0.84848485,\n",
       "        0.84175084, 0.83501684, 0.84511785, 0.84511785, 0.84175084,\n",
       "        0.83501684, 0.82491582, 0.83501684, 0.82154882, 0.82828283]),\n",
       " 'split2_test_Accuracy': array([0.82491582, 0.82828283, 0.83838384, 0.84175084, 0.82154882,\n",
       "        0.82828283, 0.83838384, 0.84511785, 0.82491582, 0.82491582,\n",
       "        0.83838384, 0.84175084, 0.82491582, 0.82828283, 0.83838384,\n",
       "        0.84175084, 0.82154882, 0.82491582, 0.84175084, 0.85185185,\n",
       "        0.82491582, 0.82491582, 0.83838384, 0.84511785, 0.83164983,\n",
       "        0.83164983, 0.84175084, 0.84175084, 0.82154882, 0.82491582,\n",
       "        0.83838384, 0.84175084, 0.82154882, 0.83164983, 0.83838384,\n",
       "        0.84175084, 0.82491582, 0.82491582, 0.83838384, 0.83838384,\n",
       "        0.82491582, 0.82491582, 0.83838384, 0.84175084, 0.82491582,\n",
       "        0.82491582, 0.83838384, 0.84848485, 0.82491582, 0.82828283,\n",
       "        0.84175084, 0.84848485, 0.82828283, 0.83501684, 0.83838384,\n",
       "        0.84511785, 0.82154882, 0.82828283, 0.83838384, 0.84175084,\n",
       "        0.82154882, 0.82828283, 0.83838384, 0.84175084, 0.82154882,\n",
       "        0.82491582, 0.83838384, 0.84175084, 0.82491582, 0.82491582,\n",
       "        0.84175084, 0.84175084, 0.82491582, 0.82491582, 0.83838384,\n",
       "        0.84848485, 0.82491582, 0.82828283, 0.83838384, 0.84848485,\n",
       "        0.82491582, 0.83164983, 0.83838384, 0.84175084, 0.82154882,\n",
       "        0.83164983, 0.83838384, 0.84175084, 0.82491582, 0.82828283,\n",
       "        0.84175084, 0.84511785, 0.82491582, 0.83164983, 0.84175084,\n",
       "        0.84848485, 0.82491582, 0.82828283, 0.84175084, 0.84175084,\n",
       "        0.82491582, 0.83164983, 0.83838384, 0.84848485, 0.82491582,\n",
       "        0.82828283, 0.83838384, 0.84848485, 0.82154882, 0.83164983,\n",
       "        0.83838384, 0.84511785, 0.82491582, 0.82828283, 0.84175084,\n",
       "        0.84175084, 0.82491582, 0.82828283, 0.84175084, 0.84175084,\n",
       "        0.82491582, 0.82828283, 0.84175084, 0.84511785, 0.82491582,\n",
       "        0.82828283, 0.83838384, 0.83838384, 0.82491582, 0.82828283,\n",
       "        0.84175084, 0.84848485, 0.82491582, 0.82828283, 0.84175084,\n",
       "        0.84848485, 0.82491582, 0.83501684, 0.83838384, 0.84511785,\n",
       "        0.82828283, 0.83164983, 0.83501684, 0.84511785, 0.82491582,\n",
       "        0.83164983, 0.83501684, 0.84511785, 0.82828283, 0.83838384,\n",
       "        0.83501684, 0.84175084, 0.82491582, 0.83164983, 0.83501684,\n",
       "        0.83838384, 0.82491582, 0.83164983, 0.83838384, 0.84511785,\n",
       "        0.82491582, 0.83501684, 0.83838384, 0.84175084, 0.82154882,\n",
       "        0.83501684, 0.83501684, 0.84175084, 0.82491582, 0.83501684,\n",
       "        0.83838384, 0.84175084, 0.82491582, 0.83501684, 0.83838384,\n",
       "        0.84175084, 0.82828283, 0.83164983, 0.83501684, 0.84175084,\n",
       "        0.82828283, 0.83501684, 0.83838384, 0.83838384, 0.82491582,\n",
       "        0.83164983, 0.84175084, 0.84511785, 0.82491582, 0.83501684,\n",
       "        0.83838384, 0.84175084, 0.82491582, 0.83164983, 0.83501684,\n",
       "        0.84175084, 0.82491582, 0.83501684, 0.83838384, 0.83838384,\n",
       "        0.82491582, 0.83501684, 0.83501684, 0.83838384, 0.82491582,\n",
       "        0.83838384, 0.83838384, 0.84175084, 0.82491582, 0.83501684,\n",
       "        0.83501684, 0.83838384, 0.82491582, 0.83501684, 0.84175084,\n",
       "        0.84175084, 0.82491582, 0.83838384, 0.83838384, 0.84511785,\n",
       "        0.82154882, 0.83501684, 0.83501684, 0.84175084, 0.82491582,\n",
       "        0.83501684, 0.83838384, 0.84511785, 0.82828283, 0.83501684,\n",
       "        0.83501684, 0.84511785, 0.82491582, 0.83838384, 0.84175084,\n",
       "        0.84175084, 0.82491582, 0.83838384, 0.83501684, 0.84511785,\n",
       "        0.81818182, 0.83838384, 0.83838384, 0.84175084, 0.82491582,\n",
       "        0.83501684, 0.83838384, 0.84175084, 0.82154882, 0.83501684,\n",
       "        0.83501684, 0.84175084, 0.82491582, 0.83501684, 0.83838384,\n",
       "        0.84175084, 0.82828283, 0.83838384, 0.84175084, 0.84175084,\n",
       "        0.82828283, 0.83501684, 0.83838384, 0.84511785, 0.82828283,\n",
       "        0.83501684, 0.83838384, 0.84175084, 0.82491582, 0.83164983,\n",
       "        0.83838384, 0.84511785, 0.82491582, 0.83501684, 0.84175084,\n",
       "        0.84511785, 0.82491582, 0.83501684, 0.83501684, 0.83838384,\n",
       "        0.82828283, 0.83501684, 0.83838384, 0.84175084, 0.83164983,\n",
       "        0.83164983, 0.84175084, 0.84175084, 0.83164983, 0.83838384,\n",
       "        0.84175084, 0.84175084, 0.83164983, 0.83501684, 0.83838384,\n",
       "        0.84175084, 0.82491582, 0.83501684, 0.83838384, 0.84511785,\n",
       "        0.83164983, 0.83838384, 0.84175084, 0.83838384, 0.82828283,\n",
       "        0.83164983, 0.83501684, 0.83501684, 0.82828283, 0.83501684,\n",
       "        0.83838384, 0.84175084, 0.83164983, 0.83164983, 0.83838384,\n",
       "        0.84175084, 0.83501684, 0.83501684, 0.83838384, 0.84175084,\n",
       "        0.83164983, 0.83838384, 0.84175084, 0.84175084, 0.83164983,\n",
       "        0.83501684, 0.83838384, 0.84175084, 0.83164983, 0.83838384,\n",
       "        0.84175084, 0.84175084, 0.82828283, 0.82828283, 0.83501684,\n",
       "        0.83838384, 0.83501684, 0.83501684, 0.83838384, 0.84175084,\n",
       "        0.83164983, 0.83501684, 0.83838384, 0.84175084, 0.82828283,\n",
       "        0.83838384, 0.84175084, 0.84175084, 0.82828283, 0.83501684,\n",
       "        0.83838384, 0.83838384, 0.82828283, 0.83838384, 0.84175084,\n",
       "        0.83838384, 0.83164983, 0.83501684, 0.84175084, 0.84511785,\n",
       "        0.82828283, 0.82828283, 0.83501684, 0.83501684, 0.83164983,\n",
       "        0.83501684, 0.84175084, 0.84175084, 0.82828283, 0.83501684,\n",
       "        0.84175084, 0.84175084, 0.82828283, 0.83838384, 0.84175084,\n",
       "        0.84175084, 0.83164983, 0.83501684, 0.84175084, 0.83838384,\n",
       "        0.82828283, 0.83501684, 0.84175084, 0.84175084, 0.82828283,\n",
       "        0.83501684, 0.84175084, 0.84175084, 0.82491582, 0.83164983,\n",
       "        0.83501684, 0.83838384, 0.83164983, 0.83164983, 0.84175084,\n",
       "        0.83838384, 0.83164983, 0.83501684, 0.84175084, 0.83838384,\n",
       "        0.83164983, 0.83501684, 0.84175084, 0.83838384, 0.82828283,\n",
       "        0.83501684, 0.84175084, 0.84175084, 0.83164983, 0.83164983,\n",
       "        0.83838384, 0.84175084, 0.82828283, 0.83164983, 0.83838384,\n",
       "        0.83838384, 0.82491582, 0.83164983, 0.83501684, 0.83838384,\n",
       "        0.82828283, 0.83501684, 0.83501684, 0.84175084, 0.82828283,\n",
       "        0.83501684, 0.83838384, 0.84511785, 0.82828283, 0.83501684,\n",
       "        0.84175084, 0.84511785, 0.82828283, 0.83501684, 0.83838384,\n",
       "        0.84511785, 0.82828283, 0.83838384, 0.84175084, 0.84848485,\n",
       "        0.83164983, 0.83838384, 0.83838384, 0.84511785, 0.82828283,\n",
       "        0.82491582, 0.83501684, 0.83838384, 0.82828283, 0.83838384,\n",
       "        0.83838384, 0.84848485, 0.82828283, 0.83501684, 0.83501684,\n",
       "        0.84511785, 0.82828283, 0.83838384, 0.84175084, 0.84848485,\n",
       "        0.82828283, 0.83838384, 0.83838384, 0.84511785, 0.83164983,\n",
       "        0.83838384, 0.83838384, 0.84848485, 0.83164983, 0.83838384,\n",
       "        0.84175084, 0.84511785, 0.82491582, 0.82491582, 0.83501684,\n",
       "        0.83501684, 0.82828283, 0.83838384, 0.83838384, 0.84848485,\n",
       "        0.82828283, 0.83838384, 0.83838384, 0.84848485, 0.83164983,\n",
       "        0.83838384, 0.83838384, 0.84848485, 0.82828283, 0.83164983,\n",
       "        0.83838384, 0.84848485, 0.82828283, 0.83501684, 0.84175084,\n",
       "        0.84511785, 0.82154882, 0.83838384, 0.83501684, 0.84848485,\n",
       "        0.82491582, 0.82491582, 0.83501684, 0.83838384, 0.82491582,\n",
       "        0.83838384, 0.83501684, 0.84848485, 0.82828283, 0.83838384,\n",
       "        0.83501684, 0.84175084, 0.82828283, 0.83838384, 0.83838384,\n",
       "        0.84175084, 0.82828283, 0.83838384, 0.83501684, 0.84175084,\n",
       "        0.82828283, 0.83838384, 0.83838384, 0.84848485, 0.83164983,\n",
       "        0.83838384, 0.83501684, 0.84848485, 0.82491582, 0.82828283,\n",
       "        0.83501684, 0.83501684, 0.82828283, 0.83501684, 0.83838384,\n",
       "        0.84511785, 0.82828283, 0.83838384, 0.83501684, 0.84175084,\n",
       "        0.82491582, 0.83838384, 0.83838384, 0.84848485, 0.82491582,\n",
       "        0.83838384, 0.83838384, 0.84511785, 0.82828283, 0.83838384,\n",
       "        0.83501684, 0.84848485, 0.83164983, 0.83838384, 0.83838384,\n",
       "        0.84511785, 0.82491582, 0.82828283, 0.83838384, 0.83838384]),\n",
       " 'mean_test_Accuracy': array([0.82042649, 0.82828283, 0.82716049, 0.82491582, 0.81930415,\n",
       "        0.82603816, 0.82716049, 0.82716049, 0.82154882, 0.82267116,\n",
       "        0.82716049, 0.82716049, 0.81818182, 0.82603816, 0.82716049,\n",
       "        0.82603816, 0.81593715, 0.82154882, 0.82716049, 0.8305275 ,\n",
       "        0.81705948, 0.82267116, 0.82828283, 0.82828283, 0.82042649,\n",
       "        0.82042649, 0.82267116, 0.82603816, 0.81930415, 0.82716049,\n",
       "        0.82603816, 0.82603816, 0.81818182, 0.82940516, 0.82716049,\n",
       "        0.82603816, 0.81818182, 0.82603816, 0.82716049, 0.82603816,\n",
       "        0.81818182, 0.82379349, 0.82716049, 0.82716049, 0.81705948,\n",
       "        0.82042649, 0.82716049, 0.82940516, 0.81705948, 0.82379349,\n",
       "        0.82828283, 0.82940516, 0.81930415, 0.82154882, 0.82154882,\n",
       "        0.82491582, 0.81818182, 0.82716049, 0.82603816, 0.82716049,\n",
       "        0.81818182, 0.82716049, 0.82603816, 0.82828283, 0.82042649,\n",
       "        0.82491582, 0.82940516, 0.82828283, 0.82042649, 0.82603816,\n",
       "        0.82716049, 0.82716049, 0.81818182, 0.82716049, 0.82603816,\n",
       "        0.82940516, 0.81705948, 0.82491582, 0.82491582, 0.8305275 ,\n",
       "        0.81818182, 0.82042649, 0.82042649, 0.82603816, 0.82042649,\n",
       "        0.82491582, 0.82828283, 0.82716049, 0.82154882, 0.82491582,\n",
       "        0.82940516, 0.82828283, 0.81930415, 0.82716049, 0.82828283,\n",
       "        0.82940516, 0.82042649, 0.82491582, 0.82828283, 0.82603816,\n",
       "        0.81705948, 0.82491582, 0.82716049, 0.82940516, 0.81705948,\n",
       "        0.82603816, 0.82491582, 0.82940516, 0.81818182, 0.82042649,\n",
       "        0.82042649, 0.82379349, 0.82042649, 0.82603816, 0.82716049,\n",
       "        0.82603816, 0.82042649, 0.82491582, 0.82716049, 0.82716049,\n",
       "        0.82042649, 0.82491582, 0.82828283, 0.82603816, 0.82042649,\n",
       "        0.82491582, 0.82716049, 0.82491582, 0.81818182, 0.82379349,\n",
       "        0.82716049, 0.82828283, 0.81930415, 0.82267116, 0.82603816,\n",
       "        0.82716049, 0.81818182, 0.82379349, 0.82042649, 0.82491582,\n",
       "        0.82154882, 0.82379349, 0.82379349, 0.82940516, 0.82042649,\n",
       "        0.82379349, 0.82603816, 0.8305275 , 0.82154882, 0.82603816,\n",
       "        0.82491582, 0.82828283, 0.81818182, 0.82491582, 0.82603816,\n",
       "        0.82716049, 0.81930415, 0.82491582, 0.82379349, 0.82828283,\n",
       "        0.81818182, 0.82491582, 0.82603816, 0.82828283, 0.81593715,\n",
       "        0.82154882, 0.82154882, 0.82379349, 0.81930415, 0.82603816,\n",
       "        0.82603816, 0.82603816, 0.81930415, 0.82379349, 0.82379349,\n",
       "        0.82716049, 0.82154882, 0.82379349, 0.82603816, 0.82491582,\n",
       "        0.82154882, 0.82491582, 0.82603816, 0.82716049, 0.81930415,\n",
       "        0.82491582, 0.82716049, 0.82828283, 0.82042649, 0.82716049,\n",
       "        0.82716049, 0.82716049, 0.81705948, 0.82154882, 0.82379349,\n",
       "        0.82379349, 0.82154882, 0.82379349, 0.82379349, 0.82828283,\n",
       "        0.82154882, 0.82379349, 0.82379349, 0.82828283, 0.82267116,\n",
       "        0.82491582, 0.82828283, 0.82940516, 0.81705948, 0.82603816,\n",
       "        0.82379349, 0.82828283, 0.81818182, 0.82491582, 0.82603816,\n",
       "        0.82828283, 0.82267116, 0.82716049, 0.82491582, 0.82828283,\n",
       "        0.81705948, 0.82267116, 0.82267116, 0.82267116, 0.82154882,\n",
       "        0.82603816, 0.82491582, 0.82940516, 0.81818182, 0.82716049,\n",
       "        0.82379349, 0.82940516, 0.82042649, 0.82603816, 0.82828283,\n",
       "        0.82940516, 0.81930415, 0.82716049, 0.82379349, 0.82940516,\n",
       "        0.81593715, 0.82603816, 0.82491582, 0.82828283, 0.82042649,\n",
       "        0.82603816, 0.82716049, 0.82603816, 0.81705948, 0.82154882,\n",
       "        0.82267116, 0.82042649, 0.82154882, 0.82716049, 0.82828283,\n",
       "        0.82716049, 0.82267116, 0.82940516, 0.82828283, 0.82828283,\n",
       "        0.82042649, 0.82603816, 0.82379349, 0.82828283, 0.82042649,\n",
       "        0.82603816, 0.82379349, 0.82828283, 0.81818182, 0.82491582,\n",
       "        0.82379349, 0.82828283, 0.81593715, 0.82491582, 0.82603816,\n",
       "        0.82940516, 0.81818182, 0.82154882, 0.82042649, 0.82154882,\n",
       "        0.82267116, 0.82828283, 0.83164983, 0.82828283, 0.82379349,\n",
       "        0.82716049, 0.8338945 , 0.82603816, 0.82379349, 0.82940516,\n",
       "        0.83277217, 0.82828283, 0.82379349, 0.82828283, 0.83164983,\n",
       "        0.82828283, 0.82154882, 0.82716049, 0.82940516, 0.82940516,\n",
       "        0.82603816, 0.82828283, 0.82940516, 0.82603816, 0.81818182,\n",
       "        0.82154882, 0.82491582, 0.82154882, 0.82379349, 0.82716049,\n",
       "        0.82940516, 0.82716049, 0.82491582, 0.82603816, 0.82940516,\n",
       "        0.82716049, 0.82716049, 0.82716049, 0.83164983, 0.82828283,\n",
       "        0.82491582, 0.8305275 , 0.8305275 , 0.82716049, 0.82379349,\n",
       "        0.82940516, 0.83277217, 0.82716049, 0.82491582, 0.82940516,\n",
       "        0.83164983, 0.82716049, 0.81818182, 0.82154882, 0.82379349,\n",
       "        0.82154882, 0.82491582, 0.82828283, 0.82940516, 0.82828283,\n",
       "        0.82379349, 0.82828283, 0.83277217, 0.82828283, 0.82267116,\n",
       "        0.8305275 , 0.83501684, 0.82828283, 0.82154882, 0.82716049,\n",
       "        0.83277217, 0.82603816, 0.82491582, 0.8305275 , 0.83164983,\n",
       "        0.82716049, 0.82379349, 0.82603816, 0.82940516, 0.82716049,\n",
       "        0.82042649, 0.82154882, 0.82491582, 0.82267116, 0.82603816,\n",
       "        0.82940516, 0.83501684, 0.82828283, 0.82267116, 0.82940516,\n",
       "        0.83277217, 0.82828283, 0.82379349, 0.8305275 , 0.83164983,\n",
       "        0.82828283, 0.82379349, 0.82716049, 0.8338945 , 0.82716049,\n",
       "        0.82267116, 0.82491582, 0.8338945 , 0.82716049, 0.82379349,\n",
       "        0.82940516, 0.83164983, 0.82828283, 0.81930415, 0.82154882,\n",
       "        0.82267116, 0.82154882, 0.82267116, 0.82603816, 0.8338945 ,\n",
       "        0.82716049, 0.82154882, 0.82828283, 0.83164983, 0.82828283,\n",
       "        0.82379349, 0.82603816, 0.83277217, 0.82716049, 0.82154882,\n",
       "        0.82940516, 0.83277217, 0.82716049, 0.82379349, 0.82603816,\n",
       "        0.8338945 , 0.82603816, 0.82379349, 0.82379349, 0.82940516,\n",
       "        0.82828283, 0.81930415, 0.82154882, 0.82154882, 0.82042649,\n",
       "        0.82379349, 0.82603816, 0.82828283, 0.82716049, 0.82491582,\n",
       "        0.82828283, 0.82940516, 0.82940516, 0.82154882, 0.82716049,\n",
       "        0.82940516, 0.82828283, 0.82379349, 0.82716049, 0.82828283,\n",
       "        0.82491582, 0.82491582, 0.82603816, 0.83164983, 0.82716049,\n",
       "        0.82603816, 0.82828283, 0.82603816, 0.82828283, 0.82042649,\n",
       "        0.82042649, 0.82379349, 0.82154882, 0.82379349, 0.82940516,\n",
       "        0.8305275 , 0.82940516, 0.82491582, 0.82716049, 0.82828283,\n",
       "        0.82603816, 0.82379349, 0.82828283, 0.82828283, 0.82828283,\n",
       "        0.82267116, 0.82603816, 0.82828283, 0.82491582, 0.82716049,\n",
       "        0.82828283, 0.82603816, 0.82828283, 0.82491582, 0.82603816,\n",
       "        0.82603816, 0.82940516, 0.81930415, 0.82154882, 0.82491582,\n",
       "        0.82042649, 0.82491582, 0.82603816, 0.82828283, 0.82603816,\n",
       "        0.82379349, 0.82828283, 0.82940516, 0.82828283, 0.82603816,\n",
       "        0.82828283, 0.82716049, 0.82828283, 0.82379349, 0.82716049,\n",
       "        0.82716049, 0.82828283, 0.82267116, 0.82716049, 0.82828283,\n",
       "        0.82491582, 0.82267116, 0.82716049, 0.82379349, 0.83164983,\n",
       "        0.82042649, 0.82267116, 0.82491582, 0.82491582, 0.82267116,\n",
       "        0.82491582, 0.82716049, 0.82716049, 0.82379349, 0.82603816,\n",
       "        0.82716049, 0.82491582, 0.82603816, 0.82828283, 0.82828283,\n",
       "        0.82716049, 0.82379349, 0.82716049, 0.82603816, 0.82716049,\n",
       "        0.82379349, 0.82603816, 0.82716049, 0.83164983, 0.82267116,\n",
       "        0.82828283, 0.82716049, 0.83164983, 0.81930415, 0.82267116,\n",
       "        0.82154882, 0.82042649, 0.82379349, 0.82716049, 0.82940516,\n",
       "        0.82603816, 0.82379349, 0.82828283, 0.82828283, 0.82828283,\n",
       "        0.82267116, 0.82603816, 0.82716049, 0.82940516, 0.82042649,\n",
       "        0.82828283, 0.82716049, 0.82603816, 0.82267116, 0.82940516,\n",
       "        0.82603816, 0.82828283, 0.82379349, 0.82716049, 0.82603816,\n",
       "        0.82716049, 0.81930415, 0.82154882, 0.82154882, 0.82267116]),\n",
       " 'std_test_Accuracy': array([0.01410753, 0.01924403, 0.01356122, 0.01716842, 0.01383707,\n",
       "        0.01657107, 0.01356122, 0.01871305, 0.0153066 , 0.01657107,\n",
       "        0.01356122, 0.01830472, 0.01454712, 0.01930937, 0.01356122,\n",
       "        0.01767454, 0.0104081 , 0.0153066 , 0.01610853, 0.01950409,\n",
       "        0.01356122, 0.01657107, 0.01428499, 0.01924403, 0.01144561,\n",
       "        0.00965469, 0.01657107, 0.01563231, 0.01657107, 0.01930937,\n",
       "        0.01514112, 0.01767454, 0.0153066 , 0.01930937, 0.01356122,\n",
       "        0.01767454, 0.01454712, 0.01788707, 0.01356122, 0.01745943,\n",
       "        0.01454712, 0.01514112, 0.01356122, 0.01830472, 0.01356122,\n",
       "        0.01679756, 0.01587221, 0.02026428, 0.01356122, 0.01679756,\n",
       "        0.01672241, 0.02026428, 0.0104081 , 0.01259817, 0.01374573,\n",
       "        0.01649488, 0.0153066 , 0.01788707, 0.01514112, 0.01830472,\n",
       "        0.0153066 , 0.01788707, 0.01514112, 0.01904665, 0.01514112,\n",
       "        0.01649488, 0.01514112, 0.01904665, 0.01679756, 0.01788707,\n",
       "        0.01610853, 0.01830472, 0.01198325, 0.01930937, 0.01745943,\n",
       "        0.02026428, 0.01356122, 0.01802736, 0.01672241, 0.0208162 ,\n",
       "        0.00952332, 0.00965469, 0.01679756, 0.01563231, 0.01514112,\n",
       "        0.01716842, 0.01428499, 0.01830472, 0.0153066 , 0.0153066 ,\n",
       "        0.01514112, 0.01924403, 0.01563231, 0.01950409, 0.01672241,\n",
       "        0.02026428, 0.01679756, 0.0153066 , 0.01672241, 0.01767454,\n",
       "        0.01356122, 0.01716842, 0.01356122, 0.02026428, 0.01356122,\n",
       "        0.01657107, 0.01672241, 0.02026428, 0.00727356, 0.00965469,\n",
       "        0.01514112, 0.01788707, 0.01410753, 0.01657107, 0.01830472,\n",
       "        0.01767454, 0.01410753, 0.0153066 , 0.01830472, 0.01830472,\n",
       "        0.01144561, 0.01802736, 0.01672241, 0.01830472, 0.01410753,\n",
       "        0.0153066 , 0.01830472, 0.01672241, 0.01454712, 0.01679756,\n",
       "        0.01830472, 0.01982438, 0.01299196, 0.01563231, 0.01563231,\n",
       "        0.01950409, 0.00727356, 0.00965469, 0.01679756, 0.01982438,\n",
       "        0.01454712, 0.01871305, 0.01830472, 0.01988782, 0.01410753,\n",
       "        0.01871305, 0.02026428, 0.02063387, 0.01198325, 0.0223905 ,\n",
       "        0.01924403, 0.01904665, 0.01198325, 0.01716842, 0.02026428,\n",
       "        0.01830472, 0.0104081 , 0.02250274, 0.02063387, 0.01924403,\n",
       "        0.01198325, 0.02182068, 0.01988782, 0.01904665, 0.0079361 ,\n",
       "        0.01454712, 0.01259817, 0.01871305, 0.01299196, 0.02289122,\n",
       "        0.01988782, 0.01767454, 0.0104081 , 0.0208162 , 0.02305571,\n",
       "        0.01830472, 0.01198325, 0.02135387, 0.02026428, 0.01716842,\n",
       "        0.01198325, 0.01924403, 0.01745943, 0.01830472, 0.0104081 ,\n",
       "        0.02250274, 0.01830472, 0.01924403, 0.01144561, 0.02401901,\n",
       "        0.01830472, 0.01830472, 0.00883727, 0.01198325, 0.01356122,\n",
       "        0.01679756, 0.01259817, 0.0208162 , 0.02305571, 0.01924403,\n",
       "        0.01259817, 0.0208162 , 0.0208162 , 0.01924403, 0.01111054,\n",
       "        0.02147152, 0.01924403, 0.01988782, 0.01111054, 0.02026428,\n",
       "        0.0208162 , 0.01924403, 0.01198325, 0.01924403, 0.01988782,\n",
       "        0.01904665, 0.01657107, 0.0208162 , 0.01904665, 0.01924403,\n",
       "        0.00883727, 0.01299196, 0.01299196, 0.01830472, 0.0153066 ,\n",
       "        0.02026428, 0.02396651, 0.01988782, 0.01428499, 0.01871305,\n",
       "        0.02338122, 0.01988782, 0.01144561, 0.0223905 , 0.02396651,\n",
       "        0.01988782, 0.01299196, 0.02338122, 0.02338122, 0.01988782,\n",
       "        0.01111054, 0.0223905 , 0.01904665, 0.01904665, 0.01410753,\n",
       "        0.02289122, 0.01830472, 0.01767454, 0.00883727, 0.01259817,\n",
       "        0.01299196, 0.01788707, 0.01259817, 0.01871305, 0.02182068,\n",
       "        0.01830472, 0.01299196, 0.02026428, 0.02396651, 0.01904665,\n",
       "        0.01356122, 0.02026428, 0.02305571, 0.01924403, 0.01356122,\n",
       "        0.02289122, 0.02063387, 0.01904665, 0.01198325, 0.01982438,\n",
       "        0.02063387, 0.02147152, 0.0104081 , 0.02182068, 0.01988782,\n",
       "        0.01988782, 0.00952332, 0.01259817, 0.01410753, 0.01716842,\n",
       "        0.02099696, 0.02250274, 0.01716842, 0.01672241, 0.02135387,\n",
       "        0.02222109, 0.01871305, 0.01767454, 0.02135387, 0.02026428,\n",
       "        0.01514112, 0.01672241, 0.01871305, 0.01982438, 0.01716842,\n",
       "        0.01672241, 0.0207556 , 0.02135387, 0.01767454, 0.01767454,\n",
       "        0.02099696, 0.02182068, 0.01745943, 0.01514112, 0.01198325,\n",
       "        0.01672241, 0.01428499, 0.01454712, 0.02222109, 0.02135387,\n",
       "        0.01767454, 0.01610853, 0.02250274, 0.02099696, 0.01767454,\n",
       "        0.01610853, 0.02135387, 0.02135387, 0.01454712, 0.01672241,\n",
       "        0.02250274, 0.02135387, 0.01830472, 0.01610853, 0.01871305,\n",
       "        0.02099696, 0.01830472, 0.01610853, 0.01982438, 0.02289122,\n",
       "        0.01672241, 0.01610853, 0.01198325, 0.01454712, 0.01356122,\n",
       "        0.0153066 , 0.02182068, 0.02250274, 0.01767454, 0.01672241,\n",
       "        0.02135387, 0.01982438, 0.01830472, 0.01672241, 0.02099696,\n",
       "        0.02135387, 0.01982438, 0.01672241, 0.01982438, 0.01871305,\n",
       "        0.01830472, 0.01514112, 0.0207556 , 0.02401901, 0.01924403,\n",
       "        0.01587221, 0.01610853, 0.02289122, 0.01745943, 0.01871305,\n",
       "        0.01111054, 0.01716842, 0.01428499, 0.01514112, 0.01830472,\n",
       "        0.02099696, 0.01716842, 0.01672241, 0.02099696, 0.02099696,\n",
       "        0.02026428, 0.01672241, 0.01950409, 0.01871305, 0.01924403,\n",
       "        0.01672241, 0.02135387, 0.01610853, 0.01871305, 0.01587221,\n",
       "        0.01830472, 0.01924403, 0.01871305, 0.01830472, 0.01679756,\n",
       "        0.02370226, 0.01924403, 0.01672241, 0.0079361 , 0.01428499,\n",
       "        0.01299196, 0.0153066 , 0.01767454, 0.02099696, 0.02135387,\n",
       "        0.01587221, 0.01672241, 0.02250274, 0.01924403, 0.01428499,\n",
       "        0.01871305, 0.02026428, 0.02026428, 0.01587221, 0.01982438,\n",
       "        0.02099696, 0.01514112, 0.01830472, 0.01871305, 0.02099696,\n",
       "        0.01950409, 0.01767454, 0.01950409, 0.01871305, 0.01767454,\n",
       "        0.01428499, 0.0079361 , 0.01428499, 0.01454712, 0.01679756,\n",
       "        0.01950409, 0.02026428, 0.01454712, 0.01410753, 0.0207556 ,\n",
       "        0.01716842, 0.01514112, 0.01563231, 0.01982438, 0.01871305,\n",
       "        0.01745943, 0.01716842, 0.01950409, 0.02135387, 0.01428499,\n",
       "        0.01982438, 0.0207556 , 0.01988782, 0.01672241, 0.01950409,\n",
       "        0.02099696, 0.02182068, 0.01745943, 0.01716842, 0.01111054,\n",
       "        0.01679756, 0.01356122, 0.01716842, 0.02222109, 0.02026428,\n",
       "        0.01610853, 0.01657107, 0.02348872, 0.01871305, 0.01716842,\n",
       "        0.01830472, 0.01679756, 0.02182068, 0.01672241, 0.01802736,\n",
       "        0.02099696, 0.0223905 , 0.01672241, 0.01982438, 0.02222109,\n",
       "        0.01924403, 0.01745943, 0.01982438, 0.01982438, 0.01988782,\n",
       "        0.01767454, 0.01563231, 0.0104081 , 0.0153066 , 0.01428499,\n",
       "        0.01410753, 0.01802736, 0.01745943, 0.01672241, 0.01930937,\n",
       "        0.01950409, 0.01924403, 0.01514112, 0.01982438, 0.02370226,\n",
       "        0.01924403, 0.01587221, 0.02182068, 0.02222109, 0.01679756,\n",
       "        0.01587221, 0.01982438, 0.02099696, 0.01871305, 0.01672241,\n",
       "        0.01982438, 0.02338122, 0.0208162 , 0.01830472, 0.01924403,\n",
       "        0.00883727, 0.01657107, 0.01428499, 0.01672241, 0.02205037,\n",
       "        0.01904665, 0.01610853, 0.01950409, 0.02222109, 0.0223905 ,\n",
       "        0.01610853, 0.01716842, 0.01930937, 0.02182068, 0.01672241,\n",
       "        0.01610853, 0.02222109, 0.01830472, 0.01767454, 0.02063387,\n",
       "        0.02222109, 0.0223905 , 0.0208162 , 0.01924403, 0.02026428,\n",
       "        0.01924403, 0.01871305, 0.01716842, 0.0079361 , 0.01563231,\n",
       "        0.01259817, 0.01410753, 0.01950409, 0.02135387, 0.01767454,\n",
       "        0.02026428, 0.02222109, 0.02182068, 0.01716842, 0.01672241,\n",
       "        0.01930937, 0.0223905 , 0.01587221, 0.02026428, 0.01950409,\n",
       "        0.01924403, 0.01587221, 0.01830472, 0.01830472, 0.02026428,\n",
       "        0.01767454, 0.01982438, 0.02135387, 0.0208162 , 0.01988782,\n",
       "        0.01871305, 0.0079361 , 0.01454712, 0.01374573, 0.01563231]),\n",
       " 'rank_test_Accuracy': array([486,  78, 172, 310, 526, 239, 172, 172, 442, 414, 172, 172, 528,\n",
       "        239, 172, 270, 557, 442, 172,  30, 549, 414,  78,  78, 480, 480,\n",
       "        414, 270, 526, 172, 270, 270, 528,  36, 172, 270, 528, 270, 172,\n",
       "        270, 528, 360, 172, 172, 549, 486, 172,  36, 549, 360,  78,  36,\n",
       "        513, 442, 442, 310, 528, 172, 270, 172, 528, 172, 270,  78, 486,\n",
       "        310,  36,  78, 486, 270, 172, 172, 528, 172, 270,  36, 549, 310,\n",
       "        352,  27, 528, 480, 486, 270, 486, 310,  78, 172, 442, 310,  36,\n",
       "         78, 513, 172,  78,  36, 486, 310,  78, 270, 549, 310, 172,  36,\n",
       "        549, 239, 352,  36, 528, 480, 486, 360, 486, 239, 172, 270, 486,\n",
       "        310, 172, 172, 486, 310,  78, 239, 486, 310, 172, 352, 528, 360,\n",
       "        172,  78, 513, 414, 270, 172, 528, 360, 486, 310, 442, 360, 360,\n",
       "         36, 486, 360, 239,  27, 442, 270, 310,  78, 528, 310, 239, 172,\n",
       "        513, 310, 360,  78, 528, 310, 270,  78, 557, 442, 442, 360, 513,\n",
       "        239, 270, 270, 513, 360, 360, 172, 442, 360, 239, 310, 442, 310,\n",
       "        270, 172, 513, 310, 172,  78, 486, 155, 172, 172, 549, 442, 360,\n",
       "        360, 442, 360, 360,  78, 442, 360, 360,  78, 414, 310,  78,  36,\n",
       "        549, 239, 360,  78, 528, 310, 270,  78, 414, 172, 352,  78, 547,\n",
       "        414, 414, 414, 442, 239, 352,  36, 528, 155, 360,  36, 486, 270,\n",
       "         78,  36, 513, 172, 360,  36, 557, 270, 352,  78, 486, 239, 172,\n",
       "        270, 547, 442, 414, 480, 442, 155,  78, 172, 414,  36,  78,  78,\n",
       "        486, 239, 360,  78, 486, 239, 360,  78, 528, 310, 360,  78, 560,\n",
       "        310, 270,  36, 528, 442, 486, 442, 414,  78,  17,  78, 360, 172,\n",
       "          3, 270, 360,  36,   8,  78, 360,  78,  17,  78, 442, 155,  36,\n",
       "         36, 239,  78,  36, 270, 528, 442, 310, 442, 360, 155,  36, 172,\n",
       "        310, 239,  36, 172, 155, 155,  17,  78, 310,  30,  27, 172, 360,\n",
       "         73,   8, 172, 310,  36,  17, 172, 528, 442, 360, 442, 310,  78,\n",
       "         36,  78, 360,  78,   8,  78, 414,  30,   1,  78, 442, 155,   8,\n",
       "        270, 310,  30,  17, 172, 360, 239,  36, 172, 486, 442, 310, 414,\n",
       "        239,  73,   1,  78, 414,  73,   8,  78, 360,  30,  17,  78, 360,\n",
       "        155,   3, 172, 414, 310,   3, 172, 360,  73,  17,  78, 513, 442,\n",
       "        414, 442, 414, 239,   3, 172, 442,  78,  17,  78, 360, 239,   8,\n",
       "        172, 442,  73,   8, 172, 360, 239,   3, 270, 360, 360,  36,  78,\n",
       "        513, 442, 442, 486, 360, 239,  78, 172, 310,  78,  36,  36, 442,\n",
       "        155,  36,  78, 360, 155,  78, 310, 310, 270,  17, 172, 239,  78,\n",
       "        270,  78, 486, 486, 360, 442, 360,  36,  30,  36, 310, 155,  78,\n",
       "        239, 360,  78,  78,  78, 414, 270,  78, 310, 172,  78, 270,  78,\n",
       "        310, 270, 270,  36, 513, 442, 310, 486, 310, 270,  78, 239, 360,\n",
       "         78,  36,  78, 239,  78, 172,  78, 360, 172, 172,  78, 414, 155,\n",
       "         78, 310, 414, 172, 360,  15, 486, 414, 310, 352, 414, 352, 155,\n",
       "        172, 360, 270, 155, 310, 239,  78,  78, 172, 360, 172, 239, 172,\n",
       "        360, 270, 172,  15, 414,  78, 155,  17, 513, 414, 442, 486, 360,\n",
       "        155,  36, 239, 360,  78,  78,  78, 414, 270, 172,  36, 480,  78,\n",
       "        172, 239, 414,  36, 239,  78, 360, 172, 270, 172, 513, 442, 442,\n",
       "        414]),\n",
       " 'split0_train_Accuracy': array([0.91750842, 0.92087542, 0.92255892, 0.92424242, 0.91750842,\n",
       "        0.92424242, 0.92424242, 0.92424242, 0.91750842, 0.92087542,\n",
       "        0.92424242, 0.92424242, 0.91750842, 0.91919192, 0.92424242,\n",
       "        0.92424242, 0.91750842, 0.91919192, 0.92424242, 0.92424242,\n",
       "        0.91582492, 0.91919192, 0.92087542, 0.92424242, 0.9040404 ,\n",
       "        0.9023569 , 0.90740741, 0.90740741, 0.91582492, 0.91919192,\n",
       "        0.92424242, 0.92424242, 0.91750842, 0.92255892, 0.92424242,\n",
       "        0.92424242, 0.91919192, 0.92087542, 0.92424242, 0.92255892,\n",
       "        0.91919192, 0.92087542, 0.92255892, 0.92424242, 0.91750842,\n",
       "        0.92087542, 0.92255892, 0.92424242, 0.91750842, 0.92087542,\n",
       "        0.92087542, 0.92255892, 0.9006734 , 0.9006734 , 0.90740741,\n",
       "        0.90740741, 0.91750842, 0.92087542, 0.92255892, 0.92424242,\n",
       "        0.91750842, 0.92087542, 0.92255892, 0.92424242, 0.91750842,\n",
       "        0.92255892, 0.92424242, 0.92424242, 0.91750842, 0.92087542,\n",
       "        0.92424242, 0.92424242, 0.91919192, 0.92087542, 0.92255892,\n",
       "        0.92424242, 0.91414141, 0.92087542, 0.92087542, 0.92255892,\n",
       "        0.9006734 , 0.8989899 , 0.90740741, 0.90740741, 0.91750842,\n",
       "        0.92087542, 0.92424242, 0.92592593, 0.91919192, 0.92087542,\n",
       "        0.92255892, 0.92424242, 0.91750842, 0.92255892, 0.92424242,\n",
       "        0.92592593, 0.91750842, 0.92087542, 0.92255892, 0.92424242,\n",
       "        0.91582492, 0.92087542, 0.91919192, 0.92255892, 0.91750842,\n",
       "        0.91919192, 0.92087542, 0.92255892, 0.8989899 , 0.8973064 ,\n",
       "        0.90572391, 0.90740741, 0.91582492, 0.92087542, 0.92255892,\n",
       "        0.92255892, 0.91582492, 0.92087542, 0.92592593, 0.92424242,\n",
       "        0.91750842, 0.92087542, 0.92087542, 0.92424242, 0.91750842,\n",
       "        0.91919192, 0.92424242, 0.92255892, 0.91582492, 0.91919192,\n",
       "        0.92087542, 0.91919192, 0.91414141, 0.91919192, 0.92087542,\n",
       "        0.92087542, 0.8973064 , 0.8973064 , 0.9023569 , 0.90572391,\n",
       "        0.92087542, 0.92087542, 0.92424242, 0.92424242, 0.92087542,\n",
       "        0.92255892, 0.92424242, 0.92424242, 0.92087542, 0.92087542,\n",
       "        0.92424242, 0.92592593, 0.91919192, 0.92087542, 0.92424242,\n",
       "        0.92255892, 0.91750842, 0.91919192, 0.92255892, 0.92592593,\n",
       "        0.91582492, 0.92255892, 0.92424242, 0.92424242, 0.9040404 ,\n",
       "        0.90572391, 0.90740741, 0.90909091, 0.91919192, 0.92255892,\n",
       "        0.92592593, 0.92255892, 0.91919192, 0.92087542, 0.92592593,\n",
       "        0.92255892, 0.92087542, 0.92087542, 0.92424242, 0.92424242,\n",
       "        0.92087542, 0.92255892, 0.92424242, 0.92424242, 0.91750842,\n",
       "        0.92255892, 0.92592593, 0.92424242, 0.91750842, 0.92255892,\n",
       "        0.92255892, 0.92592593, 0.9023569 , 0.9040404 , 0.90572391,\n",
       "        0.90740741, 0.92087542, 0.92087542, 0.92424242, 0.92424242,\n",
       "        0.91919192, 0.92255892, 0.92424242, 0.92255892, 0.92087542,\n",
       "        0.92087542, 0.92592593, 0.92592593, 0.91919192, 0.92087542,\n",
       "        0.92592593, 0.92424242, 0.91750842, 0.92087542, 0.92592593,\n",
       "        0.92592593, 0.91414141, 0.92255892, 0.92592593, 0.92592593,\n",
       "        0.9023569 , 0.90572391, 0.9040404 , 0.90740741, 0.92087542,\n",
       "        0.92087542, 0.92424242, 0.92255892, 0.92087542, 0.92087542,\n",
       "        0.92424242, 0.92424242, 0.91582492, 0.92087542, 0.92424242,\n",
       "        0.92592593, 0.91919192, 0.92087542, 0.92424242, 0.92424242,\n",
       "        0.91582492, 0.92087542, 0.92592593, 0.92424242, 0.91750842,\n",
       "        0.92087542, 0.92424242, 0.92087542, 0.9023569 , 0.9006734 ,\n",
       "        0.90572391, 0.90572391, 0.91750842, 0.92087542, 0.92424242,\n",
       "        0.92087542, 0.91750842, 0.92087542, 0.92424242, 0.91919192,\n",
       "        0.91919192, 0.92087542, 0.92424242, 0.92255892, 0.91919192,\n",
       "        0.92087542, 0.92424242, 0.92087542, 0.91750842, 0.92087542,\n",
       "        0.92255892, 0.92087542, 0.91750842, 0.92255892, 0.92424242,\n",
       "        0.92087542, 0.8989899 , 0.8989899 , 0.9023569 , 0.90572391,\n",
       "        0.91919192, 0.92087542, 0.92424242, 0.92424242, 0.91750842,\n",
       "        0.92255892, 0.92424242, 0.92424242, 0.91919192, 0.92255892,\n",
       "        0.92592593, 0.92592593, 0.91750842, 0.92424242, 0.92424242,\n",
       "        0.92424242, 0.91750842, 0.92255892, 0.92424242, 0.92424242,\n",
       "        0.91750842, 0.92087542, 0.92424242, 0.92424242, 0.9040404 ,\n",
       "        0.90909091, 0.90909091, 0.91077441, 0.91919192, 0.92255892,\n",
       "        0.92592593, 0.92424242, 0.91750842, 0.92255892, 0.92592593,\n",
       "        0.92424242, 0.91919192, 0.92255892, 0.92424242, 0.92592593,\n",
       "        0.91750842, 0.92424242, 0.92424242, 0.92255892, 0.91750842,\n",
       "        0.92255892, 0.92424242, 0.92424242, 0.91750842, 0.91919192,\n",
       "        0.92424242, 0.92255892, 0.9040404 , 0.90572391, 0.90572391,\n",
       "        0.91077441, 0.91750842, 0.92424242, 0.92424242, 0.92424242,\n",
       "        0.91919192, 0.92592593, 0.92424242, 0.92424242, 0.91750842,\n",
       "        0.92424242, 0.92592593, 0.92424242, 0.91919192, 0.92424242,\n",
       "        0.92760943, 0.92592593, 0.91750842, 0.92087542, 0.92424242,\n",
       "        0.92424242, 0.91750842, 0.91919192, 0.92592593, 0.92255892,\n",
       "        0.8989899 , 0.90572391, 0.90572391, 0.90909091, 0.91750842,\n",
       "        0.92255892, 0.92424242, 0.92424242, 0.91919192, 0.92255892,\n",
       "        0.92424242, 0.92424242, 0.91750842, 0.92087542, 0.92424242,\n",
       "        0.92255892, 0.91919192, 0.92424242, 0.92424242, 0.92424242,\n",
       "        0.91750842, 0.92087542, 0.92424242, 0.92255892, 0.91582492,\n",
       "        0.92087542, 0.92424242, 0.92255892, 0.9006734 , 0.9040404 ,\n",
       "        0.9040404 , 0.90909091, 0.91750842, 0.92087542, 0.92255892,\n",
       "        0.92255892, 0.91750842, 0.92087542, 0.92424242, 0.92424242,\n",
       "        0.91750842, 0.92087542, 0.92592593, 0.92255892, 0.91750842,\n",
       "        0.92087542, 0.92592593, 0.92255892, 0.91750842, 0.91919192,\n",
       "        0.92424242, 0.92255892, 0.91750842, 0.92087542, 0.92255892,\n",
       "        0.92424242, 0.8973064 , 0.9023569 , 0.9040404 , 0.90909091,\n",
       "        0.92255892, 0.92592593, 0.92592593, 0.92929293, 0.92424242,\n",
       "        0.92592593, 0.92592593, 0.92760943, 0.92592593, 0.92592593,\n",
       "        0.92592593, 0.92760943, 0.92424242, 0.92592593, 0.92592593,\n",
       "        0.92760943, 0.92255892, 0.92424242, 0.92592593, 0.92592593,\n",
       "        0.92087542, 0.92592593, 0.92592593, 0.92929293, 0.9040404 ,\n",
       "        0.91077441, 0.90909091, 0.91414141, 0.92255892, 0.92255892,\n",
       "        0.92592593, 0.92929293, 0.92255892, 0.92255892, 0.92760943,\n",
       "        0.92760943, 0.92255892, 0.92424242, 0.92760943, 0.92760943,\n",
       "        0.92255892, 0.92592593, 0.92592593, 0.92929293, 0.92087542,\n",
       "        0.92592593, 0.92592593, 0.92929293, 0.91919192, 0.92087542,\n",
       "        0.92592593, 0.93097643, 0.9040404 , 0.91077441, 0.90909091,\n",
       "        0.91077441, 0.92424242, 0.92592593, 0.92592593, 0.92929293,\n",
       "        0.92087542, 0.92592593, 0.92592593, 0.92424242, 0.92087542,\n",
       "        0.92592593, 0.92592593, 0.92760943, 0.92255892, 0.92424242,\n",
       "        0.92592593, 0.93097643, 0.91750842, 0.92424242, 0.92424242,\n",
       "        0.92592593, 0.92087542, 0.92255892, 0.92424242, 0.92929293,\n",
       "        0.9040404 , 0.90740741, 0.90740741, 0.90909091, 0.91919192,\n",
       "        0.92255892, 0.92592593, 0.92760943, 0.92087542, 0.92592593,\n",
       "        0.92592593, 0.92592593, 0.92087542, 0.92424242, 0.92592593,\n",
       "        0.92929293, 0.92087542, 0.92424242, 0.92592593, 0.92929293,\n",
       "        0.91750842, 0.92255892, 0.92592593, 0.92760943, 0.91919192,\n",
       "        0.92255892, 0.92424242, 0.92929293, 0.9023569 , 0.90572391,\n",
       "        0.90740741, 0.90909091, 0.92087542, 0.92424242, 0.92592593,\n",
       "        0.92592593, 0.92087542, 0.92424242, 0.92592593, 0.92760943,\n",
       "        0.91919192, 0.92424242, 0.92592593, 0.92929293, 0.92087542,\n",
       "        0.92424242, 0.92592593, 0.92592593, 0.91919192, 0.92255892,\n",
       "        0.92424242, 0.92929293, 0.92087542, 0.92087542, 0.92592593,\n",
       "        0.92592593, 0.9006734 , 0.9040404 , 0.90740741, 0.90909091]),\n",
       " 'split1_train_Accuracy': array([0.88720539, 0.89393939, 0.89225589, 0.88720539, 0.88720539,\n",
       "        0.89225589, 0.89393939, 0.88720539, 0.88720539, 0.89393939,\n",
       "        0.89393939, 0.88720539, 0.88720539, 0.89225589, 0.89225589,\n",
       "        0.88720539, 0.88720539, 0.8956229 , 0.89225589, 0.88720539,\n",
       "        0.88720539, 0.89057239, 0.89225589, 0.88720539, 0.87373737,\n",
       "        0.87542088, 0.87710438, 0.87710438, 0.88720539, 0.8956229 ,\n",
       "        0.8973064 , 0.88720539, 0.88720539, 0.89393939, 0.8973064 ,\n",
       "        0.88720539, 0.88720539, 0.89225589, 0.8956229 , 0.88720539,\n",
       "        0.88720539, 0.8956229 , 0.89225589, 0.88720539, 0.88888889,\n",
       "        0.89225589, 0.89225589, 0.88720539, 0.88720539, 0.88888889,\n",
       "        0.89225589, 0.88720539, 0.87542088, 0.87542088, 0.87710438,\n",
       "        0.87542088, 0.88720539, 0.89393939, 0.8956229 , 0.88552189,\n",
       "        0.88720539, 0.89225589, 0.8956229 , 0.88552189, 0.88720539,\n",
       "        0.89225589, 0.89225589, 0.88383838, 0.88720539, 0.89057239,\n",
       "        0.8973064 , 0.88552189, 0.88552189, 0.89225589, 0.89057239,\n",
       "        0.88552189, 0.88552189, 0.88888889, 0.88888889, 0.88383838,\n",
       "        0.87373737, 0.87205387, 0.87373737, 0.87373737, 0.88720539,\n",
       "        0.89225589, 0.89057239, 0.88383838, 0.88720539, 0.89225589,\n",
       "        0.8956229 , 0.88383838, 0.88720539, 0.89057239, 0.89393939,\n",
       "        0.88383838, 0.88552189, 0.89225589, 0.89057239, 0.88552189,\n",
       "        0.88552189, 0.89393939, 0.89057239, 0.88552189, 0.88552189,\n",
       "        0.88888889, 0.88888889, 0.88552189, 0.87373737, 0.87373737,\n",
       "        0.87205387, 0.87373737, 0.88720539, 0.89057239, 0.89225589,\n",
       "        0.88552189, 0.88720539, 0.89393939, 0.89225589, 0.88383838,\n",
       "        0.88720539, 0.89057239, 0.89225589, 0.88383838, 0.88720539,\n",
       "        0.89393939, 0.89225589, 0.88552189, 0.88888889, 0.89057239,\n",
       "        0.88888889, 0.88215488, 0.88720539, 0.88888889, 0.88720539,\n",
       "        0.88383838, 0.87373737, 0.87373737, 0.87037037, 0.87205387,\n",
       "        0.89225589, 0.89225589, 0.89225589, 0.88720539, 0.89057239,\n",
       "        0.89225589, 0.89057239, 0.88888889, 0.89057239, 0.89225589,\n",
       "        0.89225589, 0.88888889, 0.89225589, 0.89393939, 0.89057239,\n",
       "        0.88888889, 0.89057239, 0.89393939, 0.89225589, 0.88720539,\n",
       "        0.88888889, 0.8956229 , 0.89225589, 0.88888889, 0.87710438,\n",
       "        0.87878788, 0.87710438, 0.87878788, 0.89057239, 0.89225589,\n",
       "        0.89393939, 0.88888889, 0.89225589, 0.89393939, 0.89225589,\n",
       "        0.88888889, 0.88888889, 0.89393939, 0.89057239, 0.88720539,\n",
       "        0.89225589, 0.89393939, 0.89057239, 0.88720539, 0.88888889,\n",
       "        0.89393939, 0.89225589, 0.88888889, 0.88720539, 0.89393939,\n",
       "        0.89225589, 0.88888889, 0.87710438, 0.87878788, 0.87710438,\n",
       "        0.87542088, 0.89393939, 0.89225589, 0.89225589, 0.88888889,\n",
       "        0.89057239, 0.89225589, 0.89393939, 0.88720539, 0.88552189,\n",
       "        0.89225589, 0.89393939, 0.88888889, 0.88720539, 0.89393939,\n",
       "        0.89225589, 0.88888889, 0.89057239, 0.89393939, 0.89225589,\n",
       "        0.88888889, 0.88720539, 0.89393939, 0.88888889, 0.88720539,\n",
       "        0.87878788, 0.87878788, 0.87373737, 0.87373737, 0.89057239,\n",
       "        0.89393939, 0.89057239, 0.88720539, 0.89057239, 0.89393939,\n",
       "        0.89057239, 0.88888889, 0.89057239, 0.89393939, 0.89225589,\n",
       "        0.88720539, 0.88888889, 0.89393939, 0.89393939, 0.88888889,\n",
       "        0.88888889, 0.89393939, 0.88888889, 0.88888889, 0.88552189,\n",
       "        0.89393939, 0.88888889, 0.88720539, 0.87710438, 0.87205387,\n",
       "        0.87373737, 0.87373737, 0.88888889, 0.89393939, 0.89225589,\n",
       "        0.88720539, 0.88888889, 0.89393939, 0.89225589, 0.88720539,\n",
       "        0.88888889, 0.89225589, 0.89057239, 0.88720539, 0.88888889,\n",
       "        0.89225589, 0.89225589, 0.88888889, 0.88888889, 0.89225589,\n",
       "        0.88888889, 0.88720539, 0.88720539, 0.89225589, 0.89057239,\n",
       "        0.88720539, 0.87542088, 0.87205387, 0.87205387, 0.87205387,\n",
       "        0.89057239, 0.89225589, 0.89393939, 0.89057239, 0.89057239,\n",
       "        0.89225589, 0.8956229 , 0.89057239, 0.89225589, 0.89393939,\n",
       "        0.8956229 , 0.89393939, 0.8956229 , 0.89225589, 0.89393939,\n",
       "        0.89393939, 0.89057239, 0.89393939, 0.89393939, 0.89393939,\n",
       "        0.89057239, 0.89225589, 0.89057239, 0.89057239, 0.87878788,\n",
       "        0.87710438, 0.88047138, 0.87710438, 0.89225589, 0.89393939,\n",
       "        0.8956229 , 0.89393939, 0.89225589, 0.89225589, 0.8956229 ,\n",
       "        0.89057239, 0.89225589, 0.89225589, 0.8956229 , 0.89225589,\n",
       "        0.89225589, 0.89393939, 0.8956229 , 0.89393939, 0.88888889,\n",
       "        0.89393939, 0.89225589, 0.88888889, 0.89057239, 0.89393939,\n",
       "        0.89057239, 0.88888889, 0.87878788, 0.87878788, 0.88047138,\n",
       "        0.87878788, 0.89225589, 0.89225589, 0.89393939, 0.89057239,\n",
       "        0.89057239, 0.89393939, 0.89393939, 0.89225589, 0.89057239,\n",
       "        0.89393939, 0.8956229 , 0.89057239, 0.89057239, 0.89393939,\n",
       "        0.89393939, 0.89057239, 0.89225589, 0.89393939, 0.89225589,\n",
       "        0.89057239, 0.88888889, 0.89225589, 0.89225589, 0.89057239,\n",
       "        0.87878788, 0.87710438, 0.88215488, 0.87710438, 0.89225589,\n",
       "        0.89225589, 0.89393939, 0.89225589, 0.89225589, 0.89225589,\n",
       "        0.89393939, 0.89057239, 0.89057239, 0.89393939, 0.89393939,\n",
       "        0.89225589, 0.89225589, 0.89393939, 0.89393939, 0.89057239,\n",
       "        0.88888889, 0.89393939, 0.89225589, 0.89057239, 0.89225589,\n",
       "        0.89225589, 0.89225589, 0.88888889, 0.87878788, 0.87542088,\n",
       "        0.87710438, 0.87542088, 0.88888889, 0.89225589, 0.89057239,\n",
       "        0.89225589, 0.88720539, 0.89225589, 0.89057239, 0.89225589,\n",
       "        0.89057239, 0.89393939, 0.89393939, 0.89225589, 0.89057239,\n",
       "        0.89393939, 0.89393939, 0.88888889, 0.88552189, 0.89225589,\n",
       "        0.89225589, 0.88888889, 0.88720539, 0.89225589, 0.89057239,\n",
       "        0.89057239, 0.88047138, 0.87373737, 0.87542088, 0.87205387,\n",
       "        0.8956229 , 0.8989899 , 0.89057239, 0.89225589, 0.8973064 ,\n",
       "        0.8989899 , 0.89393939, 0.89225589, 0.8956229 , 0.8973064 ,\n",
       "        0.89393939, 0.89225589, 0.89393939, 0.8973064 , 0.89393939,\n",
       "        0.89057239, 0.8989899 , 0.8973064 , 0.89057239, 0.88888889,\n",
       "        0.89393939, 0.8973064 , 0.89225589, 0.89057239, 0.87878788,\n",
       "        0.88215488, 0.88047138, 0.88047138, 0.8956229 , 0.8973064 ,\n",
       "        0.89225589, 0.89057239, 0.8973064 , 0.89393939, 0.8956229 ,\n",
       "        0.88888889, 0.8956229 , 0.8973064 , 0.89393939, 0.88888889,\n",
       "        0.89393939, 0.8956229 , 0.89057239, 0.89057239, 0.8956229 ,\n",
       "        0.89393939, 0.89225589, 0.88888889, 0.89057239, 0.8956229 ,\n",
       "        0.89057239, 0.88888889, 0.87878788, 0.88215488, 0.88047138,\n",
       "        0.88047138, 0.89393939, 0.8973064 , 0.89057239, 0.89057239,\n",
       "        0.89393939, 0.8956229 , 0.89057239, 0.88720539, 0.89393939,\n",
       "        0.8956229 , 0.89393939, 0.88720539, 0.89225589, 0.8973064 ,\n",
       "        0.89225589, 0.88720539, 0.89057239, 0.8956229 , 0.89057239,\n",
       "        0.88720539, 0.88888889, 0.89393939, 0.89393939, 0.88888889,\n",
       "        0.87878788, 0.88047138, 0.88047138, 0.87878788, 0.89393939,\n",
       "        0.8956229 , 0.89393939, 0.88720539, 0.89393939, 0.8973064 ,\n",
       "        0.89393939, 0.88720539, 0.89225589, 0.89393939, 0.89225589,\n",
       "        0.88720539, 0.89225589, 0.8956229 , 0.89393939, 0.88552189,\n",
       "        0.88888889, 0.8973064 , 0.89225589, 0.88720539, 0.88720539,\n",
       "        0.89393939, 0.89057239, 0.88888889, 0.87710438, 0.88047138,\n",
       "        0.88047138, 0.87878788, 0.89225589, 0.8956229 , 0.89225589,\n",
       "        0.88888889, 0.89057239, 0.8956229 , 0.89225589, 0.88888889,\n",
       "        0.89225589, 0.8956229 , 0.89057239, 0.88720539, 0.89225589,\n",
       "        0.8956229 , 0.89057239, 0.88720539, 0.88888889, 0.89393939,\n",
       "        0.89057239, 0.88720539, 0.88552189, 0.89393939, 0.89225589,\n",
       "        0.88888889, 0.87373737, 0.87878788, 0.87542088, 0.87373737]),\n",
       " 'split2_train_Accuracy': array([0.8973064 , 0.8973064 , 0.8956229 , 0.8989899 , 0.8956229 ,\n",
       "        0.8989899 , 0.89393939, 0.8989899 , 0.8973064 , 0.8973064 ,\n",
       "        0.89393939, 0.8989899 , 0.8956229 , 0.8973064 , 0.89393939,\n",
       "        0.8973064 , 0.89225589, 0.8973064 , 0.89225589, 0.8989899 ,\n",
       "        0.89393939, 0.8956229 , 0.89225589, 0.8989899 , 0.88383838,\n",
       "        0.88383838, 0.88383838, 0.88383838, 0.8973064 , 0.8973064 ,\n",
       "        0.89225589, 0.8989899 , 0.8973064 , 0.8989899 , 0.89393939,\n",
       "        0.8989899 , 0.89057239, 0.8973064 , 0.89393939, 0.8989899 ,\n",
       "        0.8973064 , 0.8973064 , 0.89393939, 0.8973064 , 0.8973064 ,\n",
       "        0.8973064 , 0.89393939, 0.8973064 , 0.89225589, 0.8989899 ,\n",
       "        0.89225589, 0.8973064 , 0.88383838, 0.88552189, 0.88215488,\n",
       "        0.88383838, 0.8956229 , 0.8989899 , 0.89393939, 0.8989899 ,\n",
       "        0.8956229 , 0.8989899 , 0.89225589, 0.8989899 , 0.8973064 ,\n",
       "        0.8973064 , 0.89225589, 0.8989899 , 0.8973064 , 0.8973064 ,\n",
       "        0.89225589, 0.8989899 , 0.8956229 , 0.8973064 , 0.8956229 ,\n",
       "        0.8973064 , 0.89225589, 0.8973064 , 0.8956229 , 0.8989899 ,\n",
       "        0.87878788, 0.88215488, 0.88215488, 0.88383838, 0.8973064 ,\n",
       "        0.8989899 , 0.89393939, 0.8973064 , 0.8973064 , 0.8989899 ,\n",
       "        0.89225589, 0.8973064 , 0.8973064 , 0.8989899 , 0.89393939,\n",
       "        0.8989899 , 0.8973064 , 0.8989899 , 0.89225589, 0.8989899 ,\n",
       "        0.8956229 , 0.8973064 , 0.89393939, 0.8989899 , 0.89057239,\n",
       "        0.8973064 , 0.8956229 , 0.8989899 , 0.88047138, 0.88047138,\n",
       "        0.87710438, 0.88215488, 0.8956229 , 0.8973064 , 0.89225589,\n",
       "        0.8989899 , 0.8956229 , 0.8956229 , 0.89225589, 0.8989899 ,\n",
       "        0.8973064 , 0.8973064 , 0.89393939, 0.8989899 , 0.8973064 ,\n",
       "        0.89393939, 0.89225589, 0.8989899 , 0.89393939, 0.89393939,\n",
       "        0.89393939, 0.8989899 , 0.89225589, 0.8973064 , 0.89225589,\n",
       "        0.8989899 , 0.87542088, 0.87878788, 0.87710438, 0.88215488,\n",
       "        0.89393939, 0.8956229 , 0.9023569 , 0.8989899 , 0.8989899 ,\n",
       "        0.8989899 , 0.9006734 , 0.8989899 , 0.89393939, 0.8973064 ,\n",
       "        0.8973064 , 0.8989899 , 0.89225589, 0.8973064 , 0.9006734 ,\n",
       "        0.8989899 , 0.89393939, 0.8956229 , 0.9006734 , 0.8989899 ,\n",
       "        0.8956229 , 0.8973064 , 0.8989899 , 0.8989899 , 0.88552189,\n",
       "        0.88383838, 0.88383838, 0.88720539, 0.89393939, 0.8956229 ,\n",
       "        0.8989899 , 0.9006734 , 0.89393939, 0.8989899 , 0.8989899 ,\n",
       "        0.9006734 , 0.89225589, 0.89393939, 0.8989899 , 0.8989899 ,\n",
       "        0.89393939, 0.8973064 , 0.8989899 , 0.8989899 , 0.89393939,\n",
       "        0.8956229 , 0.8989899 , 0.8989899 , 0.8956229 , 0.8989899 ,\n",
       "        0.8973064 , 0.8989899 , 0.88383838, 0.88215488, 0.88047138,\n",
       "        0.88552189, 0.89057239, 0.8989899 , 0.8989899 , 0.8989899 ,\n",
       "        0.89225589, 0.8973064 , 0.8973064 , 0.8989899 , 0.89393939,\n",
       "        0.8989899 , 0.8973064 , 0.8989899 , 0.8956229 , 0.8956229 ,\n",
       "        0.8989899 , 0.8989899 , 0.8956229 , 0.8989899 , 0.8989899 ,\n",
       "        0.8989899 , 0.8956229 , 0.8973064 , 0.8973064 , 0.8989899 ,\n",
       "        0.88552189, 0.88215488, 0.88047138, 0.88552189, 0.8956229 ,\n",
       "        0.8956229 , 0.8989899 , 0.8989899 , 0.8956229 , 0.8956229 ,\n",
       "        0.8989899 , 0.8989899 , 0.89393939, 0.8973064 , 0.8973064 ,\n",
       "        0.8989899 , 0.8956229 , 0.8973064 , 0.8989899 , 0.8989899 ,\n",
       "        0.89393939, 0.8973064 , 0.8973064 , 0.8989899 , 0.89393939,\n",
       "        0.8973064 , 0.8973064 , 0.8989899 , 0.88552189, 0.88047138,\n",
       "        0.88047138, 0.88383838, 0.89057239, 0.8973064 , 0.9006734 ,\n",
       "        0.8989899 , 0.89393939, 0.8956229 , 0.9006734 , 0.8989899 ,\n",
       "        0.8973064 , 0.8973064 , 0.8989899 , 0.8989899 , 0.89225589,\n",
       "        0.8956229 , 0.9006734 , 0.8989899 , 0.89393939, 0.8973064 ,\n",
       "        0.8973064 , 0.8989899 , 0.89393939, 0.8956229 , 0.8973064 ,\n",
       "        0.8989899 , 0.88215488, 0.88047138, 0.87878788, 0.88215488,\n",
       "        0.9023569 , 0.9006734 , 0.9040404 , 0.8989899 , 0.9006734 ,\n",
       "        0.9006734 , 0.9040404 , 0.9023569 , 0.9006734 , 0.9006734 ,\n",
       "        0.9040404 , 0.8989899 , 0.9023569 , 0.9006734 , 0.9023569 ,\n",
       "        0.8973064 , 0.8973064 , 0.9023569 , 0.90572391, 0.8989899 ,\n",
       "        0.8989899 , 0.8989899 , 0.9006734 , 0.8989899 , 0.88552189,\n",
       "        0.88383838, 0.88383838, 0.88888889, 0.9023569 , 0.8989899 ,\n",
       "        0.9040404 , 0.8989899 , 0.9006734 , 0.9006734 , 0.9040404 ,\n",
       "        0.8989899 , 0.9023569 , 0.8989899 , 0.9023569 , 0.8989899 ,\n",
       "        0.9006734 , 0.9006734 , 0.9040404 , 0.8989899 , 0.8989899 ,\n",
       "        0.8973064 , 0.9040404 , 0.8989899 , 0.8973064 , 0.8973064 ,\n",
       "        0.9023569 , 0.8973064 , 0.88552189, 0.88383838, 0.88383838,\n",
       "        0.88888889, 0.9040404 , 0.8973064 , 0.9040404 , 0.8989899 ,\n",
       "        0.9023569 , 0.9006734 , 0.9040404 , 0.8989899 , 0.8989899 ,\n",
       "        0.8989899 , 0.9040404 , 0.8989899 , 0.9040404 , 0.8989899 ,\n",
       "        0.9023569 , 0.8973064 , 0.8956229 , 0.8989899 , 0.9023569 ,\n",
       "        0.8989899 , 0.89393939, 0.8973064 , 0.9040404 , 0.8989899 ,\n",
       "        0.88552189, 0.88215488, 0.88047138, 0.88552189, 0.8989899 ,\n",
       "        0.8989899 , 0.9040404 , 0.8989899 , 0.8989899 , 0.9006734 ,\n",
       "        0.9023569 , 0.8989899 , 0.9023569 , 0.8989899 , 0.8973064 ,\n",
       "        0.8989899 , 0.8989899 , 0.8989899 , 0.90572391, 0.8973064 ,\n",
       "        0.8973064 , 0.8973064 , 0.9023569 , 0.8989899 , 0.8956229 ,\n",
       "        0.8956229 , 0.9023569 , 0.8989899 , 0.88552189, 0.88215488,\n",
       "        0.88047138, 0.88552189, 0.9023569 , 0.8973064 , 0.9023569 ,\n",
       "        0.8989899 , 0.9023569 , 0.8989899 , 0.9006734 , 0.8989899 ,\n",
       "        0.8973064 , 0.8989899 , 0.8989899 , 0.8989899 , 0.8989899 ,\n",
       "        0.8989899 , 0.9040404 , 0.9006734 , 0.8956229 , 0.8956229 ,\n",
       "        0.9040404 , 0.8973064 , 0.89393939, 0.8956229 , 0.9023569 ,\n",
       "        0.8989899 , 0.88215488, 0.88047138, 0.88047138, 0.88215488,\n",
       "        0.9040404 , 0.9040404 , 0.9040404 , 0.9006734 , 0.90740741,\n",
       "        0.9023569 , 0.9040404 , 0.9023569 , 0.90909091, 0.9040404 ,\n",
       "        0.90572391, 0.9006734 , 0.90740741, 0.9040404 , 0.9040404 ,\n",
       "        0.8989899 , 0.90572391, 0.9040404 , 0.90572391, 0.9006734 ,\n",
       "        0.9040404 , 0.9023569 , 0.9040404 , 0.9006734 , 0.88720539,\n",
       "        0.88720539, 0.88383838, 0.88888889, 0.90909091, 0.9023569 ,\n",
       "        0.9023569 , 0.9006734 , 0.90740741, 0.9023569 , 0.9023569 ,\n",
       "        0.9006734 , 0.90740741, 0.9023569 , 0.9040404 , 0.9006734 ,\n",
       "        0.90740741, 0.9023569 , 0.9023569 , 0.9006734 , 0.9040404 ,\n",
       "        0.9023569 , 0.90572391, 0.9006734 , 0.9023569 , 0.9023569 ,\n",
       "        0.9040404 , 0.9006734 , 0.88552189, 0.88383838, 0.88552189,\n",
       "        0.88888889, 0.90740741, 0.9040404 , 0.90572391, 0.9006734 ,\n",
       "        0.90572391, 0.9040404 , 0.9040404 , 0.9006734 , 0.90740741,\n",
       "        0.9023569 , 0.9006734 , 0.9006734 , 0.90909091, 0.9040404 ,\n",
       "        0.9023569 , 0.9006734 , 0.90740741, 0.9040404 , 0.9040404 ,\n",
       "        0.8989899 , 0.9040404 , 0.9023569 , 0.9040404 , 0.8973064 ,\n",
       "        0.88720539, 0.88383838, 0.88383838, 0.88888889, 0.90572391,\n",
       "        0.9040404 , 0.9006734 , 0.9006734 , 0.90572391, 0.9040404 ,\n",
       "        0.9006734 , 0.9006734 , 0.90909091, 0.9040404 , 0.9040404 ,\n",
       "        0.9006734 , 0.90572391, 0.9040404 , 0.9023569 , 0.8989899 ,\n",
       "        0.9040404 , 0.9006734 , 0.90572391, 0.9023569 , 0.9006734 ,\n",
       "        0.9006734 , 0.9023569 , 0.9006734 , 0.88552189, 0.88383838,\n",
       "        0.88383838, 0.88720539, 0.9040404 , 0.9023569 , 0.9023569 ,\n",
       "        0.8989899 , 0.9040404 , 0.9023569 , 0.9006734 , 0.8989899 ,\n",
       "        0.90572391, 0.9023569 , 0.9040404 , 0.8989899 , 0.9040404 ,\n",
       "        0.9040404 , 0.9023569 , 0.9006734 , 0.90572391, 0.9023569 ,\n",
       "        0.9023569 , 0.9023569 , 0.9006734 , 0.9023569 , 0.9006734 ,\n",
       "        0.8989899 , 0.88383838, 0.88383838, 0.88047138, 0.88215488]),\n",
       " 'mean_train_Accuracy': array([0.9006734 , 0.9040404 , 0.90347924, 0.90347924, 0.90011223,\n",
       "        0.90516274, 0.9040404 , 0.90347924, 0.9006734 , 0.9040404 ,\n",
       "        0.9040404 , 0.90347924, 0.90011223, 0.90291807, 0.90347924,\n",
       "        0.90291807, 0.8989899 , 0.9040404 , 0.90291807, 0.90347924,\n",
       "        0.8989899 , 0.90179574, 0.90179574, 0.90347924, 0.88720539,\n",
       "        0.88720539, 0.88945006, 0.88945006, 0.90011223, 0.9040404 ,\n",
       "        0.90460157, 0.90347924, 0.9006734 , 0.90516274, 0.90516274,\n",
       "        0.90347924, 0.8989899 , 0.90347924, 0.90460157, 0.90291807,\n",
       "        0.90123457, 0.90460157, 0.90291807, 0.90291807, 0.90123457,\n",
       "        0.90347924, 0.90291807, 0.90291807, 0.8989899 , 0.90291807,\n",
       "        0.90179574, 0.9023569 , 0.88664422, 0.88720539, 0.88888889,\n",
       "        0.88888889, 0.90011223, 0.90460157, 0.9040404 , 0.90291807,\n",
       "        0.90011223, 0.9040404 , 0.90347924, 0.90291807, 0.9006734 ,\n",
       "        0.9040404 , 0.90291807, 0.9023569 , 0.9006734 , 0.90291807,\n",
       "        0.90460157, 0.90291807, 0.90011223, 0.90347924, 0.90291807,\n",
       "        0.9023569 , 0.8973064 , 0.9023569 , 0.90179574, 0.90179574,\n",
       "        0.88439955, 0.88439955, 0.88776655, 0.88832772, 0.9006734 ,\n",
       "        0.9040404 , 0.90291807, 0.9023569 , 0.90123457, 0.9040404 ,\n",
       "        0.90347924, 0.90179574, 0.9006734 , 0.9040404 , 0.9040404 ,\n",
       "        0.90291807, 0.90011223, 0.9040404 , 0.90179574, 0.90291807,\n",
       "        0.8989899 , 0.9040404 , 0.90123457, 0.9023569 , 0.89786756,\n",
       "        0.90179574, 0.90179574, 0.9023569 , 0.88439955, 0.88383838,\n",
       "        0.88496072, 0.88776655, 0.89955107, 0.90291807, 0.9023569 ,\n",
       "        0.9023569 , 0.89955107, 0.90347924, 0.90347924, 0.9023569 ,\n",
       "        0.9006734 , 0.90291807, 0.9023569 , 0.9023569 , 0.9006734 ,\n",
       "        0.9023569 , 0.90291807, 0.9023569 , 0.89955107, 0.90123457,\n",
       "        0.90123457, 0.90011223, 0.89786756, 0.90179574, 0.90011223,\n",
       "        0.90123457, 0.88215488, 0.88327722, 0.88327722, 0.88664422,\n",
       "        0.9023569 , 0.90291807, 0.90628507, 0.90347924, 0.90347924,\n",
       "        0.90460157, 0.90516274, 0.9040404 , 0.90179574, 0.90347924,\n",
       "        0.90460157, 0.90460157, 0.90123457, 0.9040404 , 0.90516274,\n",
       "        0.90347924, 0.9006734 , 0.90291807, 0.90516274, 0.9040404 ,\n",
       "        0.90011223, 0.90516274, 0.90516274, 0.9040404 , 0.88888889,\n",
       "        0.88945006, 0.88945006, 0.89169473, 0.90123457, 0.90347924,\n",
       "        0.90628507, 0.9040404 , 0.90179574, 0.90460157, 0.90572391,\n",
       "        0.9040404 , 0.9006734 , 0.90291807, 0.90460157, 0.90347924,\n",
       "        0.9023569 , 0.90460157, 0.90460157, 0.90347924, 0.90011223,\n",
       "        0.9040404 , 0.90572391, 0.9040404 , 0.90011223, 0.90516274,\n",
       "        0.9040404 , 0.90460157, 0.88776655, 0.88832772, 0.88776655,\n",
       "        0.88945006, 0.90179574, 0.9040404 , 0.90516274, 0.9040404 ,\n",
       "        0.9006734 , 0.9040404 , 0.90516274, 0.90291807, 0.90011223,\n",
       "        0.9040404 , 0.90572391, 0.90460157, 0.9006734 , 0.90347924,\n",
       "        0.90572391, 0.9040404 , 0.90123457, 0.90460157, 0.90572391,\n",
       "        0.90460157, 0.8989899 , 0.90460157, 0.9040404 , 0.9040404 ,\n",
       "        0.88888889, 0.88888889, 0.88608305, 0.88888889, 0.9023569 ,\n",
       "        0.90347924, 0.90460157, 0.90291807, 0.9023569 , 0.90347924,\n",
       "        0.90460157, 0.9040404 , 0.90011223, 0.9040404 , 0.90460157,\n",
       "        0.9040404 , 0.90123457, 0.9040404 , 0.90572391, 0.9040404 ,\n",
       "        0.89955107, 0.9040404 , 0.9040404 , 0.9040404 , 0.8989899 ,\n",
       "        0.9040404 , 0.90347924, 0.9023569 , 0.88832772, 0.88439955,\n",
       "        0.88664422, 0.88776655, 0.8989899 , 0.9040404 , 0.90572391,\n",
       "        0.9023569 , 0.90011223, 0.90347924, 0.90572391, 0.90179574,\n",
       "        0.90179574, 0.90347924, 0.90460157, 0.90291807, 0.90011223,\n",
       "        0.90291807, 0.90572391, 0.90291807, 0.90011223, 0.90347924,\n",
       "        0.90291807, 0.9023569 , 0.89955107, 0.90347924, 0.9040404 ,\n",
       "        0.9023569 , 0.88552189, 0.88383838, 0.88439955, 0.88664422,\n",
       "        0.9040404 , 0.90460157, 0.90740741, 0.90460157, 0.90291807,\n",
       "        0.90516274, 0.90796857, 0.90572391, 0.9040404 , 0.90572391,\n",
       "        0.90852974, 0.90628507, 0.90516274, 0.90572391, 0.90684624,\n",
       "        0.90516274, 0.90179574, 0.90628507, 0.90796857, 0.90572391,\n",
       "        0.9023569 , 0.9040404 , 0.90516274, 0.90460157, 0.88945006,\n",
       "        0.89001122, 0.89113356, 0.89225589, 0.90460157, 0.90516274,\n",
       "        0.90852974, 0.90572391, 0.90347924, 0.90516274, 0.90852974,\n",
       "        0.90460157, 0.90460157, 0.90460157, 0.90740741, 0.90572391,\n",
       "        0.90347924, 0.90628507, 0.90796857, 0.90516274, 0.90179574,\n",
       "        0.90460157, 0.90684624, 0.9040404 , 0.90179574, 0.90347924,\n",
       "        0.90572391, 0.90291807, 0.88945006, 0.88945006, 0.89001122,\n",
       "        0.89281706, 0.90460157, 0.90460157, 0.90740741, 0.90460157,\n",
       "        0.9040404 , 0.90684624, 0.90740741, 0.90516274, 0.9023569 ,\n",
       "        0.90572391, 0.90852974, 0.90460157, 0.90460157, 0.90572391,\n",
       "        0.90796857, 0.90460157, 0.90179574, 0.90460157, 0.90628507,\n",
       "        0.90460157, 0.90011223, 0.90291807, 0.90740741, 0.9040404 ,\n",
       "        0.88776655, 0.88832772, 0.88945006, 0.89057239, 0.90291807,\n",
       "        0.90460157, 0.90740741, 0.90516274, 0.90347924, 0.90516274,\n",
       "        0.90684624, 0.90460157, 0.90347924, 0.90460157, 0.90516274,\n",
       "        0.90460157, 0.90347924, 0.90572391, 0.90796857, 0.9040404 ,\n",
       "        0.90123457, 0.9040404 , 0.90628507, 0.9040404 , 0.90123457,\n",
       "        0.90291807, 0.90628507, 0.90347924, 0.88832772, 0.88720539,\n",
       "        0.88720539, 0.89001122, 0.90291807, 0.90347924, 0.90516274,\n",
       "        0.90460157, 0.9023569 , 0.9040404 , 0.90516274, 0.90516274,\n",
       "        0.90179574, 0.90460157, 0.90628507, 0.90460157, 0.9023569 ,\n",
       "        0.90460157, 0.90796857, 0.9040404 , 0.89955107, 0.9023569 ,\n",
       "        0.90684624, 0.90291807, 0.89955107, 0.90291807, 0.90516274,\n",
       "        0.90460157, 0.88664422, 0.88552189, 0.88664422, 0.88776655,\n",
       "        0.90740741, 0.90965208, 0.90684624, 0.90740741, 0.90965208,\n",
       "        0.90909091, 0.90796857, 0.90740741, 0.91021324, 0.90909091,\n",
       "        0.90852974, 0.90684624, 0.90852974, 0.90909091, 0.90796857,\n",
       "        0.90572391, 0.90909091, 0.90852974, 0.90740741, 0.90516274,\n",
       "        0.90628507, 0.90852974, 0.90740741, 0.90684624, 0.89001122,\n",
       "        0.89337823, 0.89113356, 0.89450056, 0.90909091, 0.90740741,\n",
       "        0.90684624, 0.90684624, 0.90909091, 0.90628507, 0.90852974,\n",
       "        0.90572391, 0.90852974, 0.90796857, 0.90852974, 0.90572391,\n",
       "        0.90796857, 0.90796857, 0.90628507, 0.90684624, 0.90684624,\n",
       "        0.90740741, 0.90796857, 0.90628507, 0.9040404 , 0.90628507,\n",
       "        0.90684624, 0.90684624, 0.88945006, 0.89225589, 0.89169473,\n",
       "        0.89337823, 0.90852974, 0.90909091, 0.90740741, 0.90684624,\n",
       "        0.90684624, 0.90852974, 0.90684624, 0.9040404 , 0.90740741,\n",
       "        0.90796857, 0.90684624, 0.90516274, 0.90796857, 0.90852974,\n",
       "        0.90684624, 0.90628507, 0.90516274, 0.90796857, 0.90628507,\n",
       "        0.9040404 , 0.90460157, 0.90628507, 0.90740741, 0.90516274,\n",
       "        0.89001122, 0.89057239, 0.89057239, 0.89225589, 0.90628507,\n",
       "        0.90740741, 0.90684624, 0.90516274, 0.90684624, 0.90909091,\n",
       "        0.90684624, 0.90460157, 0.90740741, 0.90740741, 0.90740741,\n",
       "        0.90572391, 0.90628507, 0.90796857, 0.90740741, 0.90460157,\n",
       "        0.90347924, 0.90684624, 0.90796857, 0.90572391, 0.9023569 ,\n",
       "        0.90572391, 0.90572391, 0.90628507, 0.88832772, 0.89001122,\n",
       "        0.89057239, 0.89169473, 0.90572391, 0.90740741, 0.90684624,\n",
       "        0.90460157, 0.90516274, 0.90740741, 0.90628507, 0.90516274,\n",
       "        0.90572391, 0.90740741, 0.90684624, 0.90516274, 0.90572391,\n",
       "        0.90796857, 0.90628507, 0.90460157, 0.90460157, 0.90628507,\n",
       "        0.90572391, 0.90628507, 0.9023569 , 0.90572391, 0.90628507,\n",
       "        0.90460157, 0.88608305, 0.88888889, 0.88776655, 0.88832772]),\n",
       " 'std_train_Accuracy': array([0.01259817, 0.01198325, 0.01356122, 0.01544994, 0.01277195,\n",
       "        0.01376862, 0.01428499, 0.01544994, 0.01259817, 0.01198325,\n",
       "        0.01428499, 0.01544994, 0.01277195, 0.01169061, 0.01469787,\n",
       "        0.01563231, 0.01325591, 0.01073576, 0.0150786 , 0.01544994,\n",
       "        0.01221748, 0.01247256, 0.01349138, 0.01544994, 0.01259817,\n",
       "        0.01125137, 0.01299196, 0.01299196, 0.01185113, 0.01073576,\n",
       "        0.0140404 , 0.01544994, 0.01259817, 0.01247256, 0.01356122,\n",
       "        0.01544994, 0.01435097, 0.01247256, 0.01390518, 0.01469787,\n",
       "        0.01335059, 0.01152786, 0.01390518, 0.01563231, 0.0120095 ,\n",
       "        0.01247256, 0.01390518, 0.01563231, 0.01325591, 0.01335059,\n",
       "        0.01349138, 0.01486828, 0.01049848, 0.0103778 , 0.01325591,\n",
       "        0.01353798, 0.01277195, 0.01169061, 0.01311259, 0.01604978,\n",
       "        0.01277195, 0.01221748, 0.01356122, 0.01604978, 0.01259817,\n",
       "        0.01325591, 0.0150786 , 0.01666582, 0.01259817, 0.01299196,\n",
       "        0.0140404 , 0.01604978, 0.01410753, 0.01247256, 0.0140404 ,\n",
       "        0.01620598, 0.01221748, 0.01353798, 0.01376862, 0.01593162,\n",
       "        0.01169061, 0.01111054, 0.01430701, 0.01410753, 0.01259817,\n",
       "        0.01221748, 0.01514112, 0.01754938, 0.01335059, 0.01221748,\n",
       "        0.01356122, 0.01679756, 0.01259817, 0.01353798, 0.01428499,\n",
       "        0.01740523, 0.01320831, 0.01221748, 0.01469787, 0.01604978,\n",
       "        0.01259817, 0.01198325, 0.01277195, 0.0153066 , 0.0140404 ,\n",
       "        0.01277195, 0.01376862, 0.0153066 , 0.01067693, 0.00991219,\n",
       "        0.01482586, 0.01430701, 0.0120095 , 0.01299196, 0.01428499,\n",
       "        0.0153066 , 0.0120095 , 0.01232015, 0.01587221, 0.01666582,\n",
       "        0.01259817, 0.01299196, 0.01311259, 0.01666582, 0.01259817,\n",
       "        0.01190415, 0.0150786 , 0.0153066 , 0.01169061, 0.01277195,\n",
       "        0.0140404 , 0.01514112, 0.01169061, 0.01277195, 0.01482586,\n",
       "        0.01520339, 0.01073576, 0.01013214, 0.01376862, 0.01410753,\n",
       "        0.01311259, 0.01277195, 0.01335059, 0.01544994, 0.01277195,\n",
       "        0.01299196, 0.01410753, 0.01486828, 0.01356122, 0.01247256,\n",
       "        0.0140404 , 0.01563231, 0.01269776, 0.01198325, 0.01410753,\n",
       "        0.01410753, 0.01198325, 0.01152786, 0.01277195, 0.01620598,\n",
       "        0.01144561, 0.01232015, 0.01376862, 0.01486828, 0.01125137,\n",
       "        0.01169061, 0.01299196, 0.01277195, 0.01277195, 0.01356122,\n",
       "        0.0140404 , 0.0139504 , 0.01232015, 0.01169061, 0.01454712,\n",
       "        0.0139504 , 0.01435097, 0.01269776, 0.01430701, 0.01544994,\n",
       "        0.01311259, 0.01277195, 0.01430701, 0.01544994, 0.01247256,\n",
       "        0.01311259, 0.01454712, 0.01486828, 0.01277195, 0.01247256,\n",
       "        0.01325591, 0.01563231, 0.01067693, 0.01119525, 0.01277195,\n",
       "        0.01335059, 0.01356122, 0.01221748, 0.01376862, 0.01486828,\n",
       "        0.01311259, 0.01325591, 0.01356122, 0.01469787, 0.0150786 ,\n",
       "        0.01221748, 0.01435097, 0.01563231, 0.01353798, 0.01232015,\n",
       "        0.01454712, 0.01486828, 0.01169061, 0.01169061, 0.01454712,\n",
       "        0.01563231, 0.01125137, 0.01277195, 0.01585235, 0.01620598,\n",
       "        0.00991219, 0.01198325, 0.01299196, 0.0139504 , 0.01325591,\n",
       "        0.01232015, 0.01430701, 0.01469787, 0.01325591, 0.01232015,\n",
       "        0.01430701, 0.01486828, 0.01119525, 0.01198325, 0.0140404 ,\n",
       "        0.01620598, 0.01299196, 0.01198325, 0.01325591, 0.01486828,\n",
       "        0.01169061, 0.01198325, 0.01585235, 0.01486828, 0.01353798,\n",
       "        0.01198325, 0.0150786 , 0.0139504 , 0.01049848, 0.0120095 ,\n",
       "        0.01376862, 0.01335059, 0.01311259, 0.01198325, 0.01353798,\n",
       "        0.0139504 , 0.01247256, 0.01232015, 0.01353798, 0.01320831,\n",
       "        0.01277195, 0.01247256, 0.01430701, 0.01469787, 0.01356122,\n",
       "        0.01277195, 0.01353798, 0.01335059, 0.01247256, 0.01247256,\n",
       "        0.01430701, 0.0139504 , 0.01299196, 0.01356122, 0.01454712,\n",
       "        0.0139504 , 0.00991219, 0.01125137, 0.01299196, 0.01410753,\n",
       "        0.01174436, 0.0120095 , 0.01259817, 0.01430701, 0.01111054,\n",
       "        0.01277195, 0.0120095 , 0.0139504 , 0.01125137, 0.01221748,\n",
       "        0.01277195, 0.0140404 , 0.00915236, 0.01353798, 0.01277195,\n",
       "        0.01356122, 0.01144561, 0.0120095 , 0.01247256, 0.01325591,\n",
       "        0.01125137, 0.01221748, 0.01410753, 0.01430701, 0.01067693,\n",
       "        0.01376862, 0.01277195, 0.0139504 , 0.01111054, 0.01247256,\n",
       "        0.01277195, 0.01325591, 0.01049848, 0.01277195, 0.01277195,\n",
       "        0.01430701, 0.01111054, 0.01299196, 0.01221748, 0.01454712,\n",
       "        0.01049848, 0.01299196, 0.0120095 , 0.01247256, 0.01185113,\n",
       "        0.01277195, 0.01320831, 0.01486828, 0.01144561, 0.01119525,\n",
       "        0.0139504 , 0.01430701, 0.01067693, 0.01169061, 0.01119525,\n",
       "        0.01335059, 0.01031693, 0.0140404 , 0.01259817, 0.01430701,\n",
       "        0.01174436, 0.01376862, 0.01259817, 0.01376862, 0.01125137,\n",
       "        0.01325591, 0.01277195, 0.01430701, 0.01169061, 0.01325591,\n",
       "        0.01430701, 0.01532716, 0.01119525, 0.01169061, 0.01335059,\n",
       "        0.01430701, 0.01247256, 0.01169061, 0.0139504 , 0.01353798,\n",
       "        0.00839878, 0.01247256, 0.01152786, 0.01353798, 0.01067693,\n",
       "        0.01299196, 0.01259817, 0.01376862, 0.01144561, 0.01277195,\n",
       "        0.01277195, 0.01430701, 0.01102519, 0.01169061, 0.01356122,\n",
       "        0.01299196, 0.01144561, 0.01325591, 0.01247256, 0.01454712,\n",
       "        0.0120095 , 0.01198325, 0.01335059, 0.01353798, 0.0104081 ,\n",
       "        0.01277195, 0.01335059, 0.01410753, 0.00915236, 0.01221748,\n",
       "        0.01198325, 0.01410753, 0.01169061, 0.01247256, 0.01320831,\n",
       "        0.01299196, 0.01237116, 0.01221748, 0.01410753, 0.01376862,\n",
       "        0.01144561, 0.01169061, 0.0140404 , 0.01299196, 0.01125137,\n",
       "        0.01169061, 0.01335059, 0.0139504 , 0.01335059, 0.01198325,\n",
       "        0.01320831, 0.01430701, 0.01299196, 0.01277195, 0.01320831,\n",
       "        0.01430701, 0.00757056, 0.01221748, 0.01247256, 0.01563231,\n",
       "        0.01125137, 0.01169061, 0.01456875, 0.01585235, 0.01111054,\n",
       "        0.01198325, 0.01335059, 0.01486828, 0.01239659, 0.01221748,\n",
       "        0.01320831, 0.0150786 , 0.01239659, 0.01221748, 0.01335059,\n",
       "        0.01585235, 0.00991219, 0.01144561, 0.01448203, 0.01544994,\n",
       "        0.01111054, 0.01247256, 0.0139504 , 0.01639915, 0.01049848,\n",
       "        0.01247256, 0.01277195, 0.01430701, 0.01099659, 0.01091034,\n",
       "        0.01410753, 0.01639915, 0.0103778 , 0.0120095 , 0.01376862,\n",
       "        0.01620598, 0.01102519, 0.01169061, 0.01410753, 0.01620598,\n",
       "        0.01169061, 0.01299196, 0.01469787, 0.01639915, 0.01049848,\n",
       "        0.01353798, 0.01383707, 0.01696545, 0.01174436, 0.01067693,\n",
       "        0.01456875, 0.01772791, 0.01067693, 0.01311259, 0.01247256,\n",
       "        0.01277195, 0.01239659, 0.01221748, 0.01448203, 0.01639915,\n",
       "        0.01102519, 0.01277195, 0.01456875, 0.0153066 , 0.01099659,\n",
       "        0.01299196, 0.01376862, 0.01679756, 0.01239659, 0.01144561,\n",
       "        0.01410753, 0.01830472, 0.01111054, 0.0120095 , 0.01383707,\n",
       "        0.01620598, 0.01306447, 0.0120095 , 0.01259817, 0.01740523,\n",
       "        0.01049848, 0.01198325, 0.01198325, 0.01259817, 0.01031693,\n",
       "        0.01125137, 0.01376862, 0.01679756, 0.01102519, 0.01221748,\n",
       "        0.01376862, 0.01604978, 0.01174436, 0.01259817, 0.0139504 ,\n",
       "        0.01754938, 0.01169061, 0.0120095 , 0.01353798, 0.01830472,\n",
       "        0.01169061, 0.01119525, 0.01383707, 0.01666582, 0.01311259,\n",
       "        0.01221748, 0.0139504 , 0.01696545, 0.01049848, 0.01119525,\n",
       "        0.01198325, 0.01277195, 0.01174436, 0.01221748, 0.01410753,\n",
       "        0.01563231, 0.01239659, 0.01221748, 0.01430701, 0.01639915,\n",
       "        0.01099659, 0.01221748, 0.01456875, 0.01772791, 0.01174436,\n",
       "        0.0120095 , 0.01469787, 0.01604978, 0.01239659, 0.0120095 ,\n",
       "        0.0139504 , 0.01740523, 0.01448203, 0.01125137, 0.01430701,\n",
       "        0.01563231, 0.01111054, 0.01091034, 0.0140404 , 0.0150786 ])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8372615039281706"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
